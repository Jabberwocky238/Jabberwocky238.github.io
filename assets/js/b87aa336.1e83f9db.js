"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[5058],{8163:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>i,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var a=n(4848),r=n(8453);const s={},i=void 0,o={id:"Craftinginterpreters/not-translated-yet/hash-tables",title:"hash-tables",description:"Hash, x. There is no definition for this word -- nobody knows what hash is.",source:"@site/docs/Craftinginterpreters/not-translated-yet/hash-tables.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/hash-tables",permalink:"/docs/Craftinginterpreters/not-translated-yet/hash-tables",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/hash-tables.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"global-variables",permalink:"/docs/Craftinginterpreters/not-translated-yet/global-variables"},next:{title:"inheritance",permalink:"/docs/Craftinginterpreters/not-translated-yet/inheritance"}},h={},l=[{value:"An Array of Buckets",id:"an-array-of-buckets",level:2},{value:"Load factor and wrapped keys",id:"load-factor-and-wrapped-keys",level:3},{value:"Collision Resolution",id:"collision-resolution",level:2},{value:"Separate chaining",id:"separate-chaining",level:3},{value:"Open addressing",id:"open-addressing",level:3},{value:"Hash Functions",id:"hash-functions",level:2},{value:"Building a Hash Table",id:"building-a-hash-table",level:2},{value:"Hashing strings",id:"hashing-strings",level:3},{value:"Inserting entries",id:"inserting-entries",level:3},{value:"Allocating and resizing",id:"allocating-and-resizing",level:3},{value:"Retrieving values",id:"retrieving-values",level:3},{value:"Deleting entries",id:"deleting-entries",level:3},{value:"Counting tombstones",id:"counting-tombstones",level:3},{value:"String Interning",id:"string-interning",level:2},{value:"Challenges",id:"challenges",level:2}];function c(e){const t={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",span:"span",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsx)(t.p,{children:"Hash, x. There is no definition for this word -- nobody knows what hash is."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsxs)(t.cite,{children:["Ambrose Bierce, ",(0,a.jsx)(t.em,{children:"The Unabridged Devil's Dictionary"})]})}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"Before we can add variables to our burgeoning virtual machine, we need some way\r\nto look up a value given a variable's name. Later, when we add classes, we'll\r\nalso need a way to store fields on instances. The perfect data structure for\r\nthese problems and others is a hash table."}),"\n",(0,a.jsx)(t.p,{children:'You probably already know what a hash table is, even if you don\'t know it by\r\nthat name. If you\'re a Java programmer, you call them "HashMaps". C# and Python\r\nusers call them "dictionaries". In C++, it\'s an "unordered map". "Objects" in\r\nJavaScript and "tables" in Lua are hash tables under the hood, which is what\r\ngives them their flexibility.'}),"\n",(0,a.jsxs)(t.p,{children:["A hash table, whatever your language calls it, associates a set of ",(0,a.jsx)(t.strong,{children:"keys"})," with\r\na set of ",(0,a.jsx)(t.strong,{children:"values"}),". Each key/value pair is an ",(0,a.jsx)(t.strong,{children:"entry"})," in the table. Given a\r\nkey, you can look up its corresponding value. You can add new key/value pairs\r\nand remove entries by key. If you add a new value for an existing key, it\r\nreplaces the previous entry."]}),"\n",(0,a.jsxs)(t.p,{children:["Hash tables appear in so many languages because they are incredibly powerful.\r\nMuch of this power comes from one metric: given a key, a hash table returns the\r\ncorresponding value in ",(0,a.jsx)(t.span,{name:"constant",children:"constant time"}),", ",(0,a.jsx)(t.em,{children:"regardless\r\nof how many keys are in the hash table"}),"."]}),"\n",(0,a.jsxs)(t.aside,{name:"constant",children:["\n",(0,a.jsxs)(t.p,{children:["More specifically, the ",(0,a.jsx)(t.em,{children:"average-case"})," lookup time is constant. Worst-case\r\nperformance can be, well, worse. In practice, it's easy to avoid degenerate\r\nbehavior and stay on the happy path."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["That's pretty remarkable when you think about it. Imagine you've got a big stack\r\nof business cards and I ask you to find a certain person. The bigger the pile\r\nis, the longer it will take. Even if the pile is nicely sorted and you've got\r\nthe manual dexterity to do a binary search by hand, you're still talking\r\n",(0,a.jsx)(t.em,{children:"O(log n)"}),". But with a ",(0,a.jsx)(t.span,{name:"rolodex",children:"hash table"}),", it takes the\r\nsame time to find that business card when the stack has ten cards as when it has\r\na million."]}),"\n",(0,a.jsxs)(t.aside,{name:"rolodex",children:["\n",(0,a.jsx)(t.p,{children:"Stuff all those cards in a Rolodex -- does anyone even remember those things\r\nanymore? -- with dividers for each letter, and you improve your speed\r\ndramatically. As we'll see, that's not too far from the trick a hash table uses."}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"an-array-of-buckets",children:"An Array of Buckets"}),"\n",(0,a.jsx)(t.p,{children:"A complete, fast hash table has a couple of moving parts. I'll introduce them\r\none at a time by working through a couple of toy problems and their solutions.\r\nEventually, we'll build up to a data structure that can associate any set of\r\nnames with their values."}),"\n",(0,a.jsxs)(t.p,{children:["For now, imagine if Lox was a ",(0,a.jsx)(t.em,{children:"lot"})," more restricted in variable names. What if a\r\nvariable's name could only be a ",(0,a.jsx)(t.span,{name:"basic",children:"single"})," lowercase\r\nletter. How could we very efficiently represent a set of variable names and\r\ntheir values?"]}),"\n",(0,a.jsxs)(t.aside,{name:"basic",children:["\n",(0,a.jsxs)(t.p,{children:["This limitation isn't ",(0,a.jsx)(t.em,{children:"too"})," far-fetched. The initial versions of BASIC out of\r\nDartmouth allowed variable names to be only a single letter followed by one\r\noptional digit."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:['With only 26 possible variables (27 if you consider underscore a "letter", I\r\nguess), the answer is easy. Declare a fixed-size array with 26 elements. We\'ll\r\nfollow tradition and call each element a ',(0,a.jsx)(t.strong,{children:"bucket"}),". Each represents a variable\r\nwith ",(0,a.jsx)(t.code,{children:"a"})," starting at index zero. If there's a value in the array at some\r\nletter's index, then that key is present with that value. Otherwise, the bucket\r\nis empty and that key/value pair isn't in the data structure."]}),"\n",(0,a.jsxs)(t.aside,{name:"bucket",children:["\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{src:"image/hash-tables/bucket-array.png",alt:"A row of buckets, each\nlabeled with a letter of the alphabet."})}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["Memory usage is great -- just a single, reasonably sized ",(0,a.jsx)(t.span,{name:"bucket",children:"array"}),". There's some waste from the empty buckets, but it's\r\nnot huge. There's no overhead for node pointers, padding, or other stuff you'd\r\nget with something like a linked list or tree."]}),"\n",(0,a.jsxs)(t.p,{children:["Performance is even better. Given a variable name -- its character -- you can\r\nsubtract the ASCII value of ",(0,a.jsx)(t.code,{children:"a"})," and use the result to index directly into the\r\narray. Then you can either look up the existing value or store a new value\r\ndirectly into that slot. It doesn't get much faster than that."]}),"\n",(0,a.jsx)(t.p,{children:"This is sort of our Platonic ideal data structure. Lightning fast, dead simple,\r\nand compact in memory. As we add support for more complex keys, we'll have to\r\nmake some concessions, but this is what we're aiming for. Even once you add in\r\nhash functions, dynamic resizing, and collision resolution, this is still the\r\ncore of every hash table out there -- a contiguous array of buckets that you\r\nindex directly into."}),"\n",(0,a.jsx)(t.h3,{id:"load-factor-and-wrapped-keys",children:"Load factor and wrapped keys"}),"\n",(0,a.jsxs)(t.p,{children:["Confining Lox to single-letter variables would make our job as implementers\r\neasier, but it's probably no fun programming in a language that gives you only\r\n26 storage locations. What if we loosened it a little and allowed variables up\r\nto ",(0,a.jsx)(t.span,{name:"six",children:"eight"})," characters long?"]}),"\n",(0,a.jsxs)(t.aside,{name:"six",children:["\n",(0,a.jsxs)(t.p,{children:["Again, this restriction isn't so crazy. Early linkers for C treated only the\r\nfirst six characters of external identifiers as meaningful. Everything after\r\nthat was ignored. If you've ever wondered why the C standard library is so\r\nenamored of abbreviation -- looking at you, ",(0,a.jsx)(t.code,{children:"strncmp()"})," -- it turns out it\r\nwasn't entirely because of the small screens (or teletypes!) of the day."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["That's small enough that we can pack all eight characters into a 64-bit integer\r\nand easily turn the string into a number. We can then use it as an array index.\r\nOr, at least, we could if we could somehow allocate a 295,148 ",(0,a.jsx)(t.em,{children:"petabyte"})," array.\r\nMemory's gotten cheaper over time, but not quite ",(0,a.jsx)(t.em,{children:"that"})," cheap. Even if we could\r\nmake an array that big, it would be heinously wasteful. Almost every bucket\r\nwould be empty unless users started writing way bigger Lox programs than we've\r\nanticipated."]}),"\n",(0,a.jsx)(t.p,{children:"Even though our variable keys cover the full 64-bit numeric range, we clearly\r\ndon't need an array that large. Instead, we allocate an array with more than\r\nenough capacity for the entries we need, but not unreasonably large. We map the\r\nfull 64-bit keys down to that smaller range by taking the value modulo the size\r\nof the array. Doing that essentially folds the larger numeric range onto itself\r\nuntil it fits the smaller range of array elements."}),"\n",(0,a.jsxs)(t.p,{children:['For example, say we want to store "bagel". We allocate an array with eight\r\nelements, plenty enough to store it and more later. We treat the key string as a\r\n64-bit integer. On a little-endian machine like Intel, packing those characters\r\ninto a 64-bit word puts the first letter, "b" (ASCII value 98), in the\r\nleast-significant byte. We take that integer modulo the array size (',(0,a.jsx)(t.span,{name:"power-of-two",children:"8"}),") to fit it in the bounds and get a bucket index, 2.\r\nThen we store the value there as usual."]}),"\n",(0,a.jsxs)(t.aside,{name:"power-of-two",children:["\n",(0,a.jsx)(t.p,{children:"I'm using powers of two for the array sizes here, but they don't need to be.\r\nSome styles of hash tables work best with powers of two, including the one we'll\r\nbuild in this book. Others prefer prime number array sizes or have other rules."}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["Using the array size as a modulus lets us map the key's numeric range down to\r\nfit an array of any size. We can thus control the number of buckets\r\nindependently of the key range. That solves our waste problem, but introduces a\r\nnew one. Any two variables whose key number has the same remainder when divided\r\nby the array size will end up in the same bucket. Keys can ",(0,a.jsx)(t.strong,{children:"collide"}),'. For\r\nexample, if we try to add "jam", it also ends up in bucket 2.']}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/collision.png",alt:"'Bagel' and 'jam' both end up in bucket index 2."}),"\n",(0,a.jsxs)(t.p,{children:["We have some control over this by tuning the array size. The bigger the array,\r\nthe fewer the indexes that get mapped to the same bucket and the fewer the\r\ncollisions that are likely to occur. Hash table implementers track this\r\ncollision likelihood by measuring the table's ",(0,a.jsx)(t.strong,{children:"load factor"}),". It's defined as\r\nthe number of entries divided by the number of buckets. So a hash table with\r\nfive entries and an array of 16 elements has a load factor of 0.3125. The higher\r\nthe load factor, the greater the chance of collisions."]}),"\n",(0,a.jsxs)(t.p,{children:["One way we mitigate collisions is by resizing the array. Just like the dynamic\r\narrays we implemented earlier, we reallocate and grow the hash table's array as\r\nit fills up. Unlike a regular dynamic array, though, we won't wait until the\r\narray is ",(0,a.jsx)(t.em,{children:"full"}),". Instead, we pick a desired load factor and grow the array when\r\nit goes over that."]}),"\n",(0,a.jsx)(t.h2,{id:"collision-resolution",children:"Collision Resolution"}),"\n",(0,a.jsxs)(t.p,{children:["Even with a very low load factor, collisions can still occur. The ",(0,a.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Birthday_problem",children:(0,a.jsx)(t.em,{children:"birthday\r\nparadox"})})," tells us that as the number of entries in the hash table\r\nincreases, the chance of collision increases very quickly. We can pick a large\r\narray size to reduce that, but it's a losing game. Say we wanted to store a\r\nhundred items in a hash table. To keep the chance of collision below a\r\nstill-pretty-high 10%, we need an array with at least 47,015 elements. To get\r\nthe chance below 1% requires an array with 492,555 elements, over 4,000 empty\r\nbuckets for each one in use."]}),"\n",(0,a.jsxs)(t.p,{children:["A low load factor can make collisions ",(0,a.jsx)(t.span,{name:"pigeon",children:"rarer"}),", but the\r\n",(0,a.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Pigeonhole_principle",children:(0,a.jsx)(t.em,{children:"pigeonhole principle"})})," tells us we can never eliminate them entirely.\r\nIf you've got five pet pigeons and four holes to put them in, at least one hole\r\nis going to end up with more than one pigeon. With 18,446,744,073,709,551,616\r\ndifferent variable names, any reasonably sized array can potentially end up with\r\nmultiple keys in the same bucket."]}),"\n",(0,a.jsxs)(t.p,{children:["Thus we still have to handle collisions gracefully when they occur. Users don't\r\nlike it when their programming language can look up variables correctly only\r\n",(0,a.jsx)(t.em,{children:"most"})," of the time."]}),"\n",(0,a.jsxs)(t.aside,{name:"pigeon",children:["\n",(0,a.jsx)(t.p,{children:"Put these two funny-named mathematical rules together and you get this\r\nobservation: Take a birdhouse containing 365 pigeonholes, and use each pigeon's\r\nbirthday to assign it to a pigeonhole. You'll need only about 26 randomly chosen\r\npigeons before you get a greater than 50% chance of two pigeons in the same box."}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/pigeons.png",alt:"Two pigeons in the same hole."}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"separate-chaining",children:"Separate chaining"}),"\n",(0,a.jsxs)(t.p,{children:["Techniques for resolving collisions fall into two broad categories. The first is\r\n",(0,a.jsx)(t.strong,{children:"separate chaining"}),". Instead of each bucket containing a single entry, we let\r\nit contain a collection of them. In the classic implementation, each bucket\r\npoints to a linked list of entries. To look up an entry, you find its bucket and\r\nthen walk the list until you find an entry with the matching key."]}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/chaining.png",alt:"An array with eight buckets. Bucket 2 links to a chain of two nodes. Bucket 5 links to a single node."}),"\n",(0,a.jsxs)(t.p,{children:["In catastrophically bad cases where every entry collides in the same bucket, the\r\ndata structure degrades into a single unsorted linked list with ",(0,a.jsx)(t.em,{children:"O(n)"})," lookup.\r\nIn practice, it's easy to avoid that by controlling the load factor and how\r\nentries get scattered across buckets. In typical separate-chained hash tables,\r\nit's rare for a bucket to have more than one or two entries."]}),"\n",(0,a.jsxs)(t.p,{children:["Separate chaining is conceptually simple -- it's literally an array of linked\r\nlists. Most operations are straightforward to implement, even deletion which, as\r\nwe'll see, can be a pain. But it's not a great fit for modern CPUs. It has a lot\r\nof overhead from pointers and tends to scatter little linked list ",(0,a.jsx)(t.span,{name:"node",children:"nodes"})," around in memory which isn't great for cache usage."]}),"\n",(0,a.jsxs)(t.aside,{name:"node",children:["\n",(0,a.jsx)(t.p,{children:"There are a few tricks to optimize this. Many implementations store the first\r\nentry right in the bucket so that in the common case where there's only one, no\r\nextra pointer indirection is needed. You can also make each linked list node\r\nstore a few entries to reduce the pointer overhead."}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"open-addressing",children:"Open addressing"}),"\n",(0,a.jsxs)(t.p,{children:["The other technique is ",(0,a.jsx)(t.span,{name:"open",children:"called"})," ",(0,a.jsx)(t.strong,{children:"open addressing"})," or\r\n(confusingly) ",(0,a.jsx)(t.strong,{children:"closed hashing"}),". With this technique, all entries live directly\r\nin the bucket array, with one entry per bucket. If two entries collide in the\r\nsame bucket, we find a different empty bucket to use instead."]}),"\n",(0,a.jsxs)(t.aside,{name:"open",children:["\n",(0,a.jsx)(t.p,{children:'It\'s called "open" addressing because the entry may end up at an address\r\n(bucket) outside of its preferred one. It\'s called "closed" hashing because all\r\nof the entries stay inside the array of buckets.'}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["Storing all entries in a single, big, contiguous array is great for keeping the\r\nmemory representation simple and fast. But it makes all of the operations on the\r\nhash table more complex. When inserting an entry, its bucket may be full,\r\nsending us to look at another bucket. That bucket itself may be occupied and so\r\non. This process of finding an available bucket is called ",(0,a.jsx)(t.strong,{children:"probing"}),", and the\r\norder that you examine buckets is a ",(0,a.jsx)(t.strong,{children:"probe sequence"}),"."]}),"\n",(0,a.jsxs)(t.p,{children:["There are a ",(0,a.jsx)(t.span,{name:"probe",children:"number"})," of algorithms for determining\r\nwhich buckets to probe and how to decide which entry goes in which bucket.\r\nThere's been a ton of research here because even slight tweaks can have a large\r\nperformance impact. And, on a data structure as heavily used as hash tables,\r\nthat performance impact touches a very large number of real-world programs\r\nacross a range of hardware capabilities."]}),"\n",(0,a.jsxs)(t.aside,{name:"probe",children:["\n",(0,a.jsx)(t.p,{children:'If you\'d like to learn more (and you should, because some of these are really\r\ncool), look into "double hashing", "cuckoo hashing", "Robin Hood hashing", and\r\nanything those lead you to.'}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["As usual in this book, we'll pick the simplest one that gets the job done\r\nefficiently. That's good old ",(0,a.jsx)(t.strong,{children:"linear probing"}),". When looking for an entry, we\r\nlook in the first bucket its key maps to. If it's not in there, we look in the\r\nvery next element in the array, and so on. If we reach the end, we wrap back\r\naround to the beginning."]}),"\n",(0,a.jsxs)(t.p,{children:["The good thing about linear probing is that it's cache friendly. Since you walk\r\nthe array directly in memory order, it keeps the CPU's cache lines full and\r\nhappy. The bad thing is that it's prone to ",(0,a.jsx)(t.strong,{children:"clustering"}),". If you have a lot of\r\nentries with numerically similar key values, you can end up with a lot of\r\ncolliding, overflowing buckets right next to each other."]}),"\n",(0,a.jsx)(t.p,{children:'Compared to separate chaining, open addressing can be harder to wrap your head\r\naround. I think of open addressing as similar to separate chaining except that\r\nthe "list" of nodes is threaded through the bucket array itself. Instead of\r\nstoring the links between them in pointers, the connections are calculated\r\nimplicitly by the order that you look through the buckets.'}),"\n",(0,a.jsx)(t.p,{children:"The tricky part is that more than one of these implicit lists may be interleaved\r\ntogether. Let's walk through an example that covers all the interesting cases.\r\nWe'll ignore values for now and just worry about a set of keys. We start with an\r\nempty array of 8 buckets."}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/insert-1.png",alt:"An array with eight empty buckets.",className:"wide"}),"\n",(0,a.jsx)(t.p,{children:'We decide to insert "bagel". The first letter, "b" (ASCII value 98), modulo the\r\narray size (8) puts it in bucket 2.'}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/insert-2.png",alt:"Bagel goes into bucket 2.",className:"wide"}),"\n",(0,a.jsx)(t.p,{children:"Next, we insert \"jam\". That also wants to go in bucket 2 (106 mod 8 = 2), but\r\nthat bucket's taken. We keep probing to the next bucket. It's empty, so we put\r\nit there."}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/insert-3.png",alt:"Jam goes into bucket 3, since 2 is full.",className:"wide"}),"\n",(0,a.jsx)(t.p,{children:'We insert "fruit", which happily lands in bucket 6.'}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/insert-4.png",alt:"Fruit goes into bucket 6.",className:"wide"}),"\n",(0,a.jsx)(t.p,{children:'Likewise, "migas" can go in its preferred bucket 5.'}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/insert-5.png",alt:"Migas goes into bucket 5.",className:"wide"}),"\n",(0,a.jsxs)(t.p,{children:['When we try to insert "eggs", it also wants to be in bucket 5. That\'s full, so we\r\nskip to 6. Bucket 6 is also full. Note that the entry in there is ',(0,a.jsx)(t.em,{children:"not"}),' part of\r\nthe same probe sequence. "Fruit" is in its preferred bucket, 6. So the 5 and 6\r\nsequences have collided and are interleaved. We skip over that and finally put\r\n"eggs" in bucket 7.']}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/insert-6.png",alt:"Eggs goes into bucket 7 because 5 and 6 are full.",className:"wide"}),"\n",(0,a.jsx)(t.p,{children:"We run into a similar problem with \"nuts\". It can't land in 6 like it wants to.\r\nNor can it go into 7. So we keep going. But we've reached the end of the array,\r\nso we wrap back around to 0 and put it there."}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/insert-7.png",alt:"Nuts wraps around to bucket 0 because 6 and 7 are full.",className:"wide"}),"\n",(0,a.jsx)(t.p,{children:'In practice, the interleaving turns out to not be much of a problem. Even in\r\nseparate chaining, we need to walk the list to check each entry\'s key because\r\nmultiple keys can reduce to the same bucket. With open addressing, we need to do\r\nthat same check, and that also covers the case where you are stepping over\r\nentries that "belong" to a different original bucket.'}),"\n",(0,a.jsx)(t.h2,{id:"hash-functions",children:"Hash Functions"}),"\n",(0,a.jsx)(t.p,{children:"We can now build ourselves a reasonably efficient table for storing variable\r\nnames up to eight characters long, but that limitation is still annoying. In\r\norder to relax the last constraint, we need a way to take a string of any length\r\nand convert it to a fixed-size integer."}),"\n",(0,a.jsxs)(t.p,{children:['Finally, we get to the "hash" part of "hash table". A ',(0,a.jsx)(t.strong,{children:"hash function"}),' takes\r\nsome larger blob of data and "hashes" it to produce a fixed-size integer ',(0,a.jsx)(t.strong,{children:"hash\r\ncode"})," whose value depends on all of the bits of the original data. A ",(0,a.jsx)(t.span,{name:"crypto",children:"good"})," hash function has three main goals:"]}),"\n",(0,a.jsxs)(t.aside,{name:"crypto",children:["\n",(0,a.jsxs)(t.p,{children:['Hash functions are also used for cryptography. In that domain, "good" has a\r\n',(0,a.jsx)(t.em,{children:"much"})," more stringent definition to avoid exposing details about the data being\r\nhashed. We, thankfully, don't need to worry about those concerns for this book."]}),"\n"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsxs)(t.strong,{children:["It must be ",(0,a.jsx)(t.em,{children:"deterministic"}),"."]})," The same input must always hash to the same\r\nnumber. If the same variable ends up in different buckets at different\r\npoints in time, it's gonna get really hard to find it."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsxs)(t.strong,{children:["It must be ",(0,a.jsx)(t.em,{children:"uniform"}),"."]})," Given a typical set of inputs, it should produce a\r\nwide and evenly distributed range of output numbers, with as few clumps or\r\npatterns as possible. We want it to ",(0,a.jsx)(t.span,{name:"scatter",children:"scatter"}),"\r\nvalues across the whole numeric range to minimize collisions and clustering."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsxs)(t.strong,{children:["It must be ",(0,a.jsx)(t.em,{children:"fast"}),"."]})," Every operation on the hash table requires us to hash\r\nthe key first. If hashing is slow, it can potentially cancel out the speed\r\nof the underlying array storage."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.aside,{name:"scatter",children:["\n",(0,a.jsx)(t.p,{children:'One of the original names for a hash table was "scatter table" because it takes\r\nthe entries and scatters them throughout the array. The word "hash" came from\r\nthe idea that a hash function takes the input data, chops it up, and tosses it\r\nall together into a pile to come up with a single number from all of those bits.'}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"There is a veritable pile of hash functions out there. Some are old and\r\noptimized for architectures no one uses anymore. Some are designed to be fast,\r\nothers cryptographically secure. Some take advantage of vector instructions and\r\ncache sizes for specific chips, others aim to maximize portability."}),"\n",(0,a.jsxs)(t.p,{children:["There are people out there for whom designing and evaluating hash functions is,\r\nlike, their ",(0,a.jsx)(t.em,{children:"jam"}),". I admire them, but I'm not mathematically astute enough to\r\n",(0,a.jsx)(t.em,{children:"be"})," one. So for clox, I picked a simple, well-worn hash function called\r\n",(0,a.jsx)(t.a,{href:"http://www.isthe.com/chongo/tech/comp/fnv/",children:"FNV-1a"})," that's served me fine over the years. Consider ",(0,a.jsx)(t.span,{name:"thing",children:"trying"})," out different ones in your code and see if they make\r\na difference."]}),"\n",(0,a.jsxs)(t.aside,{name:"thing",children:["\n",(0,a.jsx)(t.p,{children:"Who knows, maybe hash functions could turn out to be your thing too?"}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"OK, that's a quick run through of buckets, load factors, open addressing,\r\ncollision resolution, and hash functions. That's an awful lot of text and not a\r\nlot of real code. Don't worry if it still seems vague. Once we're done coding it\r\nup, it will all click into place."}),"\n",(0,a.jsx)(t.h2,{id:"building-a-hash-table",children:"Building a Hash Table"}),"\n",(0,a.jsx)(t.p,{children:"The great thing about hash tables compared to other classic techniques like\r\nbalanced search trees is that the actual data structure is so simple. Ours goes\r\ninto a new module."}),"\n",(0,a.jsx)(t.p,{children:"^code table-h"}),"\n",(0,a.jsxs)(t.p,{children:["A hash table is an array of entries. As in our dynamic array earlier, we keep\r\ntrack of both the allocated size of the array (",(0,a.jsx)(t.code,{children:"capacity"}),") and the number of\r\nkey/value pairs currently stored in it (",(0,a.jsx)(t.code,{children:"count"}),"). The ratio of count to capacity\r\nis exactly the load factor of the hash table."]}),"\n",(0,a.jsx)(t.p,{children:"Each entry is one of these:"}),"\n",(0,a.jsx)(t.p,{children:"^code entry (1 before, 2 after)"}),"\n",(0,a.jsxs)(t.p,{children:["It's a simple key/value pair. Since the key is always a ",(0,a.jsx)(t.span,{name:"string",children:"string"}),", we store the ObjString pointer directly instead of\r\nwrapping it in a Value. It's a little faster and smaller this way."]}),"\n",(0,a.jsxs)(t.aside,{name:"string",children:["\n",(0,a.jsx)(t.p,{children:"In clox, we only need to support keys that are strings. Handling other types of\r\nkeys doesn't add much complexity. As long as you can compare two objects for\r\nequality and reduce them to sequences of bits, it's easy to use them as hash\r\nkeys."}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"To create a new, empty hash table, we declare a constructor-like function."}),"\n",(0,a.jsx)(t.p,{children:"^code init-table-h (2 before, 2 after)"}),"\n",(0,a.jsx)(t.p,{children:"We need a new implementation file to define that. While we're at it, let's get\r\nall of the pesky includes out of the way."}),"\n",(0,a.jsx)(t.p,{children:"^code table-c"}),"\n",(0,a.jsxs)(t.p,{children:["As in our dynamic value array type, a hash table initially starts with zero\r\ncapacity and a ",(0,a.jsx)(t.code,{children:"NULL"})," array. We don't allocate anything until needed. Assuming\r\nwe do eventually allocate something, we need to be able to free it too."]}),"\n",(0,a.jsx)(t.p,{children:"^code free-table-h (1 before, 2 after)"}),"\n",(0,a.jsx)(t.p,{children:"And its glorious implementation:"}),"\n",(0,a.jsx)(t.p,{children:"^code free-table"}),"\n",(0,a.jsxs)(t.p,{children:["Again, it looks just like a dynamic array. In fact, you can think of a hash\r\ntable as basically a dynamic array with a really strange policy for inserting\r\nitems. We don't need to check for ",(0,a.jsx)(t.code,{children:"NULL"})," here since ",(0,a.jsx)(t.code,{children:"FREE_ARRAY()"})," already\r\nhandles that gracefully."]}),"\n",(0,a.jsx)(t.h3,{id:"hashing-strings",children:"Hashing strings"}),"\n",(0,a.jsx)(t.p,{children:"Before we can start putting entries in the table, we need to, well, hash them.\r\nTo ensure that the entries get distributed uniformly throughout the array, we\r\nwant a good hash function that looks at all of the bits of the key string. If it\r\nlooked at, say, only the first few characters, then a series of strings that all\r\nshared the same prefix would end up colliding in the same bucket."}),"\n",(0,a.jsx)(t.p,{children:"On the other hand, walking the entire string to calculate the hash is kind of\r\nslow. We'd lose some of the performance benefit of the hash table if we had to\r\nwalk the string every time we looked for a key in the table. So we'll do the\r\nobvious thing: cache it."}),"\n",(0,a.jsx)(t.p,{children:'Over in the "object" module in ObjString, we add:'}),"\n",(0,a.jsx)(t.p,{children:"^code obj-string-hash (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["Each ObjString stores the hash code for its string. Since strings are immutable\r\nin Lox, we can calculate the hash code once up front and be certain that it will\r\nnever get invalidated. Caching it eagerly makes a kind of sense: allocating the\r\nstring and copying its characters over is already an ",(0,a.jsx)(t.em,{children:"O(n)"})," operation, so it's a\r\ngood time to also do the ",(0,a.jsx)(t.em,{children:"O(n)"})," calculation of the string's hash."]}),"\n",(0,a.jsx)(t.p,{children:"Whenever we call the internal function to allocate a string, we pass in its\r\nhash code."}),"\n",(0,a.jsx)(t.p,{children:"^code allocate-string (1 after)"}),"\n",(0,a.jsx)(t.p,{children:"That function simply stores the hash in the struct."}),"\n",(0,a.jsx)(t.p,{children:"^code allocate-store-hash (1 before, 2 after)"}),"\n",(0,a.jsxs)(t.p,{children:["The fun happens over at the callers. ",(0,a.jsx)(t.code,{children:"allocateString()"})," is called from two\r\nplaces: the function that copies a string and the one that takes ownership of an\r\nexisting dynamically allocated string. We'll start with the first."]}),"\n",(0,a.jsx)(t.p,{children:"^code copy-string-hash (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"No magic here. We calculate the hash code and then pass it along."}),"\n",(0,a.jsx)(t.p,{children:"^code copy-string-allocate (2 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"The other string function is similar."}),"\n",(0,a.jsx)(t.p,{children:"^code take-string-hash (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"The interesting code is over here:"}),"\n",(0,a.jsx)(t.p,{children:"^code hash-string"}),"\n",(0,a.jsx)(t.p,{children:'This is the actual bona fide "hash function" in clox. The algorithm is called\r\n"FNV-1a", and is the shortest decent hash function I know. Brevity is certainly\r\na virtue in a book that aims to show you every line of code.'}),"\n",(0,a.jsx)(t.p,{children:"The basic idea is pretty simple, and many hash functions follow the same\r\npattern. You start with some initial hash value, usually a constant with certain\r\ncarefully chosen mathematical properties. Then you walk the data to be hashed.\r\nFor each byte (or sometimes word), you mix the bits into the hash value somehow,\r\nand then scramble the resulting bits around some."}),"\n",(0,a.jsxs)(t.p,{children:['What it means to "mix" and "scramble" can get pretty sophisticated. Ultimately,\r\nthough, the basic goal is ',(0,a.jsx)(t.em,{children:"uniformity"})," -- we want the resulting hash values to\r\nbe as widely scattered around the numeric range as possible to avoid collisions\r\nand clustering."]}),"\n",(0,a.jsx)(t.h3,{id:"inserting-entries",children:"Inserting entries"}),"\n",(0,a.jsx)(t.p,{children:"Now that string objects know their hash code, we can start putting them into\r\nhash tables."}),"\n",(0,a.jsx)(t.p,{children:"^code table-set-h (1 before, 2 after)"}),"\n",(0,a.jsxs)(t.p,{children:["This function adds the given key/value pair to the given hash table. If an entry\r\nfor that key is already present, the new value overwrites the old value. The\r\nfunction returns ",(0,a.jsx)(t.code,{children:"true"})," if a new entry was added. Here's the implementation:"]}),"\n",(0,a.jsx)(t.p,{children:"^code table-set"}),"\n",(0,a.jsxs)(t.p,{children:["Most of the interesting logic is in ",(0,a.jsx)(t.code,{children:"findEntry()"})," which we'll get to soon. That\r\nfunction's job is to take a key and figure out which bucket in the array it\r\nshould go in. It returns a pointer to that bucket -- the address of the Entry in\r\nthe array."]}),"\n",(0,a.jsx)(t.p,{children:"Once we have a bucket, inserting is straightforward. We update the hash table's\r\nsize, taking care to not increase the count if we overwrote the value for an\r\nalready-present key. Then we copy the key and value into the corresponding\r\nfields in the Entry."}),"\n",(0,a.jsx)(t.p,{children:"We're missing a little something here, though. We haven't actually allocated the\r\nEntry array yet. Oops! Before we can insert anything, we need to make sure we\r\nhave an array, and that it's big enough."}),"\n",(0,a.jsx)(t.p,{children:"^code table-set-grow (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["This is similar to the code we wrote a while back for growing a dynamic array.\r\nIf we don't have enough capacity to insert an item, we reallocate and grow the\r\narray. The ",(0,a.jsx)(t.code,{children:"GROW_CAPACITY()"})," macro takes an existing capacity and grows it by\r\na multiple to ensure that we get amortized constant performance over a series\r\nof inserts."]}),"\n",(0,a.jsxs)(t.p,{children:["The interesting difference here is that ",(0,a.jsx)(t.code,{children:"TABLE_MAX_LOAD"})," constant."]}),"\n",(0,a.jsx)(t.p,{children:"^code max-load (2 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["This is how we manage the table's ",(0,a.jsx)(t.span,{name:"75",children:"load"})," factor. We don't\r\ngrow when the capacity is completely full. Instead, we grow the array before\r\nthen, when the array becomes at least 75% full."]}),"\n",(0,a.jsxs)(t.aside,{name:"75",children:["\n",(0,a.jsx)(t.p,{children:"Ideal max load factor varies based on the hash function, collision-handling\r\nstrategy, and typical keysets you'll see. Since a toy language like Lox doesn't\r\nhave \"real world\" data sets, it's hard to optimize this, and I picked 75%\r\nsomewhat arbitrarily. When you build your own hash tables, benchmark and tune\r\nthis."}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["We'll get to the implementation of ",(0,a.jsx)(t.code,{children:"adjustCapacity()"})," soon. First, let's look\r\nat that ",(0,a.jsx)(t.code,{children:"findEntry()"})," function you've been wondering about."]}),"\n",(0,a.jsx)(t.p,{children:"^code find-entry"}),"\n",(0,a.jsxs)(t.p,{children:["This function is the real core of the hash table. It's responsible for taking a\r\nkey and an array of buckets, and figuring out which bucket the entry belongs in.\r\nThis function is also where linear probing and collision handling come into\r\nplay. We'll use ",(0,a.jsx)(t.code,{children:"findEntry()"})," both to look up existing entries in the hash\r\ntable and to decide where to insert new ones."]}),"\n",(0,a.jsx)(t.p,{children:"For all that, there isn't much to it. First, we use modulo to map the key's hash\r\ncode to an index within the array's bounds. That gives us a bucket index where,\r\nideally, we'll be able to find or place the entry."}),"\n",(0,a.jsx)(t.p,{children:"There are a few cases to check for:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:["If the key for the Entry at that array index is ",(0,a.jsx)(t.code,{children:"NULL"}),", then the bucket is\r\nempty. If we're using ",(0,a.jsx)(t.code,{children:"findEntry()"})," to look up something in the hash table,\r\nthis means it isn't there. If we're using it to insert, it means we've found\r\na place to add the new entry."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:["If the key in the bucket is ",(0,a.jsx)(t.span,{name:"equal",children:"equal"})," to the key we're\r\nlooking for, then that key is already present in the table. If we're doing a\r\nlookup, that's good -- we've found the key we seek. If we're doing an insert,\r\nthis means we'll be replacing the value for that key instead of adding a new\r\nentry."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.aside,{name:"equal",children:["\n",(0,a.jsxs)(t.p,{children:["It looks like we're using ",(0,a.jsx)(t.code,{children:"=="})," to see if two strings are equal. That doesn't\r\nwork, does it? There could be two copies of the same string at different places\r\nin memory. Fear not, astute reader. We'll solve this further on. And, strangely\r\nenough, it's a hash table that provides the tool we need."]}),"\n"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Otherwise, the bucket has an entry in it, but with a different key. This is\r\na collision. In that case, we start probing. That's what that ",(0,a.jsx)(t.code,{children:"for"})," loop\r\ndoes. We start at the bucket where the entry would ideally go. If that\r\nbucket is empty or has the same key, we're done. Otherwise, we advance to\r\nthe next element -- this is the ",(0,a.jsx)(t.em,{children:"linear"}),' part of "linear probing" -- and\r\ncheck there. If we go past the end of the array, that second modulo operator\r\nwraps us back around to the beginning.']}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["We exit the loop when we find either an empty bucket or a bucket with the same\r\nkey as the one we're looking for. You might be wondering about an infinite loop.\r\nWhat if we collide with ",(0,a.jsx)(t.em,{children:"every"})," bucket? Fortunately, that can't happen thanks to\r\nour load factor. Because we grow the array as soon as it gets close to being\r\nfull, we know there will always be empty buckets."]}),"\n",(0,a.jsxs)(t.p,{children:["We return directly from within the loop, yielding a pointer to the found Entry\r\nso the caller can either insert something into it or read from it. Way back in\r\n",(0,a.jsx)(t.code,{children:"tableSet()"}),", the function that first kicked this off, we store the new entry in\r\nthat returned bucket and we're done."]}),"\n",(0,a.jsx)(t.h3,{id:"allocating-and-resizing",children:"Allocating and resizing"}),"\n",(0,a.jsx)(t.p,{children:"Before we can put entries in the hash table, we do need a place to actually\r\nstore them. We need to allocate an array of buckets. That happens in this\r\nfunction:"}),"\n",(0,a.jsx)(t.p,{children:"^code table-adjust-capacity"}),"\n",(0,a.jsxs)(t.p,{children:["We create a bucket array with ",(0,a.jsx)(t.code,{children:"capacity"})," entries. After we allocate the array,\r\nwe initialize every element to be an empty bucket and then store the array (and\r\nits capacity) in the hash table's main struct. This code is fine for when we\r\ninsert the very first entry into the table, and we require the first allocation\r\nof the array. But what about when we already have one and we need to grow it?"]}),"\n",(0,a.jsxs)(t.p,{children:["Back when we were doing a dynamic array, we could just use ",(0,a.jsx)(t.code,{children:"realloc()"})," and let\r\nthe C standard library copy everything over. That doesn't work for a hash table.\r\nRemember that to choose the bucket for each entry, we take its hash key ",(0,a.jsx)(t.em,{children:"modulo\r\nthe array size"}),". That means that when the array size changes, entries may end up\r\nin different buckets."]}),"\n",(0,a.jsx)(t.p,{children:"Those new buckets may have new collisions that we need to deal with. So the\r\nsimplest way to get every entry where it belongs is to rebuild the table from\r\nscratch by re-inserting every entry into the new empty array."}),"\n",(0,a.jsx)(t.p,{children:"^code re-hash (2 before, 2 after)"}),"\n",(0,a.jsxs)(t.p,{children:["We walk through the old array front to back. Any time we find a non-empty\r\nbucket, we insert that entry into the new array. We use ",(0,a.jsx)(t.code,{children:"findEntry()"}),", passing\r\nin the ",(0,a.jsx)(t.em,{children:"new"})," array instead of the one currently stored in the Table. (This is\r\nwhy ",(0,a.jsx)(t.code,{children:"findEntry()"})," takes a pointer directly to an Entry array and not the whole\r\n",(0,a.jsx)(t.code,{children:"Table"})," struct. That way, we can pass the new array and capacity before we've\r\nstored those in the struct.)"]}),"\n",(0,a.jsx)(t.p,{children:"After that's done, we can release the memory for the old array."}),"\n",(0,a.jsx)(t.p,{children:"^code free-old-array (3 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"With that, we have a hash table that we can stuff as many entries into as we\r\nlike. It handles overwriting existing keys and growing itself as needed to\r\nmaintain the desired load capacity."}),"\n",(0,a.jsx)(t.p,{children:"While we're at it, let's also define a helper function for copying all of the\r\nentries of one hash table into another."}),"\n",(0,a.jsx)(t.p,{children:"^code table-add-all-h (1 before, 2 after)"}),"\n",(0,a.jsx)(t.p,{children:"We won't need this until much later when we support method inheritance, but we\r\nmay as well implement it now while we've got all the hash table stuff fresh in\r\nour minds."}),"\n",(0,a.jsx)(t.p,{children:"^code table-add-all"}),"\n",(0,a.jsxs)(t.p,{children:["There's not much to say about this. It walks the bucket array of the source hash\r\ntable. Whenever it finds a non-empty bucket, it adds the entry to the\r\ndestination hash table using the ",(0,a.jsx)(t.code,{children:"tableSet()"})," function we recently defined."]}),"\n",(0,a.jsx)(t.h3,{id:"retrieving-values",children:"Retrieving values"}),"\n",(0,a.jsx)(t.p,{children:"Now that our hash table contains some stuff, let's start pulling things back\r\nout. Given a key, we can look up the corresponding value, if there is one, with\r\nthis function:"}),"\n",(0,a.jsx)(t.p,{children:"^code table-get-h (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["You pass in a table and a key. If it finds an entry with that key, it returns\r\n",(0,a.jsx)(t.code,{children:"true"}),", otherwise it returns ",(0,a.jsx)(t.code,{children:"false"}),". If the entry exists, the ",(0,a.jsx)(t.code,{children:"value"})," output\r\nparameter points to the resulting value."]}),"\n",(0,a.jsxs)(t.p,{children:["Since ",(0,a.jsx)(t.code,{children:"findEntry()"})," already does the hard work, the implementation isn't bad."]}),"\n",(0,a.jsx)(t.p,{children:"^code table-get"}),"\n",(0,a.jsxs)(t.p,{children:["If the table is completely empty, we definitely won't find the entry, so we\r\ncheck for that first. This isn't just an optimization -- it also ensures that we\r\ndon't try to access the bucket array when the array is ",(0,a.jsx)(t.code,{children:"NULL"}),". Otherwise, we let\r\n",(0,a.jsx)(t.code,{children:"findEntry()"})," work its magic. That returns a pointer to a bucket. If the bucket\r\nis empty, which we detect by seeing if the key is ",(0,a.jsx)(t.code,{children:"NULL"}),", then we didn't find an\r\nEntry with our key. If ",(0,a.jsx)(t.code,{children:"findEntry()"})," does return a non-empty Entry, then that's\r\nour match. We take the Entry's value and copy it to the output parameter so the\r\ncaller can get it. Piece of cake."]}),"\n",(0,a.jsx)(t.h3,{id:"deleting-entries",children:"Deleting entries"}),"\n",(0,a.jsxs)(t.p,{children:["There is one more fundamental operation a full-featured hash table needs to\r\nsupport: removing an entry. This seems pretty obvious, if you can add things,\r\nyou should be able to ",(0,a.jsx)(t.em,{children:"un"}),"-add them, right? But you'd be surprised how many\r\ntutorials on hash tables omit this."]}),"\n",(0,a.jsxs)(t.p,{children:["I could have taken that route too. In fact, we use deletion in clox only in a\r\ntiny edge case in the VM. But if you want to actually understand how to\r\ncompletely implement a hash table, this feels important. I can sympathize with\r\ntheir desire to overlook it. As we'll see, deleting from a hash table that uses\r\n",(0,a.jsx)(t.span,{name:"delete",children:"open"})," addressing is tricky."]}),"\n",(0,a.jsxs)(t.aside,{name:"delete",children:["\n",(0,a.jsx)(t.p,{children:"With separate chaining, deleting is as easy as removing a node from a linked\r\nlist."}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"At least the declaration is simple."}),"\n",(0,a.jsx)(t.p,{children:"^code table-delete-h (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["The obvious approach is to mirror insertion. Use ",(0,a.jsx)(t.code,{children:"findEntry()"})," to look up the\r\nentry's bucket. Then clear out the bucket. Done!"]}),"\n",(0,a.jsx)(t.p,{children:"In cases where there are no collisions, that works fine. But if a collision has\r\noccurred, then the bucket where the entry lives may be part of one or more\r\nimplicit probe sequences. For example, here's a hash table containing three keys\r\nall with the same preferred bucket, 2:"}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/delete-1.png",alt:"A hash table containing 'bagel' in bucket 2, 'biscuit' in bucket 3, and 'jam' in bucket 4."}),"\n",(0,a.jsx)(t.p,{children:"Remember that when we're walking a probe sequence to find an entry, we know\r\nwe've reached the end of a sequence and that the entry isn't present when we hit\r\nan empty bucket. It's like the probe sequence is a list of entries and an empty\r\nentry terminates that list."}),"\n",(0,a.jsx)(t.p,{children:'If we delete "biscuit" by simply clearing the Entry, then we break that probe\r\nsequence in the middle, leaving the trailing entries orphaned and unreachable.\r\nSort of like removing a node from a linked list without relinking the pointer\r\nfrom the previous node to the next one.'}),"\n",(0,a.jsx)(t.p,{children:'If we later try to look for "jam", we\'d start at "bagel", stop at the next\r\nempty Entry, and never find it.'}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/delete-2.png",alt:"The 'biscuit' entry has been deleted from the hash table, breaking the chain."}),"\n",(0,a.jsxs)(t.p,{children:["To solve this, most implementations use a trick called ",(0,a.jsx)(t.span,{name:"tombstone",children:(0,a.jsx)(t.strong,{children:"tombstones"})}),'. Instead of clearing the entry on\r\ndeletion, we replace it with a special sentinel entry called a "tombstone". When\r\nwe are following a probe sequence during a lookup, and we hit a tombstone, we\r\n',(0,a.jsx)(t.em,{children:"don't"})," treat it like an empty slot and stop iterating. Instead, we keep going\r\nso that deleting an entry doesn't break any implicit collision chains and we can\r\nstill find entries after it."]}),"\n",(0,a.jsx)(t.img,{src:"image/hash-tables/delete-3.png",alt:"Instead of deleting 'biscuit', it's replaced with a tombstone."}),"\n",(0,a.jsx)(t.p,{children:"The code looks like this:"}),"\n",(0,a.jsx)(t.p,{children:"^code table-delete"}),"\n",(0,a.jsxs)(t.p,{children:["First, we find the bucket containing the entry we want to delete. (If we don't\r\nfind it, there's nothing to delete, so we bail out.) We replace the entry with a\r\ntombstone. In clox, we use a ",(0,a.jsx)(t.code,{children:"NULL"})," key and a ",(0,a.jsx)(t.code,{children:"true"})," value to represent that,\r\nbut any representation that can't be confused with an empty bucket or a valid\r\nentry works."]}),"\n",(0,a.jsxs)(t.aside,{name:"tombstone",children:["\n",(0,a.jsx)(t.img,{src:"image/hash-tables/tombstone.png",alt:"A tombstone enscribed 'Here lies entry biscuit \u2192 3.75, gone but not deleted'."}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:'That\'s all we need to do to delete an entry. Simple and fast. But all of the\r\nother operations need to correctly handle tombstones too. A tombstone is a sort\r\nof "half" entry. It has some of the characteristics of a present entry, and some\r\nof the characteristics of an empty one.'}),"\n",(0,a.jsx)(t.p,{children:"When we are following a probe sequence during a lookup, and we hit a tombstone,\r\nwe note it and keep going."}),"\n",(0,a.jsx)(t.p,{children:"^code find-tombstone (2 before, 2 after)"}),"\n",(0,a.jsx)(t.p,{children:"The first time we pass a tombstone, we store it in this local variable:"}),"\n",(0,a.jsx)(t.p,{children:"^code find-entry-tombstone (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["If we reach a truly empty entry, then the key isn't present. In that case, if we\r\nhave passed a tombstone, we return its bucket instead of the later empty one. If\r\nwe're calling ",(0,a.jsx)(t.code,{children:"findEntry()"})," in order to insert a node, that lets us treat the\r\ntombstone bucket as empty and reuse it for the new entry."]}),"\n",(0,a.jsx)(t.p,{children:"Reusing tombstone slots automatically like this helps reduce the number of\r\ntombstones wasting space in the bucket array. In typical use cases where there\r\nis a mixture of insertions and deletions, the number of tombstones grows for a\r\nwhile and then tends to stabilize."}),"\n",(0,a.jsxs)(t.p,{children:["Even so, there's no guarantee that a large number of deletes won't cause the\r\narray to be full of tombstones. In the very worst case, we could end up with\r\n",(0,a.jsx)(t.em,{children:"no"})," empty buckets. That would be bad because, remember, the only thing\r\npreventing an infinite loop in ",(0,a.jsx)(t.code,{children:"findEntry()"})," is the assumption that we'll\r\neventually hit an empty bucket."]}),"\n",(0,a.jsx)(t.p,{children:"So we need to be thoughtful about how tombstones interact with the table's load\r\nfactor and resizing. The key question is, when calculating the load factor,\r\nshould we treat tombstones like full buckets or empty ones?"}),"\n",(0,a.jsx)(t.h3,{id:"counting-tombstones",children:"Counting tombstones"}),"\n",(0,a.jsx)(t.p,{children:"If we treat tombstones like full buckets, then we may end up with a bigger array\r\nthan we probably need because it artificially inflates the load factor. There\r\nare tombstones we could reuse, but they aren't treated as unused so we end up\r\ngrowing the array prematurely."}),"\n",(0,a.jsxs)(t.p,{children:["But if we treat tombstones like empty buckets and ",(0,a.jsx)(t.em,{children:"don't"})," include them in the\r\nload factor, then we run the risk of ending up with ",(0,a.jsx)(t.em,{children:"no"})," actual empty buckets to\r\nterminate a lookup. An infinite loop is a much worse problem than a few extra\r\narray slots, so for load factor, we consider tombstones to be full buckets."]}),"\n",(0,a.jsx)(t.p,{children:"That's why we don't reduce the count when deleting an entry in the previous\r\ncode. The count is no longer the number of entries in the hash table, it's the\r\nnumber of entries plus tombstones. That implies that we increment the count\r\nduring insertion only if the new entry goes into an entirely empty bucket."}),"\n",(0,a.jsx)(t.p,{children:"^code set-increment-count (1 before, 2 after)"}),"\n",(0,a.jsx)(t.p,{children:"If we are replacing a tombstone with a new entry, the bucket has already been\r\naccounted for and the count doesn't change."}),"\n",(0,a.jsxs)(t.p,{children:["When we resize the array, we allocate a new array and re-insert all of the\r\nexisting entries into it. During that process, we ",(0,a.jsx)(t.em,{children:"don't"})," copy the tombstones\r\nover. They don't add any value since we're rebuilding the probe sequences\r\nanyway, and would just slow down lookups. That means we need to recalculate the\r\ncount since it may change during a resize. So we clear it out:"]}),"\n",(0,a.jsx)(t.p,{children:"^code resize-init-count (2 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"Then each time we find a non-tombstone entry, we increment it."}),"\n",(0,a.jsx)(t.p,{children:"^code resize-increment-count (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["This means that when we grow the capacity, we may end up with ",(0,a.jsx)(t.em,{children:"fewer"})," entries in\r\nthe resulting larger array because all of the tombstones get discarded. That's a\r\nlittle wasteful, but not a huge practical problem."]}),"\n",(0,a.jsxs)(t.p,{children:["I find it interesting that much of the work to support deleting entries is in\r\n",(0,a.jsx)(t.code,{children:"findEntry()"})," and ",(0,a.jsx)(t.code,{children:"adjustCapacity()"}),". The actual delete logic is quite simple\r\nand fast. In practice, deletions tend to be rare, so you'd expect a hash table\r\nto do as much work as it can in the delete function and leave the other\r\nfunctions alone to keep them faster. With our tombstone approach, deletes are\r\nfast, but lookups get penalized."]}),"\n",(0,a.jsx)(t.p,{children:"I did a little benchmarking to test this out in a few different deletion\r\nscenarios. I was surprised to discover that tombstones did end up being faster\r\noverall compared to doing all the work during deletion to reinsert the affected\r\nentries."}),"\n",(0,a.jsxs)(t.p,{children:["But if you think about it, it's not that the tombstone approach pushes the work\r\nof fully deleting an entry to other operations, it's more that it makes deleting\r\n",(0,a.jsx)(t.em,{children:"lazy"}),". At first, it does the minimal work to turn the entry into a tombstone.\r\nThat can cause a penalty when later lookups have to skip over it. But it also\r\nallows that tombstone bucket to be reused by a later insert too. That reuse is a\r\nvery efficient way to avoid the cost of rearranging all of the following\r\naffected entries. You basically recycle a node in the chain of probed entries.\r\nIt's a neat trick."]}),"\n",(0,a.jsx)(t.h2,{id:"string-interning",children:"String Interning"}),"\n",(0,a.jsx)(t.p,{children:"We've got ourselves a hash table that mostly works, though it has a critical\r\nflaw in its center. Also, we aren't using it for anything yet. It's time to\r\naddress both of those and, in the process, learn a classic technique used by\r\ninterpreters."}),"\n",(0,a.jsxs)(t.p,{children:["The reason the hash table doesn't totally work is that when ",(0,a.jsx)(t.code,{children:"findEntry()"})," checks\r\nto see if an existing key matches the one it's looking for, it uses ",(0,a.jsx)(t.code,{children:"=="})," to\r\ncompare two strings for equality. That only returns true if the two keys are the\r\nexact same string in memory. Two separate strings with the same characters\r\nshould be considered equal, but aren't."]}),"\n",(0,a.jsxs)(t.p,{children:["Remember, back when we added strings in the last chapter, we added ",(0,a.jsx)(t.a,{href:"strings.html#operations-on-strings",children:"explicit\r\nsupport to compare the strings character-by-character"})," in order to get\r\ntrue value equality. We could do that in ",(0,a.jsx)(t.code,{children:"findEntry()"}),", but that's ",(0,a.jsx)(t.span,{name:"hash-collision",children:"slow"}),"."]}),"\n",(0,a.jsxs)(t.aside,{name:"hash-collision",children:["\n",(0,a.jsx)(t.p,{children:"In practice, we would first compare the hash codes of the two strings. That\r\nquickly detects almost all different strings -- it wouldn't be a very good hash\r\nfunction if it didn't. But when the two hashes are the same, we still have to\r\ncompare characters to make sure we didn't have a hash collision on different\r\nstrings."}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["Instead, we'll use a technique called ",(0,a.jsx)(t.strong,{children:"string interning"}),". The core problem is\r\nthat it's possible to have different strings in memory with the same characters.\r\nThose need to behave like equivalent values even though they are distinct\r\nobjects. They're essentially duplicates, and we have to compare all of their\r\nbytes to detect that."]}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.span,{name:"intern",children:"String interning"}),' is a process of deduplication. We\r\ncreate a collection of "interned" strings. Any string in that collection is\r\nguaranteed to be textually distinct from all others. When you intern a string,\r\nyou look for a matching string in the collection. If found, you use that\r\noriginal one. Otherwise, the string you have is unique, so you add it to the\r\ncollection.']}),"\n",(0,a.jsxs)(t.aside,{name:"intern",children:["\n",(0,a.jsx)(t.p,{children:'I\'m guessing "intern" is short for "internal". I think the idea is that the\r\nlanguage\'s runtime keeps its own "internal" collection of these strings, whereas\r\nother strings could be user created and floating around in memory. When you\r\nintern a string, you ask the runtime to add the string to that internal\r\ncollection and return a pointer to it.'}),"\n",(0,a.jsxs)(t.p,{children:["Languages vary in how much string interning they do and how it's exposed to the\r\nuser. Lua interns ",(0,a.jsx)(t.em,{children:"all"}),' strings, which is what clox will do too. Lisp, Scheme,\r\nSmalltalk, Ruby and others have a separate string-like type called "symbol" that\r\nis implicitly interned. (This is why they say symbols are "faster" in Ruby.)\r\nJava interns constant strings by default, and provides an API to let you\r\nexplicitly intern any string you give it.']}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"In this way, you know that each sequence of characters is represented by only\r\none string in memory. This makes value equality trivial. If two strings point\r\nto the same address in memory, they are obviously the same string and must be\r\nequal. And, because we know strings are unique, if two strings point to\r\ndifferent addresses, they must be distinct strings."}),"\n",(0,a.jsxs)(t.p,{children:["Thus, pointer equality exactly matches value equality. Which in turn means that\r\nour existing ",(0,a.jsx)(t.code,{children:"=="})," in ",(0,a.jsx)(t.code,{children:"findEntry()"})," does the right thing. Or, at least, it will\r\nonce we intern all the strings. In order to reliably deduplicate all strings,\r\nthe VM needs to be able to find every string that's created. We do that by\r\ngiving it a hash table to store them all."]}),"\n",(0,a.jsx)(t.p,{children:"^code vm-strings (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"As usual, we need an include."}),"\n",(0,a.jsx)(t.p,{children:"^code vm-include-table (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"When we spin up a new VM, the string table is empty."}),"\n",(0,a.jsx)(t.p,{children:"^code init-strings (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"And when we shut down the VM, we clean up any resources used by the table."}),"\n",(0,a.jsx)(t.p,{children:"^code free-strings (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"Some languages have a separate type or an explicit step to intern a string. For\r\nclox, we'll automatically intern every one. That means whenever we create a new\r\nunique string, we add it to the table."}),"\n",(0,a.jsx)(t.p,{children:"^code allocate-store-string (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["We're using the table more like a hash ",(0,a.jsx)(t.em,{children:"set"})," than a hash ",(0,a.jsx)(t.em,{children:"table"}),". The keys are\r\nthe strings and those are all we care about, so we just use ",(0,a.jsx)(t.code,{children:"nil"})," for the\r\nvalues."]}),"\n",(0,a.jsxs)(t.p,{children:["This gets a string into the table assuming that it's unique, but we need to\r\nactually check for duplication before we get here. We do that in the two\r\nhigher-level functions that call ",(0,a.jsx)(t.code,{children:"allocateString()"}),". Here's one:"]}),"\n",(0,a.jsx)(t.p,{children:"^code copy-string-intern (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:'When copying a string into a new LoxString, we look it up in the string table\r\nfirst. If we find it, instead of "copying", we just return a reference to that\r\nstring. Otherwise, we fall through, allocate a new string, and store it in the\r\nstring table.'}),"\n",(0,a.jsx)(t.p,{children:"Taking ownership of a string is a little different."}),"\n",(0,a.jsx)(t.p,{children:"^code take-string-intern (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"Again, we look up the string in the string table first. If we find it, before we\r\nreturn it, we free the memory for the string that was passed in. Since ownership\r\nis being passed to this function and we no longer need the duplicate string,\r\nit's up to us to free it."}),"\n",(0,a.jsx)(t.p,{children:"Before we get to the new function we need to write, there's one more include."}),"\n",(0,a.jsx)(t.p,{children:"^code object-include-table (1 before, 1 after)"}),"\n",(0,a.jsxs)(t.p,{children:["To look for a string in the table, we can't use the normal ",(0,a.jsx)(t.code,{children:"tableGet()"})," function\r\nbecause that calls ",(0,a.jsx)(t.code,{children:"findEntry()"}),", which has the exact problem with duplicate\r\nstrings that we're trying to fix right now. Instead, we use this new function:"]}),"\n",(0,a.jsx)(t.p,{children:"^code table-find-string-h (1 before, 2 after)"}),"\n",(0,a.jsx)(t.p,{children:"The implementation looks like so:"}),"\n",(0,a.jsx)(t.p,{children:"^code table-find-string"}),"\n",(0,a.jsxs)(t.p,{children:["It appears we have copy-pasted ",(0,a.jsx)(t.code,{children:"findEntry()"}),". There is a lot of redundancy, but\r\nalso a couple of key differences. First, we pass in the raw character array of\r\nthe key we're looking for instead of an ObjString. At the point that we call\r\nthis, we haven't created an ObjString yet."]}),"\n",(0,a.jsx)(t.p,{children:"Second, when checking to see if we found the key, we look at the actual strings.\r\nWe first see if they have matching lengths and hashes. Those are quick to check\r\nand if they aren't equal, the strings definitely aren't the same."}),"\n",(0,a.jsx)(t.p,{children:"If there is a hash collision, we do an actual character-by-character string\r\ncomparison. This is the one place in the VM where we actually test strings for\r\ntextual equality. We do it here to deduplicate strings and then the rest of the\r\nVM can take for granted that any two strings at different addresses in memory\r\nmust have different contents."}),"\n",(0,a.jsxs)(t.p,{children:["In fact, now that we've interned all the strings, we can take advantage of it in\r\nthe bytecode interpreter. When a user does ",(0,a.jsx)(t.code,{children:"=="})," on two objects that happen to be\r\nstrings, we don't need to test the characters any more."]}),"\n",(0,a.jsx)(t.p,{children:"^code equal (1 before, 1 after)"}),"\n",(0,a.jsx)(t.p,{children:"We've added a little overhead when creating strings to intern them. But in\r\nreturn, at runtime, the equality operator on strings is much faster. With that,\r\nwe have a full-featured hash table ready for us to use for tracking variables,\r\ninstances, or any other key-value pairs that might show up."}),"\n",(0,a.jsxs)(t.p,{children:["We also sped up testing strings for equality. This is nice for when the user\r\ndoes ",(0,a.jsx)(t.code,{children:"=="})," on strings. But it's even more critical in a dynamically typed\r\nlanguage like Lox where method calls and instance fields are looked up by name\r\nat runtime. If testing a string for equality is slow, then that means looking up\r\na method by name is slow. And if ",(0,a.jsx)(t.em,{children:"that's"})," slow in your object-oriented language,\r\nthen ",(0,a.jsx)(t.em,{children:"everything"})," is slow."]}),"\n",(0,a.jsxs)(t.div,{className:"challenges",children:["\n",(0,a.jsx)(t.h2,{id:"challenges",children:"Challenges"}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In clox, we happen to only need keys that are strings, so the hash table we\r\nbuilt is hardcoded for that key type. If we exposed hash tables to Lox users\r\nas a first-class collection, it would be useful to support different kinds\r\nof keys."}),"\n",(0,a.jsxs)(t.p,{children:["Add support for keys of the other primitive types: numbers, Booleans, and\r\n",(0,a.jsx)(t.code,{children:"nil"}),". Later, clox will support user-defined classes. If we want to support\r\nkeys that are instances of those classes, what kind of complexity does that\r\nadd?"]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Hash tables have a lot of knobs you can tweak that affect their performance.\r\nYou decide whether to use separate chaining or open addressing. Depending on\r\nwhich fork in that road you take, you can tune how many entries are stored\r\nin each node, or the probing strategy you use. You control the hash\r\nfunction, load factor, and growth rate."}),"\n",(0,a.jsxs)(t.p,{children:["All of this variety wasn't created just to give CS doctoral candidates\r\nsomething to ",(0,a.jsx)(t.span,{name:"publish",children:"publish"})," theses on: each has its\r\nuses in the many varied domains and hardware scenarios where hashing comes\r\ninto play. Look up a few hash table implementations in different open source\r\nsystems, research the choices they made, and try to figure out why they did\r\nthings that way."]}),"\n",(0,a.jsxs)(t.aside,{name:"publish",children:["\n",(0,a.jsxs)(t.p,{children:["Well, at least that wasn't the ",(0,a.jsx)(t.em,{children:"only"})," reason they were created. Whether that\r\nwas the ",(0,a.jsx)(t.em,{children:"main"})," reason is up for debate."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Benchmarking a hash table is notoriously difficult. A hash table\r\nimplementation may perform well with some keysets and poorly with others. It\r\nmay work well at small sizes but degrade as it grows, or vice versa. It may\r\nchoke when deletions are common, but fly when they aren't. Creating\r\nbenchmarks that accurately represent how your users will use the hash table\r\nis a challenge."}),"\n",(0,a.jsx)(t.p,{children:"Write a handful of different benchmark programs to validate our hash table\r\nimplementation. How does the performance vary between them? Why did you\r\nchoose the specific test cases you chose?"}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>o});var a=n(6540);const r={},s=a.createContext(r);function i(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);