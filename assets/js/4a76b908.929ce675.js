"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[6374],{7468:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var r=t(4848),s=t(8453);const a={},i=void 0,o={id:"Craftinginterpreters/not-translated-yet/scanning-on-demand",title:"scanning-on-demand",description:"Literature is idiosyncratic arrangements in horizontal lines in only",source:"@site/docs/Craftinginterpreters/not-translated-yet/scanning-on-demand.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/scanning-on-demand",permalink:"/docs/Craftinginterpreters/not-translated-yet/scanning-on-demand",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/scanning-on-demand.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"resolving-and-binding",permalink:"/docs/Craftinginterpreters/not-translated-yet/resolving-and-binding"},next:{title:"scanning",permalink:"/docs/Craftinginterpreters/not-translated-yet/scanning"}},h={},l=[{value:"Spinning Up the Interpreter",id:"spinning-up-the-interpreter",level:2},{value:"Opening the compilation pipeline",id:"opening-the-compilation-pipeline",level:3},{value:"The scanner scans",id:"the-scanner-scans",level:3},{value:"A Token at a Time",id:"a-token-at-a-time",level:2},{value:"Scanning tokens",id:"scanning-tokens",level:3},{value:"A Lexical Grammar for Lox",id:"a-lexical-grammar-for-lox",level:2},{value:"Whitespace",id:"whitespace",level:3},{value:"Comments",id:"comments",level:3},{value:"Literal tokens",id:"literal-tokens",level:3},{value:"Identifiers and Keywords",id:"identifiers-and-keywords",level:2},{value:"Tries and state machines",id:"tries-and-state-machines",level:3},{value:"Challenges",id:"challenges",level:2}];function c(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"Literature is idiosyncratic arrangements in horizontal lines in only\r\ntwenty-six phonetic symbols, ten Arabic numbers, and about eight punctuation\r\nmarks."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.cite,{children:["Kurt Vonnegut, ",(0,r.jsx)(n.em,{children:"Like Shaking Hands With God: A Conversation about Writing"})]})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Our second interpreter, clox, has three phases -- scanner, compiler, and virtual\r\nmachine. A data structure joins each pair of phases. Tokens flow from scanner to\r\ncompiler, and chunks of bytecode from compiler to VM. We began our\r\nimplementation near the end with ",(0,r.jsx)(n.a,{href:"chunks-of-bytecode.html",children:"chunks"})," and the ",(0,r.jsx)(n.a,{href:"a-virtual-machine.html",children:"VM"}),". Now, we're going to\r\nhop back to the beginning and build a scanner that makes tokens. In the\r\n",(0,r.jsx)(n.a,{href:"compiling-expressions.html",children:"next chapter"}),", we'll tie the two ends together with our bytecode compiler."]}),"\n",(0,r.jsx)(n.img,{src:"image/scanning-on-demand/pipeline.png",alt:"Source code \u2192 scanner \u2192 tokens \u2192 compiler \u2192 bytecode chunk \u2192 VM."}),"\n",(0,r.jsx)(n.p,{children:"I'll admit, this is not the most exciting chapter in the book. With two\r\nimplementations of the same language, there's bound to be some redundancy. I did\r\nsneak in a few interesting differences compared to jlox's scanner. Read on to\r\nsee what they are."}),"\n",(0,r.jsx)(n.h2,{id:"spinning-up-the-interpreter",children:"Spinning Up the Interpreter"}),"\n",(0,r.jsxs)(n.p,{children:["Now that we're building the front end, we can get clox running like a real\r\ninterpreter. No more hand-authored chunks of bytecode. It's time for a REPL and\r\nscript loading. Tear out most of the code in ",(0,r.jsx)(n.code,{children:"main()"})," and replace it with:"]}),"\n",(0,r.jsx)(n.p,{children:"^code args (3 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["If you pass ",(0,r.jsx)(n.span,{name:"args",children:"no arguments"})," to the executable, you are\r\ndropped into the REPL. A single command line argument is understood to be the\r\npath to a script to run."]}),"\n",(0,r.jsxs)(n.aside,{name:"args",children:["\n",(0,r.jsxs)(n.p,{children:["The code tests for one and two arguments, not zero and one, because the first\r\nargument in ",(0,r.jsx)(n.code,{children:"argv"})," is always the name of the executable being run."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"We'll need a few system headers, so let's get them all out of the way."}),"\n",(0,r.jsx)(n.p,{children:"^code main-includes (1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Next, we get the REPL up and REPL-ing."}),"\n",(0,r.jsx)(n.p,{children:"^code repl (1 before)"}),"\n",(0,r.jsx)(n.p,{children:"A quality REPL handles input that spans multiple lines gracefully and doesn't\r\nhave a hardcoded line length limit. This REPL here is a little more, ahem,\r\naustere, but it's fine for our purposes."}),"\n",(0,r.jsxs)(n.p,{children:["The real work happens in ",(0,r.jsx)(n.code,{children:"interpret()"}),". We'll get to that soon, but first let's\r\ntake care of loading scripts."]}),"\n",(0,r.jsx)(n.p,{children:"^code run-file"}),"\n",(0,r.jsx)(n.p,{children:"We read the file and execute the resulting string of Lox source code. Then,\r\nbased on the result of that, we set the exit code appropriately because we're\r\nscrupulous tool builders and care about little details like that."}),"\n",(0,r.jsxs)(n.p,{children:["We also need to free the source code string because ",(0,r.jsx)(n.code,{children:"readFile()"})," dynamically\r\nallocates it and passes ownership to its caller. That function looks like this:"]}),"\n",(0,r.jsxs)(n.aside,{name:"owner",children:["\n",(0,r.jsxs)(n.p,{children:["C asks us not just to manage memory explicitly, but ",(0,r.jsx)(n.em,{children:"mentally"}),". We programmers\r\nhave to remember the ownership rules and hand-implement them throughout the\r\nprogram. Java just does it for us. C++ gives us tools to encode the policy\r\ndirectly so that the compiler validates it for us."]}),"\n",(0,r.jsx)(n.p,{children:"I like C's simplicity, but we pay a real price for it -- the language requires\r\nus to be more conscientious."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code read-file"}),"\n",(0,r.jsx)(n.p,{children:"Like a lot of C code, it takes more effort than it seems like it should,\r\nespecially for a language expressly designed for operating systems. The\r\ndifficult part is that we want to allocate a big enough string to read the whole\r\nfile, but we don't know how big the file is until we've read it."}),"\n",(0,r.jsxs)(n.p,{children:["The code here is the classic trick to solve that. We open the file, but before\r\nreading it, we seek to the very end using ",(0,r.jsx)(n.code,{children:"fseek()"}),". Then we call ",(0,r.jsx)(n.code,{children:"ftell()"}),"\r\nwhich tells us how many bytes we are from the start of the file. Since we seeked\r\n(sought?) to the end, that's the size. We rewind back to the beginning, allocate\r\na string of that ",(0,r.jsx)(n.span,{name:"one",children:"size"}),", and read the whole file in a\r\nsingle batch."]}),"\n",(0,r.jsxs)(n.aside,{name:"one",children:["\n",(0,r.jsxs)(n.p,{children:["Well, that size ",(0,r.jsx)(n.em,{children:"plus one"}),". Always gotta remember to make room for the null\r\nbyte."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["So we're done, right? Not quite. These function calls, like most calls in the C\r\nstandard library, can fail. If this were Java, the failures would be thrown as\r\nexceptions and automatically unwind the stack so we wouldn't ",(0,r.jsx)(n.em,{children:"really"})," need to\r\nhandle them. In C, if we don't check for them, they silently get ignored."]}),"\n",(0,r.jsx)(n.p,{children:"This isn't really a book on good C programming practice, but I hate to encourage\r\nbad style, so let's go ahead and handle the errors. It's good for us, like\r\neating our vegetables or flossing."}),"\n",(0,r.jsx)(n.p,{children:"Fortunately, we don't need to do anything particularly clever if a failure\r\noccurs. If we can't correctly read the user's script, all we can really do is\r\ntell the user and exit the interpreter gracefully. First of all, we might fail\r\nto open the file."}),"\n",(0,r.jsx)(n.p,{children:"^code no-file (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"This can happen if the file doesn't exist or the user doesn't have access to it.\r\nIt's pretty common -- people mistype paths all the time."}),"\n",(0,r.jsx)(n.p,{children:"This failure is much rarer:"}),"\n",(0,r.jsx)(n.p,{children:"^code no-buffer (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"If we can't even allocate enough memory to read the Lox script, the user's\r\nprobably got bigger problems to worry about, but we should do our best to at\r\nleast let them know."}),"\n",(0,r.jsx)(n.p,{children:"Finally, the read itself may fail."}),"\n",(0,r.jsx)(n.p,{children:"^code no-read (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["This is also unlikely. Actually, the ",(0,r.jsx)(n.span,{name:"printf",children:" calls"})," to\r\n",(0,r.jsx)(n.code,{children:"fseek()"}),", ",(0,r.jsx)(n.code,{children:"ftell()"}),", and ",(0,r.jsx)(n.code,{children:"rewind()"})," could theoretically fail too, but let's not\r\ngo too far off in the weeds, shall we?"]}),"\n",(0,r.jsxs)(n.aside,{name:"printf",children:["\n",(0,r.jsxs)(n.p,{children:["Even good old ",(0,r.jsx)(n.code,{children:"printf()"})," can fail. Yup. How many times have you handled ",(0,r.jsx)(n.em,{children:"that"}),"\r\nerror?"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"opening-the-compilation-pipeline",children:"Opening the compilation pipeline"}),"\n",(0,r.jsxs)(n.p,{children:["We've got ourselves a string of Lox source code, so now we're ready to set up a\r\npipeline to scan, compile, and execute it. It's driven by ",(0,r.jsx)(n.code,{children:"interpret()"}),". Right\r\nnow, that function runs our old hardcoded test chunk. Let's change it to\r\nsomething closer to its final incarnation."]}),"\n",(0,r.jsx)(n.p,{children:"^code vm-interpret-h (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Where before we passed in a Chunk, now we pass in the string of source code.\r\nHere's the new implementation:"}),"\n",(0,r.jsx)(n.p,{children:"^code vm-interpret-c (1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["We won't build the actual ",(0,r.jsx)(n.em,{children:"compiler"})," yet in this chapter, but we can start\r\nlaying out its structure. It lives in a new module."]}),"\n",(0,r.jsx)(n.p,{children:"^code vm-include-compiler (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"For now, the one function in it is declared like so:"}),"\n",(0,r.jsx)(n.p,{children:"^code compiler-h"}),"\n",(0,r.jsx)(n.p,{children:"That signature will change, but it gets us going."}),"\n",(0,r.jsx)(n.p,{children:"The first phase of compilation is scanning -- the thing we're doing in this\r\nchapter -- so right now all the compiler does is set that up."}),"\n",(0,r.jsx)(n.p,{children:"^code compiler-c"}),"\n",(0,r.jsx)(n.p,{children:"This will also grow in later chapters, naturally."}),"\n",(0,r.jsx)(n.h3,{id:"the-scanner-scans",children:"The scanner scans"}),"\n",(0,r.jsx)(n.p,{children:"There are still a few more feet of scaffolding to stand up before we can start\r\nwriting useful code. First, a new header:"}),"\n",(0,r.jsx)(n.p,{children:"^code scanner-h"}),"\n",(0,r.jsx)(n.p,{children:"And its corresponding implementation:"}),"\n",(0,r.jsx)(n.p,{children:"^code scanner-c"}),"\n",(0,r.jsx)(n.p,{children:"As our scanner chews through the user's source code, it tracks how far it's\r\ngone. Like we did with the VM, we wrap that state in a struct and then create a\r\nsingle top-level module variable of that type so we don't have to pass it around\r\nall of the various functions."}),"\n",(0,r.jsxs)(n.p,{children:["There are surprisingly few fields. The ",(0,r.jsx)(n.code,{children:"start"})," pointer marks the beginning of\r\nthe current lexeme being scanned, and ",(0,r.jsx)(n.code,{children:"current"})," points to the current character\r\nbeing looked at."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"fields"})}),"\n",(0,r.jsx)(n.img,{src:"image/scanning-on-demand/fields.png",alt:"The start and current fields pointing at 'print bacon;'. Start points at 'b' and current points at 'o'."}),"\n",(0,r.jsxs)(n.aside,{name:"fields",children:["\n",(0,r.jsxs)(n.p,{children:["Here, we are in the middle of scanning the identifier ",(0,r.jsx)(n.code,{children:"bacon"}),". The current\r\ncharacter is ",(0,r.jsx)(n.code,{children:"o"})," and the character we most recently consumed is ",(0,r.jsx)(n.code,{children:"c"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["We have a ",(0,r.jsx)(n.code,{children:"line"})," field to track what line the current lexeme is on for error\r\nreporting. That's it! We don't even keep a pointer to the beginning of the\r\nsource code string. The scanner works its way through the code once and is done\r\nafter that."]}),"\n",(0,r.jsx)(n.p,{children:"Since we have some state, we should initialize it."}),"\n",(0,r.jsx)(n.p,{children:"^code init-scanner"}),"\n",(0,r.jsx)(n.p,{children:"We start at the very first character on the very first line, like a runner\r\ncrouched at the starting line."}),"\n",(0,r.jsx)(n.h2,{id:"a-token-at-a-time",children:"A Token at a Time"}),"\n",(0,r.jsx)(n.p,{children:"In jlox, when the starting gun went off, the scanner raced ahead and eagerly\r\nscanned the whole program, returning a list of tokens. This would be a challenge\r\nin clox. We'd need some sort of growable array or list to store the tokens in.\r\nWe'd need to manage allocating and freeing the tokens, and the collection\r\nitself. That's a lot of code, and a lot of memory churn."}),"\n",(0,r.jsxs)(n.p,{children:["At any point in time, the compiler needs only one or two tokens -- remember our\r\ngrammar requires only a single token of lookahead -- so we don't need to keep\r\nthem ",(0,r.jsx)(n.em,{children:"all"})," around at the same time. Instead, the simplest solution is to not\r\nscan a token until the compiler needs one. When the scanner provides one, it\r\nreturns the token by value. It doesn't need to dynamically allocate anything --\r\nit can just pass tokens around on the C stack."]}),"\n",(0,r.jsx)(n.p,{children:"Unfortunately, we don't have a compiler yet that can ask the scanner for tokens,\r\nso the scanner will just sit there doing nothing. To kick it into action, we'll\r\nwrite some temporary code to drive it."}),"\n",(0,r.jsx)(n.p,{children:"^code dump-tokens (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.aside,{name:"format",children:["\n",(0,r.jsxs)(n.p,{children:["That ",(0,r.jsx)(n.code,{children:"%.*s"})," in the format string is a neat feature. Usually, you set the output\r\nprecision -- the number of characters to show -- by placing a number inside the\r\nformat string. Using ",(0,r.jsx)(n.code,{children:"*"})," instead lets you pass the precision as an argument. So\r\nthat ",(0,r.jsx)(n.code,{children:"printf()"})," call prints the first ",(0,r.jsx)(n.code,{children:"token.length"})," characters of the string at\r\n",(0,r.jsx)(n.code,{children:"token.start"}),". We need to limit the length like that because the lexeme points\r\ninto the original source string and doesn't have a terminator at the end."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:'This loops indefinitely. Each turn through the loop, it scans one token and\r\nprints it. When it reaches a special "end of file" token or an error, it stops.\r\nFor example, if we run the interpreter on this program:'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"print 1 + 2;\n"})}),"\n",(0,r.jsx)(n.p,{children:"It prints out:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"   1 31 'print'\r\n   | 21 '1'\r\n   |  7 '+'\r\n   | 21 '2'\r\n   |  8 ';'\r\n   2 39 ''\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The first column is the line number, the second is the numeric value of the\r\ntoken ",(0,r.jsx)(n.span,{name:"token",children:"type"}),", and then finally the lexeme. That last\r\nempty lexeme on line 2 is the EOF token."]}),"\n",(0,r.jsxs)(n.aside,{name:"token",children:["\n",(0,r.jsx)(n.p,{children:"Yeah, the raw index of the token type isn't exactly human readable, but it's all\r\nC gives us."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The goal for the rest of the chapter is to make that blob of code work by\r\nimplementing this key function:"}),"\n",(0,r.jsx)(n.p,{children:"^code scan-token-h (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"Each call scans and returns the next token in the source code. A token looks\r\nlike this:"}),"\n",(0,r.jsx)(n.p,{children:"^code token-struct (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["It's pretty similar to jlox's Token class. We have an enum identifying what type\r\nof token it is -- number, identifier, ",(0,r.jsx)(n.code,{children:"+"})," operator, etc. The enum is virtually\r\nidentical to the one in jlox, so let's just hammer out the whole thing."]}),"\n",(0,r.jsx)(n.p,{children:"^code token-type (2 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Aside from prefixing all the names with ",(0,r.jsx)(n.code,{children:"TOKEN_"})," (since C tosses enum names in\r\nthe top-level namespace) the only difference is that extra ",(0,r.jsx)(n.code,{children:"TOKEN_ERROR"})," type.\r\nWhat's that about?"]}),"\n",(0,r.jsx)(n.p,{children:'There are only a couple of errors that get detected during scanning:\r\nunterminated strings and unrecognized characters. In jlox, the scanner reports\r\nthose itself. In clox, the scanner produces a synthetic "error" token for that\r\nerror and passes it over to the compiler. This way, the compiler knows an error\r\noccurred and can kick off error recovery before reporting it.'}),"\n",(0,r.jsx)(n.p,{children:"The novel part in clox's Token type is how it represents the lexeme. In jlox,\r\neach Token stored the lexeme as its own separate little Java string. If we did\r\nthat for clox, we'd have to figure out how to manage the memory for those\r\nstrings. That's especially hard since we pass tokens by value\r\n-- multiple tokens could point to the same lexeme string. Ownership gets weird."}),"\n",(0,r.jsxs)(n.p,{children:["Instead, we use the original source string as our character store. We represent\r\na lexeme by a pointer to its first character and the number of characters it\r\ncontains. This means we don't need to worry about managing memory for lexemes at\r\nall and we can freely copy tokens around. As long as the main source code string\r\n",(0,r.jsx)(n.span,{name:"outlive",children:"outlives"})," all of the tokens, everything works fine."]}),"\n",(0,r.jsxs)(n.aside,{name:"outlive",children:["\n",(0,r.jsxs)(n.p,{children:["I don't mean to sound flippant. We really do need to think about and ensure that\r\nthe source string, which is created far away over in the \"main\" module, has a\r\nlong enough lifetime. That's why ",(0,r.jsx)(n.code,{children:"runFile()"})," doesn't free the string until\r\n",(0,r.jsx)(n.code,{children:"interpret()"})," finishes executing the code and returns."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"scanning-tokens",children:"Scanning tokens"}),"\n",(0,r.jsx)(n.p,{children:"We're ready to scan some tokens. We'll work our way up to the complete\r\nimplementation, starting with this:"}),"\n",(0,r.jsx)(n.p,{children:"^code scan-token"}),"\n",(0,r.jsxs)(n.p,{children:["Since each call to this function scans a complete token, we know we are at the\r\nbeginning of a new token when we enter the function. Thus, we set\r\n",(0,r.jsx)(n.code,{children:"scanner.start"})," to point to the current character so we remember where the\r\nlexeme we're about to scan starts."]}),"\n",(0,r.jsx)(n.p,{children:"Then we check to see if we've reached the end of the source code. If so, we\r\nreturn an EOF token and stop. This is a sentinel value that signals to the\r\ncompiler to stop asking for more tokens."}),"\n",(0,r.jsx)(n.p,{children:"If we aren't at the end, we do some... stuff... to scan the next token. But we\r\nhaven't written that code yet. We'll get to that soon. If that code doesn't\r\nsuccessfully scan and return a token, then we reach the end of the function.\r\nThat must mean we're at a character that the scanner can't recognize, so we\r\nreturn an error token for that."}),"\n",(0,r.jsx)(n.p,{children:"This function relies on a couple of helpers, most of which are familiar from\r\njlox. First up:"}),"\n",(0,r.jsx)(n.p,{children:"^code is-at-end"}),"\n",(0,r.jsx)(n.p,{children:"We require the source string to be a good null-terminated C string. If the\r\ncurrent character is the null byte, then we've reached the end."}),"\n",(0,r.jsx)(n.p,{children:"To create a token, we have this constructor-like function:"}),"\n",(0,r.jsx)(n.p,{children:"^code make-token"}),"\n",(0,r.jsxs)(n.p,{children:["It uses the scanner's ",(0,r.jsx)(n.code,{children:"start"})," and ",(0,r.jsx)(n.code,{children:"current"})," pointers to capture the token's\r\nlexeme. It sets a couple of other obvious fields then returns the token. It has\r\na sister function for returning error tokens."]}),"\n",(0,r.jsx)(n.p,{children:"^code error-token"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"axolotl"})}),"\n",(0,r.jsxs)(n.aside,{name:"axolotl",children:["\n",(0,r.jsx)(n.p,{children:"This part of the chapter is pretty dry, so here's a picture of an axolotl."}),"\n",(0,r.jsx)(n.img,{src:"image/scanning-on-demand/axolotl.png",alt:"A drawing of an axolotl."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The only difference is that the \"lexeme\" points to the error message string\r\ninstead of pointing into the user's source code. Again, we need to ensure that\r\nthe error message sticks around long enough for the compiler to read it. In\r\npractice, we only ever call this function with C string literals. Those are\r\nconstant and eternal, so we're fine."}),"\n",(0,r.jsx)(n.p,{children:"What we have now is basically a working scanner for a language with an empty\r\nlexical grammar. Since the grammar has no productions, every character is an\r\nerror. That's not exactly a fun language to program in, so let's fill in the\r\nrules."}),"\n",(0,r.jsx)(n.h2,{id:"a-lexical-grammar-for-lox",children:"A Lexical Grammar for Lox"}),"\n",(0,r.jsx)(n.p,{children:"The simplest tokens are only a single character. We recognize those like so:"}),"\n",(0,r.jsx)(n.p,{children:"^code scan-char (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"We read the next character from the source code, and then do a straightforward\r\nswitch to see if it matches any of Lox's one-character lexemes. To read the next\r\ncharacter, we use a new helper which consumes the current character and returns\r\nit."}),"\n",(0,r.jsx)(n.p,{children:"^code advance"}),"\n",(0,r.jsxs)(n.p,{children:["Next up are the two-character punctuation tokens like ",(0,r.jsx)(n.code,{children:"!="})," and ",(0,r.jsx)(n.code,{children:">="}),". Each of\r\nthese also has a corresponding single-character token. That means that when we\r\nsee a character like ",(0,r.jsx)(n.code,{children:"!"}),", we don't know if we're in a ",(0,r.jsx)(n.code,{children:"!"})," token or a ",(0,r.jsx)(n.code,{children:"!="})," until\r\nwe look at the next character too. We handle those like so:"]}),"\n",(0,r.jsx)(n.p,{children:"^code two-char (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["After consuming the first character, we look for an ",(0,r.jsx)(n.code,{children:"="}),". If found, we consume it\r\nand return the corresponding two-character token. Otherwise, we leave the\r\ncurrent character alone (so it can be part of the ",(0,r.jsx)(n.em,{children:"next"})," token) and return the\r\nappropriate one-character token."]}),"\n",(0,r.jsx)(n.p,{children:"That logic for conditionally consuming the second character lives here:"}),"\n",(0,r.jsx)(n.p,{children:"^code match"}),"\n",(0,r.jsxs)(n.p,{children:["If the current character is the desired one, we advance and return ",(0,r.jsx)(n.code,{children:"true"}),".\r\nOtherwise, we return ",(0,r.jsx)(n.code,{children:"false"})," to indicate it wasn't matched."]}),"\n",(0,r.jsx)(n.p,{children:"Now our scanner supports all of the punctuation-like tokens. Before we get to\r\nthe longer ones, let's take a little side trip to handle characters that aren't\r\npart of a token at all."}),"\n",(0,r.jsx)(n.h3,{id:"whitespace",children:"Whitespace"}),"\n",(0,r.jsxs)(n.p,{children:["Our scanner needs to handle spaces, tabs, and newlines, but those characters\r\ndon't become part of any token's lexeme. We could check for those inside the\r\nmain character switch in ",(0,r.jsx)(n.code,{children:"scanToken()"})," but it gets a little tricky to ensure\r\nthat the function still correctly finds the next token ",(0,r.jsx)(n.em,{children:"after"})," the whitespace\r\nwhen you call it. We'd have to wrap the whole body of the function in a loop or\r\nsomething."]}),"\n",(0,r.jsx)(n.p,{children:"Instead, before starting the token, we shunt off to a separate function."}),"\n",(0,r.jsx)(n.p,{children:"^code call-skip-whitespace (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"This advances the scanner past any leading whitespace. After this call returns,\r\nwe know the very next character is a meaningful one (or we're at the end of the\r\nsource code)."}),"\n",(0,r.jsx)(n.p,{children:"^code skip-whitespace"}),"\n",(0,r.jsxs)(n.p,{children:["It's sort of a separate mini-scanner. It loops, consuming every whitespace\r\ncharacter it encounters. We need to be careful that it does ",(0,r.jsx)(n.em,{children:"not"})," consume any\r\n",(0,r.jsx)(n.em,{children:"non"}),"-whitespace characters. To support that, we use this:"]}),"\n",(0,r.jsx)(n.p,{children:"^code peek"}),"\n",(0,r.jsx)(n.p,{children:"This simply returns the current character, but doesn't consume it. The previous\r\ncode handles all the whitespace characters except for newlines."}),"\n",(0,r.jsx)(n.p,{children:"^code newline (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"When we consume one of those, we also bump the current line number."}),"\n",(0,r.jsx)(n.h3,{id:"comments",children:"Comments"}),"\n",(0,r.jsx)(n.p,{children:'Comments aren\'t technically "whitespace", if you want to get all precise with\r\nyour terminology, but as far as Lox is concerned, they may as well be, so we\r\nskip those too.'}),"\n",(0,r.jsx)(n.p,{children:"^code comment (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Comments start with ",(0,r.jsx)(n.code,{children:"//"})," in Lox, so as with ",(0,r.jsx)(n.code,{children:"!="})," and friends, we need a second\r\ncharacter of lookahead. However, with ",(0,r.jsx)(n.code,{children:"!="}),", we still wanted to consume the ",(0,r.jsx)(n.code,{children:"!"}),"\r\neven if the ",(0,r.jsx)(n.code,{children:"="})," wasn't found. Comments are different. If we don't find a second\r\n",(0,r.jsx)(n.code,{children:"/"}),", then ",(0,r.jsx)(n.code,{children:"skipWhitespace()"})," needs to not consume the ",(0,r.jsx)(n.em,{children:"first"})," slash either."]}),"\n",(0,r.jsx)(n.p,{children:"To handle that, we add:"}),"\n",(0,r.jsx)(n.p,{children:"^code peek-next"}),"\n",(0,r.jsxs)(n.p,{children:["This is like ",(0,r.jsx)(n.code,{children:"peek()"})," but for one character past the current one. If the current\r\ncharacter and the next one are both ",(0,r.jsx)(n.code,{children:"/"}),", we consume them and then any other\r\ncharacters until the next newline or the end of the source code."]}),"\n",(0,r.jsxs)(n.p,{children:["We use ",(0,r.jsx)(n.code,{children:"peek()"})," to check for the newline but not consume it. That way, the\r\nnewline will be the current character on the next turn of the outer loop in\r\n",(0,r.jsx)(n.code,{children:"skipWhitespace()"})," and we'll recognize it and increment ",(0,r.jsx)(n.code,{children:"scanner.line"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"literal-tokens",children:"Literal tokens"}),"\n",(0,r.jsx)(n.p,{children:"Number and string tokens are special because they have a runtime value\r\nassociated with them. We'll start with strings because they are easy to\r\nrecognize -- they always begin with a double quote."}),"\n",(0,r.jsx)(n.p,{children:"^code scan-string (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"That calls a new function."}),"\n",(0,r.jsx)(n.p,{children:"^code string"}),"\n",(0,r.jsx)(n.p,{children:"Similar to jlox, we consume characters until we reach the closing quote. We also\r\ntrack newlines inside the string literal. (Lox supports multi-line strings.)\r\nAnd, as ever, we gracefully handle running out of source code before we find the\r\nend quote."}),"\n",(0,r.jsxs)(n.p,{children:["The main change here in clox is something that's ",(0,r.jsx)(n.em,{children:"not"})," present. Again, it\r\nrelates to memory management. In jlox, the Token class had a field of type\r\nObject to store the runtime value converted from the literal token's lexeme."]}),"\n",(0,r.jsx)(n.p,{children:"Implementing that in C would require a lot of work. We'd need some sort of union\r\nand type tag to tell whether the token contains a string or double value. If\r\nit's a string, we'd need to manage the memory for the string's character array\r\nsomehow."}),"\n",(0,r.jsxs)(n.p,{children:["Instead of adding that complexity to the scanner, we defer ",(0,r.jsx)(n.span,{name:"convert",children:"converting"})," the literal lexeme to a runtime value until\r\nlater. In clox, tokens only store the lexeme -- the character sequence exactly\r\nas it appears in the user's source code. Later in the compiler, we'll convert\r\nthat lexeme to a runtime value right when we are ready to store it in the\r\nchunk's constant table."]}),"\n",(0,r.jsxs)(n.aside,{name:"convert",children:["\n",(0,r.jsxs)(n.p,{children:["Doing the lexeme-to-value conversion in the compiler does introduce some\r\nredundancy. The work to scan a number literal is awfully similar to the work\r\nrequired to convert a sequence of digit characters to a number value. But there\r\nisn't ",(0,r.jsx)(n.em,{children:"that"})," much redundancy, it isn't in anything performance critical, and it\r\nkeeps our scanner simpler."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Next up, numbers. Instead of adding a switch case for each of the ten digits\r\nthat can start a number, we handle them here:"}),"\n",(0,r.jsx)(n.p,{children:"^code scan-number (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"That uses this obvious utility function:"}),"\n",(0,r.jsx)(n.p,{children:"^code is-digit"}),"\n",(0,r.jsx)(n.p,{children:"We finish scanning the number using this:"}),"\n",(0,r.jsx)(n.p,{children:"^code number"}),"\n",(0,r.jsx)(n.p,{children:"It's virtually identical to jlox's version except, again, we don't convert the\r\nlexeme to a double yet."}),"\n",(0,r.jsx)(n.h2,{id:"identifiers-and-keywords",children:"Identifiers and Keywords"}),"\n",(0,r.jsx)(n.p,{children:"The last batch of tokens are identifiers, both user-defined and reserved. This\r\nsection should be fun -- the way we recognize keywords in clox is quite\r\ndifferent from how we did it in jlox, and touches on some important data\r\nstructures."}),"\n",(0,r.jsx)(n.p,{children:"First, though, we have to scan the lexeme. Names start with a letter or\r\nunderscore."}),"\n",(0,r.jsx)(n.p,{children:"^code scan-identifier (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"We recognize those using this:"}),"\n",(0,r.jsx)(n.p,{children:"^code is-alpha"}),"\n",(0,r.jsx)(n.p,{children:"Once we've found an identifier, we scan the rest of it here:"}),"\n",(0,r.jsx)(n.p,{children:"^code identifier"}),"\n",(0,r.jsx)(n.p,{children:'After the first letter, we allow digits too, and we keep consuming alphanumerics\r\nuntil we run out of them. Then we produce a token with the proper type.\r\nDetermining that "proper" type is the unique part of this chapter.'}),"\n",(0,r.jsx)(n.p,{children:"^code identifier-type"}),"\n",(0,r.jsx)(n.p,{children:"Okay, I guess that's not very exciting yet. That's what it looks like if we\r\nhave no reserved words at all. How should we go about recognizing keywords? In\r\njlox, we stuffed them all in a Java Map and looked them up by name. We don't\r\nhave any sort of hash table structure in clox, at least not yet."}),"\n",(0,r.jsxs)(n.p,{children:["A hash table would be overkill anyway. To look up a string in a hash ",(0,r.jsx)(n.span,{name:"hash",children:"table"}),", we need to walk the string to calculate its hash code,\r\nfind the corresponding bucket in the hash table, and then do a\r\ncharacter-by-character equality comparison on any string it happens to find\r\nthere."]}),"\n",(0,r.jsxs)(n.aside,{name:"hash",children:["\n",(0,r.jsxs)(n.p,{children:["Don't worry if this is unfamiliar to you. When we get to ",(0,r.jsx)(n.a,{href:"hash-tables.html",children:"building our own hash\r\ntable from scratch"}),", we'll learn all about it in exquisite detail."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Let's say we've scanned the identifier \"gorgonzola\". How much work ",(0,r.jsx)(n.em,{children:"should"})," we\r\nneed to do to tell if that's a reserved word? Well, no Lox keyword starts with\r\n\"g\", so looking at the first character is enough to definitively answer no.\r\nThat's a lot simpler than a hash table lookup."]}),"\n",(0,r.jsx)(n.p,{children:'What about "cardigan"? We do have a keyword in Lox that starts with "c":\r\n"class". But the second character in "cardigan", "a", rules that out. What about\r\n"forest"? Since "for" is a keyword, we have to go farther in the string before\r\nwe can establish that we don\'t have a reserved word. But, in most cases, only a\r\ncharacter or two is enough to tell we\'ve got a user-defined name on our hands.\r\nWe should be able to recognize that and fail fast.'}),"\n",(0,r.jsx)(n.p,{children:"Here's a visual representation of that branching character-inspection logic:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"down"})}),"\n",(0,r.jsx)(n.img,{src:"image/scanning-on-demand/keywords.png",alt:"A trie that contains all of Lox's keywords."}),"\n",(0,r.jsxs)(n.aside,{name:"down",children:["\n",(0,r.jsx)(n.p,{children:"Read down each chain of nodes and you'll see Lox's keywords emerge."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"We start at the root node. If there is a child node whose letter matches the\r\nfirst character in the lexeme, we move to that node. Then repeat for the next\r\nletter in the lexeme and so on. If at any point the next letter in the lexeme\r\ndoesn't match a child node, then the identifier must not be a keyword and we\r\nstop. If we reach a double-lined box, and we're at the last character of the\r\nlexeme, then we found a keyword."}),"\n",(0,r.jsx)(n.h3,{id:"tries-and-state-machines",children:"Tries and state machines"}),"\n",(0,r.jsxs)(n.p,{children:["This tree diagram is an example of a thing called a ",(0,r.jsx)(n.span,{name:"trie",children:(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Trie",children:(0,r.jsx)(n.strong,{children:"trie"})})}),". A trie stores a set of strings. Most other\r\ndata structures for storing strings contain the raw character arrays and then\r\nwrap them inside some larger construct that helps you search faster. A trie is\r\ndifferent. Nowhere in the trie will you find a whole string."]}),"\n",(0,r.jsxs)(n.aside,{name:"trie",children:["\n",(0,r.jsxs)(n.p,{children:['"Trie" is one of the most confusing names in CS. Edward Fredkin yanked it out of\r\nthe middle of the word "retrieval", which means it should be pronounced like\r\n"tree". But, uh, there is already a pretty important data structure pronounced\r\n"tree" ',(0,r.jsx)(n.em,{children:"which tries are a special case of"}),', so unless you never speak of these\r\nthings out loud, no one can tell which one you\'re talking about. Thus, people\r\nthese days often pronounce it like "try" to avoid the headache.']}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:['Instead, each string the trie "contains" is represented as a ',(0,r.jsx)(n.em,{children:"path"}),' through the\r\ntree of character nodes, as in our traversal above. Nodes that match the last\r\ncharacter in a string have a special marker -- the double lined boxes in the\r\nillustration. That way, if your trie contains, say, "banquet" and "ban", you are\r\nable to tell that it does ',(0,r.jsx)(n.em,{children:"not"}),' contain "banque" -- the "e" node won\'t have that\r\nmarker, while the "n" and "t" nodes will.']}),"\n",(0,r.jsxs)(n.p,{children:["Tries are a special case of an even more fundamental data structure: a\r\n",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Deterministic_finite_automaton",children:(0,r.jsx)(n.strong,{children:"deterministic finite automaton"})})," (",(0,r.jsx)(n.strong,{children:"DFA"}),"). You might also know these\r\nby other names: ",(0,r.jsx)(n.strong,{children:"finite state machine"}),", or just ",(0,r.jsx)(n.strong,{children:"state machine"}),". State\r\nmachines are rad. They end up useful in everything from ",(0,r.jsx)(n.a,{href:"http://gameprogrammingpatterns.com/state.html",children:"game\r\nprogramming"})," to implementing networking protocols."]}),"\n",(0,r.jsxs)(n.p,{children:["In a DFA, you have a set of ",(0,r.jsx)(n.em,{children:"states"})," with ",(0,r.jsx)(n.em,{children:"transitions"}),' between them, forming a\r\ngraph. At any point in time, the machine is "in" exactly one state. It gets to\r\nother states by following transitions. When you use a DFA for lexical analysis,\r\neach transition is a character that gets matched from the string. Each state\r\nrepresents a set of allowed characters.']}),"\n",(0,r.jsxs)(n.p,{children:["Our keyword tree is exactly a DFA that recognizes Lox keywords. But DFAs are\r\nmore powerful than simple trees because they can be arbitrary ",(0,r.jsx)(n.em,{children:"graphs"}),".\r\nTransitions can form cycles between states. That lets you recognize arbitrarily\r\nlong strings. For example, here's a DFA that recognizes number literals:"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"railroad"})}),"\n",(0,r.jsx)(n.img,{src:"image/scanning-on-demand/numbers.png",alt:"A syntax diagram that recognizes integer and floating point literals."}),"\n",(0,r.jsxs)(n.aside,{name:"railroad",children:["\n",(0,r.jsxs)(n.p,{children:["This style of diagram is called a ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Syntax_diagram",children:(0,r.jsx)(n.strong,{children:"syntax diagram"})})," or the\r\nmore charming ",(0,r.jsx)(n.strong,{children:"railroad diagram"}),". The latter name is because it looks\r\nsomething like a switching yard for trains."]}),"\n",(0,r.jsxs)(n.p,{children:["Back before Backus-Naur Form was a thing, this was one of the predominant ways\r\nof documenting a language's grammar. These days, we mostly use text, but there's\r\nsomething delightful about the official specification for a ",(0,r.jsx)(n.em,{children:"textual language"}),"\r\nrelying on an ",(0,r.jsx)(n.em,{children:"image"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["I've collapsed the nodes for the ten digits together to keep it more readable,\r\nbut the basic process works the same -- you work through the path, entering\r\nnodes whenever you consume a corresponding character in the lexeme. If we were\r\nso inclined, we could construct one big giant DFA that does ",(0,r.jsx)(n.em,{children:"all"})," of the lexical\r\nanalysis for Lox, a single state machine that recognizes and spits out all of\r\nthe tokens we need."]}),"\n",(0,r.jsxs)(n.p,{children:["However, crafting that mega-DFA by ",(0,r.jsx)(n.span,{name:"regex",children:"hand"})," would be\r\nchallenging. That's why ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Lex_(software)",children:"Lex"})," was created. You give it a simple textual\r\ndescription of your lexical grammar -- a bunch of regular expressions -- and it\r\nautomatically generates a DFA for you and produces a pile of C code that\r\nimplements it."]}),"\n",(0,r.jsxs)(n.aside,{name:"regex",children:["\n",(0,r.jsx)(n.p,{children:"This is also how most regular expression engines in programming languages and\r\ntext editors work under the hood. They take your regex string and convert it to\r\na DFA, which they then use to match strings."}),"\n",(0,r.jsxs)(n.p,{children:["If you want to learn the algorithm to convert a regular expression into a DFA,\r\n",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools",children:"the dragon book"})," has you covered."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"We won't go down that road. We already have a perfectly serviceable hand-rolled\r\nscanner. We just need a tiny trie for recognizing keywords. How should we map\r\nthat to code?"}),"\n",(0,r.jsxs)(n.p,{children:["The absolute simplest ",(0,r.jsx)(n.span,{name:"v8",children:"solution"})," is to use a switch\r\nstatement for each node with cases for each branch. We'll start with the root\r\nnode and handle the easy keywords."]}),"\n",(0,r.jsxs)(n.aside,{name:"v8",children:["\n",(0,r.jsxs)(n.p,{children:["Simple doesn't mean dumb. The same approach is ",(0,r.jsx)(n.a,{href:"https://github.com/v8/v8/blob/e77eebfe3b747fb315bd3baad09bec0953e53e68/src/parsing/scanner.cc#L1643",children:"essentially what V8 does"}),",\r\nand that's currently one of the world's most sophisticated, fastest language\r\nimplementations."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code keywords (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:['These are the initial letters that correspond to a single keyword. If we see an\r\n"s", the only keyword the identifier could possibly be is ',(0,r.jsx)(n.code,{children:"super"}),'. It might not\r\nbe, though, so we still need to check the rest of the letters too. In the tree\r\ndiagram, this is basically that straight path hanging off the "s".']}),"\n",(0,r.jsx)(n.p,{children:"We won't roll a switch for each of those nodes. Instead, we have a utility\r\nfunction that tests the rest of a potential keyword's lexeme."}),"\n",(0,r.jsx)(n.p,{children:"^code check-keyword"}),"\n",(0,r.jsx)(n.p,{children:'We use this for all of the unbranching paths in the tree. Once we\'ve found a\r\nprefix that could only be one possible reserved word, we need to verify two\r\nthings. The lexeme must be exactly as long as the keyword. If the first letter\r\nis "s", the lexeme could still be "sup" or "superb". And the remaining\r\ncharacters must match exactly -- "supar" isn\'t good enough.'}),"\n",(0,r.jsx)(n.p,{children:"If we do have the right number of characters, and they're the ones we want, then\r\nit's a keyword, and we return the associated token type. Otherwise, it must be a\r\nnormal identifier."}),"\n",(0,r.jsxs)(n.p,{children:['We have a couple of keywords where the tree branches again after the first\r\nletter. If the lexeme starts with "f", it could be ',(0,r.jsx)(n.code,{children:"false"}),", ",(0,r.jsx)(n.code,{children:"for"}),", or ",(0,r.jsx)(n.code,{children:"fun"}),'. So\r\nwe add another switch for the branches coming off the "f" node.']}),"\n",(0,r.jsx)(n.p,{children:"^code keyword-f (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Before we switch, we need to check that there even ",(0,r.jsx)(n.em,{children:"is"}),' a second letter. "f" by\r\nitself is a valid identifier too, after all. The other letter that branches is\r\n"t".']}),"\n",(0,r.jsx)(n.p,{children:"^code keyword-t (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["That's it. A couple of nested ",(0,r.jsx)(n.code,{children:"switch"})," statements. Not only is this code ",(0,r.jsx)(n.span,{name:"short",children:"short"}),", but it's very, very fast. It does the minimum amount\r\nof work required to detect a keyword, and bails out as soon as it can tell the\r\nidentifier will not be a reserved one."]}),"\n",(0,r.jsx)(n.p,{children:"And with that, our scanner is complete."}),"\n",(0,r.jsxs)(n.aside,{name:"short",children:["\n",(0,r.jsx)(n.p,{children:"We sometimes fall into the trap of thinking that performance comes from\r\ncomplicated data structures, layers of caching, and other fancy optimizations.\r\nBut, many times, all that's required is to do less work, and I often find that\r\nwriting the simplest code I can is sufficient to accomplish that."}),"\n"]}),"\n",(0,r.jsxs)(n.div,{className:"challenges",children:["\n",(0,r.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Many newer languages support ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/String_interpolation",children:(0,r.jsx)(n.strong,{children:"string interpolation"})}),". Inside a\r\nstring literal, you have some sort of special delimiters -- most commonly\r\n",(0,r.jsx)(n.code,{children:"${"})," at the beginning and ",(0,r.jsx)(n.code,{children:"}"})," at the end. Between those delimiters, any\r\nexpression can appear. When the string literal is executed, the inner\r\nexpression is evaluated, converted to a string, and then merged with the\r\nsurrounding string literal."]}),"\n",(0,r.jsx)(n.p,{children:"For example, if Lox supported string interpolation, then this..."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'var drink = "Tea";\r\nvar steep = 4;\r\nvar cool = 2;\r\nprint "${drink} will be ready in ${steep + cool} minutes.";\n'})}),"\n",(0,r.jsx)(n.p,{children:"...would print:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"Tea will be ready in 6 minutes.\n"})}),"\n",(0,r.jsx)(n.p,{children:"What token types would you define to implement a scanner for string\r\ninterpolation? What sequence of tokens would you emit for the above string\r\nliteral?"}),"\n",(0,r.jsx)(n.p,{children:"What tokens would you emit for:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:'"Nested ${"interpolation?! Are you ${"mad?!"}"}"\n'})}),"\n",(0,r.jsx)(n.p,{children:"Consider looking at other language implementations that support\r\ninterpolation to see how they handle it."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Several languages use angle brackets for generics and also have a ",(0,r.jsx)(n.code,{children:">>"})," right\r\nshift operator. This led to a classic problem in early versions of C++:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-c++",children:"vector<vector<string>> nestedVectors;\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This would produce a compile error because the ",(0,r.jsx)(n.code,{children:">>"})," was lexed to a single\r\nright shift token, not two ",(0,r.jsx)(n.code,{children:">"})," tokens. Users were forced to avoid this by\r\nputting a space between the closing angle brackets."]}),"\n",(0,r.jsx)(n.p,{children:"Later versions of C++ are smarter and can handle the above code. Java and C#\r\nnever had the problem. How do those languages specify and implement this?"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:'Many languages, especially later in their evolution, define "contextual\r\nkeywords". These are identifiers that act like reserved words in some\r\ncontexts but can be normal user-defined identifiers in others.'}),"\n",(0,r.jsxs)(n.p,{children:["For example, ",(0,r.jsx)(n.code,{children:"await"})," is a keyword inside an ",(0,r.jsx)(n.code,{children:"async"})," method in C#, but\r\nin other methods, you can use ",(0,r.jsx)(n.code,{children:"await"})," as your own identifier."]}),"\n",(0,r.jsx)(n.p,{children:"Name a few contextual keywords from other languages, and the context where\r\nthey are meaningful. What are the pros and cons of having contextual\r\nkeywords? How would you implement them in your language's front end if you\r\nneeded to?"}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>o});var r=t(6540);const s={},a=r.createContext(s);function i(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);