"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[6056],{4332:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var r=t(4848),i=t(8453);const o={},a=void 0,s={id:"Craftinginterpreters/not-translated-yet/calls-and-functions",title:"calls-and-functions",description:"Any problem in computer science can be solved with another level of",source:"@site/docs/Craftinginterpreters/not-translated-yet/calls-and-functions.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/calls-and-functions",permalink:"/docs/Craftinginterpreters/not-translated-yet/calls-and-functions",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/calls-and-functions.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"backmatter",permalink:"/docs/Craftinginterpreters/not-translated-yet/backmatter"},next:{title:"chunks-of-bytecode",permalink:"/docs/Craftinginterpreters/not-translated-yet/chunks-of-bytecode"}},c={},l=[{value:"Function Objects",id:"function-objects",level:2},{value:"Compiling to Function Objects",id:"compiling-to-function-objects",level:2},{value:"Creating functions at compile time",id:"creating-functions-at-compile-time",level:3},{value:"Call Frames",id:"call-frames",level:2},{value:"Allocating local variables",id:"allocating-local-variables",level:3},{value:"Return addresses",id:"return-addresses",level:3},{value:"The call stack",id:"the-call-stack",level:3},{value:"Function Declarations",id:"function-declarations",level:2},{value:"A stack of compilers",id:"a-stack-of-compilers",level:3},{value:"Function parameters",id:"function-parameters",level:3},{value:"Function Calls",id:"function-calls",level:2},{value:"Binding arguments to parameters",id:"binding-arguments-to-parameters",level:3},{value:"Runtime error checking",id:"runtime-error-checking",level:3},{value:"Printing stack traces",id:"printing-stack-traces",level:3},{value:"Returning from functions",id:"returning-from-functions",level:3},{value:"Return Statements",id:"return-statements",level:2},{value:"Native Functions",id:"native-functions",level:2},{value:"Challenges",id:"challenges",level:2}];function h(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:"Any problem in computer science can be solved with another level of\r\nindirection. Except for the problem of too many layers of indirection."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.cite,{children:"David Wheeler"})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This chapter is a beast. I try to break features into bite-sized pieces, but\r\nsometimes you gotta swallow the whole ",(0,r.jsx)(n.span,{name:"eat",children:"meal"}),". Our next\r\ntask is functions. We could start with only function declarations, but that's\r\nnot very useful when you can't call them. We could do calls, but there's nothing\r\nto call. And all of the runtime support needed in the VM to support both of\r\nthose isn't very rewarding if it isn't hooked up to anything you can see. So\r\nwe're going to do it all. It's a lot, but we'll feel good when we're done."]}),"\n",(0,r.jsxs)(n.aside,{name:"eat",children:["\n",(0,r.jsx)(n.p,{children:'Eating -- consumption -- is a weird metaphor for a creative act. But most of the\r\nbiological processes that produce "output" are a little less, ahem, decorous.'}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"function-objects",children:"Function Objects"}),"\n",(0,r.jsxs)(n.p,{children:["The most interesting structural change in the VM is around the stack. We already\r\n",(0,r.jsx)(n.em,{children:"have"})," a stack for local variables and temporaries, so we're partway there. But\r\nwe have no notion of a ",(0,r.jsx)(n.em,{children:"call"})," stack. Before we can make much progress, we'll\r\nhave to fix that. But first, let's write some code. I always feel better once I\r\nstart moving. We can't do much without having some kind of representation for\r\nfunctions, so we'll start there. From the VM's perspective, what is a function?"]}),"\n",(0,r.jsx)(n.p,{children:"A function has a body that can be executed, so that means some bytecode. We\r\ncould compile the entire program and all of its function declarations into one\r\nbig monolithic Chunk. Each function would have a pointer to the first\r\ninstruction of its code inside the Chunk."}),"\n",(0,r.jsx)(n.p,{children:"This is roughly how compilation to native code works where you end up with one\r\nsolid blob of machine code. But for our bytecode VM, we can do something a\r\nlittle higher level. I think a cleaner model is to give each function its own\r\nChunk. We'll want some other metadata too, so let's go ahead and stuff it all in\r\na struct now."}),"\n",(0,r.jsx)(n.p,{children:"^code obj-function (2 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Functions are first class in Lox, so they need to be actual Lox objects. Thus\r\nObjFunction has the same Obj header that all object types share. The ",(0,r.jsx)(n.code,{children:"arity"}),"\r\nfield stores the number of parameters the function expects. Then, in addition to\r\nthe chunk, we store the function's ",(0,r.jsx)(n.span,{name:"name",children:"name"}),". That will be\r\nhandy for reporting readable runtime errors."]}),"\n",(0,r.jsxs)(n.aside,{name:"name",children:["\n",(0,r.jsx)(n.p,{children:"Humans don't seem to find numeric bytecode offsets particularly illuminating in\r\ncrash dumps."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:'This is the first time the "object" module has needed to reference Chunk, so we\r\nget an include.'}),"\n",(0,r.jsx)(n.p,{children:"^code object-include-chunk (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Like we did with strings, we define some accessories to make Lox functions\r\neasier to work with in C. Sort of a poor man's object orientation. First, we'll\r\ndeclare a C function to create a new Lox function."}),"\n",(0,r.jsx)(n.p,{children:"^code new-function-h (3 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"The implementation is over here:"}),"\n",(0,r.jsx)(n.p,{children:"^code new-function"}),"\n",(0,r.jsxs)(n.p,{children:["We use our friend ",(0,r.jsx)(n.code,{children:"ALLOCATE_OBJ()"})," to allocate memory and initialize the\r\nobject's header so that the VM knows what type of object it is. Instead of\r\npassing in arguments to initialize the function like we did with ObjString, we\r\nset the function up in a sort of blank state -- zero arity, no name, and no\r\ncode. That will get filled in later after the function is created."]}),"\n",(0,r.jsx)(n.p,{children:"Since we have a new kind of object, we need a new object type in the enum."}),"\n",(0,r.jsx)(n.p,{children:"^code obj-type-function (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"When we're done with a function object, we must return the bits it borrowed back\r\nto the operating system."}),"\n",(0,r.jsx)(n.p,{children:"^code free-function (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["This switch case is ",(0,r.jsx)(n.span,{name:"free-name",children:"responsible"})," for freeing the\r\nObjFunction itself as well as any other memory it owns. Functions own their\r\nchunk, so we call Chunk's destructor-like function."]}),"\n",(0,r.jsxs)(n.aside,{name:"free-name",children:["\n",(0,r.jsxs)(n.p,{children:["We don't need to explicitly free the function's name because it's an ObjString.\r\nThat means we can let the garbage collector manage its lifetime for us. Or, at\r\nleast, we'll be able to once we ",(0,r.jsx)(n.a,{href:"garbage-collection.html",children:"implement a garbage collector"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Lox lets you print any object, and functions are first-class objects, so we\r\nneed to handle them too."}),"\n",(0,r.jsx)(n.p,{children:"^code print-function (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"This calls out to:"}),"\n",(0,r.jsx)(n.p,{children:"^code print-function-helper"}),"\n",(0,r.jsx)(n.p,{children:"Since a function knows its name, it may as well say it."}),"\n",(0,r.jsxs)(n.p,{children:["Finally, we have a couple of macros for converting values to functions. First,\r\nmake sure your value actually ",(0,r.jsx)(n.em,{children:"is"})," a function."]}),"\n",(0,r.jsx)(n.p,{children:"^code is-function (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Assuming that evaluates to true, you can then safely cast the Value to an\r\nObjFunction pointer using this:"}),"\n",(0,r.jsx)(n.p,{children:"^code as-function (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"With that, our object model knows how to represent functions. I'm feeling warmed\r\nup now. You ready for something a little harder?"}),"\n",(0,r.jsx)(n.h2,{id:"compiling-to-function-objects",children:"Compiling to Function Objects"}),"\n",(0,r.jsx)(n.p,{children:"Right now, our compiler assumes it is always compiling to one single chunk. With\r\neach function's code living in separate chunks, that gets more complex. When the\r\ncompiler reaches a function declaration, it needs to emit code into the\r\nfunction's chunk when compiling its body. At the end of the function body, the\r\ncompiler needs to return to the previous chunk it was working with."}),"\n",(0,r.jsxs)(n.p,{children:["That's fine for code inside function bodies, but what about code that isn't? The\r\n\"top level\" of a Lox program is also imperative code and we need a chunk to\r\ncompile that into. We can simplify the compiler and VM by placing that top-level\r\ncode inside an automatically defined function too. That way, the compiler is\r\nalways within some kind of function body, and the VM always runs code by\r\ninvoking a function. It's as if the entire program is ",(0,r.jsx)(n.span,{name:"wrap",children:"wrapped"})," inside an implicit ",(0,r.jsx)(n.code,{children:"main()"})," function."]}),"\n",(0,r.jsxs)(n.aside,{name:"wrap",children:["\n",(0,r.jsx)(n.p,{children:"One semantic corner where that analogy breaks down is global variables. They\r\nhave special scoping rules different from local variables, so in that way, the\r\ntop level of a script isn't like a function body."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Before we get to user-defined functions, then, let's do the reorganization to\r\nsupport that implicit top-level function. It starts with the Compiler struct.\r\nInstead of pointing directly to a Chunk that the compiler writes to, it instead\r\nhas a reference to the function object being built."}),"\n",(0,r.jsx)(n.p,{children:"^code function-fields (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"We also have a little FunctionType enum. This lets the compiler tell when it's\r\ncompiling top-level code versus the body of a function. Most of the compiler\r\ndoesn't care about this -- that's why it's a useful abstraction -- but in one or\r\ntwo places the distinction is meaningful. We'll get to one later."}),"\n",(0,r.jsx)(n.p,{children:"^code function-type-enum"}),"\n",(0,r.jsxs)(n.p,{children:["Every place in the compiler that was writing to the Chunk now needs to go\r\nthrough that ",(0,r.jsx)(n.code,{children:"function"})," pointer. Fortunately, many ",(0,r.jsx)(n.span,{name:"current",children:"chapters"})," ago, we encapsulated access to the chunk in the\r\n",(0,r.jsx)(n.code,{children:"currentChunk()"})," function. We only need to fix that and the rest of the compiler\r\nis happy."]}),"\n",(0,r.jsxs)(n.aside,{name:"current",children:["\n",(0,r.jsx)(n.p,{children:"It's almost like I had a crystal ball that could see into the future and knew\r\nwe'd need to change the code later. But, really, it's because I wrote all the\r\ncode for the book before any of the text."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code current-chunk (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"The current chunk is always the chunk owned by the function we're in the middle\r\nof compiling. Next, we need to actually create that function. Previously, the VM\r\npassed a Chunk to the compiler which filled it with code. Instead, the compiler\r\nwill create and return a function that contains the compiled top-level code --\r\nwhich is all we support right now -- of the user's program."}),"\n",(0,r.jsx)(n.h3,{id:"creating-functions-at-compile-time",children:"Creating functions at compile time"}),"\n",(0,r.jsxs)(n.p,{children:["We start threading this through in ",(0,r.jsx)(n.code,{children:"compile()"}),", which is the main entry point\r\ninto the compiler."]}),"\n",(0,r.jsx)(n.p,{children:"^code call-init-compiler (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"There are a bunch of changes in how the compiler is initialized. First, we\r\ninitialize the new Compiler fields."}),"\n",(0,r.jsx)(n.p,{children:"^code init-compiler (1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Then we allocate a new function object to compile into."}),"\n",(0,r.jsx)(n.p,{children:"^code init-function (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"null"})}),"\n",(0,r.jsxs)(n.aside,{name:"null",children:["\n",(0,r.jsxs)(n.p,{children:["I know, it looks dumb to null the ",(0,r.jsx)(n.code,{children:"function"})," field only to immediately assign it\r\na value a few lines later. More garbage collection-related paranoia."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Creating an ObjFunction in the compiler might seem a little strange. A function\r\nobject is the ",(0,r.jsx)(n.em,{children:"runtime"})," representation of a function, but here we are creating\r\nit at compile time. The way to think of it is that a function is similar to a\r\nstring or number literal. It forms a bridge between the compile time and runtime\r\nworlds. When we get to function ",(0,r.jsx)(n.em,{children:"declarations"}),", those really ",(0,r.jsx)(n.em,{children:"are"})," literals\r\n-- they are a notation that produces values of a built-in type. So the ",(0,r.jsx)(n.span,{name:"closure",children:"compiler"})," creates function objects during compilation.\r\nThen, at runtime, they are simply invoked."]}),"\n",(0,r.jsxs)(n.aside,{name:"closure",children:["\n",(0,r.jsxs)(n.p,{children:["We can create functions at compile time because they contain only data available\r\nat compile time. The function's code, name, and arity are all fixed. When we add\r\nclosures in the ",(0,r.jsx)(n.a,{href:"closures.html",children:"next chapter"}),", which capture variables at runtime,\r\nthe story gets more complex."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Here is another strange piece of code:"}),"\n",(0,r.jsx)(n.p,{children:"^code init-function-slot (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Remember that the compiler's ",(0,r.jsx)(n.code,{children:"locals"})," array keeps track of which stack slots are\r\nassociated with which local variables or temporaries. From now on, the compiler\r\nimplicitly claims stack slot zero for the VM's own internal use. We give it an\r\nempty name so that the user can't write an identifier that refers to it. I'll\r\nexplain what this is about when it becomes useful."]}),"\n",(0,r.jsx)(n.p,{children:"That's the initialization side. We also need a couple of changes on the other\r\nend when we finish compiling some code."}),"\n",(0,r.jsx)(n.p,{children:"^code end-compiler (1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Previously, when ",(0,r.jsx)(n.code,{children:"interpret()"})," called into the compiler, it passed in a Chunk to\r\nbe written to. Now that the compiler creates the function object itself, we\r\nreturn that function. We grab it from the current compiler here:"]}),"\n",(0,r.jsx)(n.p,{children:"^code end-function (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["And then return it to ",(0,r.jsx)(n.code,{children:"compile()"})," like so:"]}),"\n",(0,r.jsx)(n.p,{children:"^code return-function (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Now is a good time to make another tweak in this function. Earlier, we added\r\nsome diagnostic code to have the VM dump the disassembled bytecode so we could\r\ndebug the compiler. We should fix that to keep working now that the generated\r\nchunk is wrapped in a function."}),"\n",(0,r.jsx)(n.p,{children:"^code disassemble-end (2 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Notice the check in here to see if the function's name is ",(0,r.jsx)(n.code,{children:"NULL"}),"? User-defined\r\nfunctions have names, but the implicit function we create for the top-level code\r\ndoes not, and we need to handle that gracefully even in our own diagnostic code.\r\nSpeaking of which:"]}),"\n",(0,r.jsx)(n.p,{children:"^code print-script (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["There's no way for a ",(0,r.jsx)(n.em,{children:"user"})," to get a reference to the top-level function and try\r\nto print it, but our ",(0,r.jsx)(n.code,{children:"DEBUG_TRACE_EXECUTION"})," ",(0,r.jsx)(n.span,{name:"debug",children:"diagnostic"})," code that prints the entire stack can and does."]}),"\n",(0,r.jsxs)(n.aside,{name:"debug",children:["\n",(0,r.jsx)(n.p,{children:"It is no fun if the diagnostic code we use to find bugs itself causes the VM to\r\nsegfault!"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Bumping up a level to ",(0,r.jsx)(n.code,{children:"compile()"}),", we adjust its signature."]}),"\n",(0,r.jsx)(n.p,{children:"^code compile-h (2 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"Instead of taking a chunk, now it returns a function. Over in the\r\nimplementation:"}),"\n",(0,r.jsx)(n.p,{children:"^code compile-signature (1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Finally we get to some actual code. We change the very end of the function to\r\nthis:"}),"\n",(0,r.jsx)(n.p,{children:"^code call-end-compiler (4 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["We get the function object from the compiler. If there were no compile errors,\r\nwe return it. Otherwise, we signal an error by returning ",(0,r.jsx)(n.code,{children:"NULL"}),". This way, the\r\nVM doesn't try to execute a function that may contain invalid bytecode."]}),"\n",(0,r.jsxs)(n.p,{children:["Eventually, we will update ",(0,r.jsx)(n.code,{children:"interpret()"})," to handle the new declaration of\r\n",(0,r.jsx)(n.code,{children:"compile()"}),", but first we have some other changes to make."]}),"\n",(0,r.jsx)(n.h2,{id:"call-frames",children:"Call Frames"}),"\n",(0,r.jsx)(n.p,{children:"It's time for a big conceptual leap. Before we can implement function\r\ndeclarations and calls, we need to get the VM ready to handle them. There are\r\ntwo main problems we need to worry about:"}),"\n",(0,r.jsx)(n.h3,{id:"allocating-local-variables",children:"Allocating local variables"}),"\n",(0,r.jsx)(n.p,{children:"The compiler allocates stack slots for local variables. How should that work\r\nwhen the set of local variables in a program is distributed across multiple\r\nfunctions?"}),"\n",(0,r.jsxs)(n.p,{children:["One option would be to keep them totally separate. Each function would get its\r\nown dedicated set of slots in the VM stack that it would own ",(0,r.jsx)(n.span,{name:"static",children:"forever"}),", even when the function isn't being called. Each\r\nlocal variable in the entire program would have a bit of memory in the VM that\r\nit keeps to itself."]}),"\n",(0,r.jsxs)(n.aside,{name:"static",children:["\n",(0,r.jsxs)(n.p,{children:["It's basically what you'd get if you declared every local variable in a C\r\nprogram using ",(0,r.jsx)(n.code,{children:"static"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Believe it or not, early programming language implementations worked this way.\r\nThe first Fortran compilers statically allocated memory for each variable. The\r\nobvious problem is that it's really inefficient. Most functions are not in the\r\nmiddle of being called at any point in time, so sitting on unused memory for\r\nthem is wasteful."}),"\n",(0,r.jsxs)(n.p,{children:['The more fundamental problem, though, is recursion. With recursion, you can be\r\n"in" multiple calls to the same function at the same time. Each needs its ',(0,r.jsx)(n.span,{name:"fortran",children:"own"})," memory for its local variables. In jlox, we solved\r\nthis by dynamically allocating memory for an environment each time a function\r\nwas called or a block entered. In clox, we don't want that kind of performance\r\ncost on every function call."]}),"\n",(0,r.jsxs)(n.aside,{name:"fortran",children:["\n",(0,r.jsx)(n.p,{children:"Fortran avoided this problem by disallowing recursion entirely. Recursion was\r\nconsidered an advanced, esoteric feature at the time."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Instead, our solution lies somewhere between Fortran's static allocation and\r\njlox's dynamic approach. The value stack in the VM works on the observation that\r\nlocal variables and temporaries behave in a last-in first-out fashion.\r\nFortunately for us, that's still true even when you add function calls into the\r\nmix. Here's an example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"fun first() {\r\n  var a = 1;\r\n  second();\r\n  var b = 2;\r\n}\r\n\r\nfun second() {\r\n  var c = 3;\r\n  var d = 4;\r\n}\r\n\r\nfirst();\n"})}),"\n",(0,r.jsx)(n.p,{children:"Step through the program and look at which variables are in memory at each point\r\nin time:"}),"\n",(0,r.jsx)(n.img,{src:"image/calls-and-functions/calls.png",alt:"Tracing through the execution of the previous program, showing the stack of variables at each step."}),"\n",(0,r.jsxs)(n.p,{children:["As execution flows through the two calls, every local variable obeys the\r\nprinciple that any variable declared after it will be discarded before the first\r\nvariable needs to be. This is true even across calls. We know we'll be done with\r\n",(0,r.jsx)(n.code,{children:"c"})," and ",(0,r.jsx)(n.code,{children:"d"})," before we are done with ",(0,r.jsx)(n.code,{children:"a"}),". It seems we should be able to allocate\r\nlocal variables on the VM's value stack."]}),"\n",(0,r.jsxs)(n.p,{children:["Ideally, we still determine ",(0,r.jsx)(n.em,{children:"where"})," on the stack each variable will go at\r\ncompile time. That keeps the bytecode instructions for working with variables\r\nsimple and fast. In the above example, we could ",(0,r.jsx)(n.span,{name:"imagine",children:"imagine"})," doing so in a straightforward way, but that\r\ndoesn't always work out. Consider:"]}),"\n",(0,r.jsxs)(n.aside,{name:"imagine",children:["\n",(0,r.jsx)(n.p,{children:"I say \"imagine\" because the compiler can't actually figure this out. Because\r\nfunctions are first class in Lox, we can't determine which functions call which\r\nothers at compile time."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"fun first() {\r\n  var a = 1;\r\n  second();\r\n  var b = 2;\r\n  second();\r\n}\r\n\r\nfun second() {\r\n  var c = 3;\r\n  var d = 4;\r\n}\r\n\r\nfirst();\n"})}),"\n",(0,r.jsxs)(n.p,{children:["In the first call to ",(0,r.jsx)(n.code,{children:"second()"}),", ",(0,r.jsx)(n.code,{children:"c"})," and ",(0,r.jsx)(n.code,{children:"d"})," would go into slots 1 and 2. But in\r\nthe second call, we need to have made room for ",(0,r.jsx)(n.code,{children:"b"}),", so ",(0,r.jsx)(n.code,{children:"c"})," and ",(0,r.jsx)(n.code,{children:"d"})," need to be in\r\nslots 2 and 3. Thus the compiler can't pin down an exact slot for each local\r\nvariable across function calls. But ",(0,r.jsx)(n.em,{children:"within"})," a given function, the ",(0,r.jsx)(n.em,{children:"relative"}),"\r\nlocations of each local variable are fixed. Variable ",(0,r.jsx)(n.code,{children:"d"})," is always in the slot\r\nright after ",(0,r.jsx)(n.code,{children:"c"}),". This is the key insight."]}),"\n",(0,r.jsx)(n.p,{children:"When a function is called, we don't know where the top of the stack will be\r\nbecause it can be called from different contexts. But, wherever that top happens\r\nto be, we do know where all of the function's local variables will be relative\r\nto that starting point. So, like many problems, we solve our allocation problem\r\nwith a level of indirection."}),"\n",(0,r.jsx)(n.p,{children:"At the beginning of each function call, the VM records the location of the first\r\nslot where that function's own locals begin. The instructions for working with\r\nlocal variables access them by a slot index relative to that, instead of\r\nrelative to the bottom of the stack like they do today. At compile time, we\r\ncalculate those relative slots. At runtime, we convert that relative slot to an\r\nabsolute stack index by adding the function call's starting slot."}),"\n",(0,r.jsxs)(n.p,{children:['It\'s as if the function gets a "window" or "frame" within the larger stack where\r\nit can store its locals. The position of the ',(0,r.jsx)(n.strong,{children:"call frame"})," is determined at\r\nruntime, but within and relative to that region, we know where to find things."]}),"\n",(0,r.jsx)(n.img,{src:"image/calls-and-functions/window.png",alt:"The stack at the two points when second() is called, with a window hovering over each one showing the pair of stack slots used by the function."}),"\n",(0,r.jsxs)(n.p,{children:["The historical name for this recorded location where the function's locals start\r\nis a ",(0,r.jsx)(n.strong,{children:"frame pointer"})," because it points to the beginning of the function's call\r\nframe. Sometimes you hear ",(0,r.jsx)(n.strong,{children:"base pointer"}),", because it points to the base stack\r\nslot on top of which all of the function's variables live."]}),"\n",(0,r.jsx)(n.p,{children:"That's the first piece of data we need to track. Every time we call a function,\r\nthe VM determines the first stack slot where that function's variables begin."}),"\n",(0,r.jsx)(n.h3,{id:"return-addresses",children:"Return addresses"}),"\n",(0,r.jsxs)(n.p,{children:["Right now, the VM works its way through the instruction stream by incrementing\r\nthe ",(0,r.jsx)(n.code,{children:"ip"})," field. The only interesting behavior is around control flow\r\ninstructions which offset the ",(0,r.jsx)(n.code,{children:"ip"})," by larger amounts. ",(0,r.jsx)(n.em,{children:"Calling"})," a function is\r\npretty straightforward -- simply set ",(0,r.jsx)(n.code,{children:"ip"})," to point to the first instruction in\r\nthat function's chunk. But what about when the function is done?"]}),"\n",(0,r.jsxs)(n.p,{children:["The VM needs to ",(0,r.jsx)(n.span,{name:"return",children:"return"})," back to the chunk where the\r\nfunction was called from and resume execution at the instruction immediately\r\nafter the call. Thus, for each function call, we need to track where we jump\r\nback to when the call completes. This is called a ",(0,r.jsx)(n.strong,{children:"return address"})," because\r\nit's the address of the instruction that the VM returns to after the call."]}),"\n",(0,r.jsxs)(n.p,{children:["Again, thanks to recursion, there may be multiple return addresses for a single\r\nfunction, so this is a property of each ",(0,r.jsx)(n.em,{children:"invocation"})," and not the function\r\nitself."]}),"\n",(0,r.jsxs)(n.aside,{name:"return",children:["\n",(0,r.jsxs)(n.p,{children:["The authors of early Fortran compilers had a clever trick for implementing\r\nreturn addresses. Since they ",(0,r.jsx)(n.em,{children:"didn't"})," support recursion, any given function\r\nneeded only a single return address at any point in time. So when a function was\r\ncalled at runtime, the program would ",(0,r.jsx)(n.em,{children:"modify its own code"})," to change a jump\r\ninstruction at the end of the function to jump back to its caller. Sometimes the\r\nline between genius and madness is hair thin."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"the-call-stack",children:"The call stack"}),"\n",(0,r.jsx)(n.p,{children:"So for each live function invocation -- each call that hasn't returned yet -- we\r\nneed to track where on the stack that function's locals begin, and where the\r\ncaller should resume. We'll put this, along with some other stuff, in a new\r\nstruct."}),"\n",(0,r.jsx)(n.p,{children:"^code call-frame (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["A CallFrame represents a single ongoing function call. The ",(0,r.jsx)(n.code,{children:"slots"})," field points\r\ninto the VM's value stack at the first slot that this function can use. I gave\r\nit a plural name because -- thanks to C's weird \"pointers are sort of arrays\"\r\nthing -- we'll treat it like an array."]}),"\n",(0,r.jsxs)(n.p,{children:["The implementation of return addresses is a little different from what I\r\ndescribed above. Instead of storing the return address in the callee's frame,\r\nthe caller stores its own ",(0,r.jsx)(n.code,{children:"ip"}),". When we return from a function, the VM will jump\r\nto the ",(0,r.jsx)(n.code,{children:"ip"})," of the caller's CallFrame and resume from there."]}),"\n",(0,r.jsx)(n.p,{children:"I also stuffed a pointer to the function being called in here. We'll use that to\r\nlook up constants and for a few other things."}),"\n",(0,r.jsxs)(n.p,{children:["Each time a function is called, we create one of these structs. We could ",(0,r.jsx)(n.span,{name:"heap",children:"dynamically"})," allocate them on the heap, but that's slow.\r\nFunction calls are a core operation, so they need to be as fast as possible.\r\nFortunately, we can make the same observation we made for variables: function\r\ncalls have stack semantics. If ",(0,r.jsx)(n.code,{children:"first()"})," calls ",(0,r.jsx)(n.code,{children:"second()"}),", the call to\r\n",(0,r.jsx)(n.code,{children:"second()"})," will complete before ",(0,r.jsx)(n.code,{children:"first()"})," does."]}),"\n",(0,r.jsxs)(n.aside,{name:"heap",children:["\n",(0,r.jsxs)(n.p,{children:["Many Lisp implementations dynamically allocate stack frames because it\r\nsimplifies implementing ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Continuation",children:"continuations"}),". If your language supports\r\ncontinuations, then function calls do ",(0,r.jsx)(n.em,{children:"not"})," always have stack semantics."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"So over in the VM, we create an array of these CallFrame structs up front and\r\ntreat it as a stack, like we do with the value array."}),"\n",(0,r.jsx)(n.p,{children:"^code frame-array (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["This array replaces the ",(0,r.jsx)(n.code,{children:"chunk"})," and ",(0,r.jsx)(n.code,{children:"ip"})," fields we used to have directly in the\r\nVM. Now each CallFrame has its own ",(0,r.jsx)(n.code,{children:"ip"})," and its own pointer to the ObjFunction\r\nthat it's executing. From there, we can get to the function's chunk."]}),"\n",(0,r.jsxs)(n.p,{children:["The new ",(0,r.jsx)(n.code,{children:"frameCount"})," field in the VM stores the current height of the CallFrame\r\nstack -- the number of ongoing function calls. To keep clox simple, the array's\r\ncapacity is fixed. This means, as in many language implementations, there is a\r\nmaximum call depth we can handle. For clox, it's defined here:"]}),"\n",(0,r.jsx)(n.p,{children:"^code frame-max (2 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["We also redefine the value stack's ",(0,r.jsx)(n.span,{name:"plenty",children:"size"})," in terms of\r\nthat to make sure we have plenty of stack slots even in very deep call trees.\r\nWhen the VM starts up, the CallFrame stack is empty."]}),"\n",(0,r.jsxs)(n.aside,{name:"plenty",children:["\n",(0,r.jsx)(n.p,{children:"It is still possible to overflow the stack if enough function calls use enough\r\ntemporaries in addition to locals. A robust implementation would guard against\r\nthis, but I'm trying to keep things simple."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code reset-frame-count (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:'The "vm.h" header needs access to ObjFunction, so we add an include.'}),"\n",(0,r.jsx)(n.p,{children:"^code vm-include-object (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Now we're ready to move over to the VM's implementation file. We've got some\r\ngrunt work ahead of us. We've moved ",(0,r.jsx)(n.code,{children:"ip"})," out of the VM struct and into\r\nCallFrame. We need to fix every line of code in the VM that touches ",(0,r.jsx)(n.code,{children:"ip"})," to\r\nhandle that. Also, the instructions that access local variables by stack slot\r\nneed to be updated to do so relative to the current CallFrame's ",(0,r.jsx)(n.code,{children:"slots"})," field."]}),"\n",(0,r.jsx)(n.p,{children:"We'll start at the top and plow through it."}),"\n",(0,r.jsx)(n.p,{children:"^code run (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["First, we store the current topmost CallFrame in a ",(0,r.jsx)(n.span,{name:"local",children:"local"})," variable inside the main bytecode execution function.\r\nThen we replace the bytecode access macros with versions that access ",(0,r.jsx)(n.code,{children:"ip"}),"\r\nthrough that variable."]}),"\n",(0,r.jsxs)(n.aside,{name:"local",children:["\n",(0,r.jsxs)(n.p,{children:["We could access the current frame by going through the CallFrame array every\r\ntime, but that's verbose. More importantly, storing the frame in a local\r\nvariable encourages the C compiler to keep that pointer in a register. That\r\nspeeds up access to the frame's ",(0,r.jsx)(n.code,{children:"ip"}),". There's no ",(0,r.jsx)(n.em,{children:"guarantee"})," that the compiler\r\nwill do this, but there's a good chance it will."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Now onto each instruction that needs a little tender loving care."}),"\n",(0,r.jsx)(n.p,{children:"^code push-local (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Previously, ",(0,r.jsx)(n.code,{children:"OP_GET_LOCAL"})," read the given local slot directly from the VM's\r\nstack array, which meant it indexed the slot starting from the bottom of the\r\nstack. Now, it accesses the current frame's ",(0,r.jsx)(n.code,{children:"slots"})," array, which means it\r\naccesses the given numbered slot relative to the beginning of that frame."]}),"\n",(0,r.jsx)(n.p,{children:"Setting a local variable works the same way."}),"\n",(0,r.jsx)(n.p,{children:"^code set-local (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["The jump instructions used to modify the VM's ",(0,r.jsx)(n.code,{children:"ip"})," field. Now, they do the same\r\nfor the current frame's ",(0,r.jsx)(n.code,{children:"ip"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"^code jump (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Same with the conditional jump:"}),"\n",(0,r.jsx)(n.p,{children:"^code jump-if-false (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"And our backward-jumping loop instruction:"}),"\n",(0,r.jsx)(n.p,{children:"^code loop (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"We have some diagnostic code that prints each instruction as it executes to help\r\nus debug our VM. That needs to work with the new structure too."}),"\n",(0,r.jsx)(n.p,{children:"^code trace-execution (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Instead of passing in the VM's ",(0,r.jsx)(n.code,{children:"chunk"})," and ",(0,r.jsx)(n.code,{children:"ip"})," fields, now we read from the\r\ncurrent CallFrame."]}),"\n",(0,r.jsxs)(n.p,{children:["You know, that wasn't too bad, actually. Most instructions just use the macros\r\nso didn't need to be touched. Next, we jump up a level to the code that calls\r\n",(0,r.jsx)(n.code,{children:"run()"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"^code interpret-stub (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["We finally get to wire up our earlier compiler changes to the back-end changes\r\nwe just made. First, we pass the source code to the compiler. It returns us a\r\nnew ObjFunction containing the compiled top-level code. If we get ",(0,r.jsx)(n.code,{children:"NULL"})," back,\r\nit means there was some compile-time error which the compiler has already\r\nreported. In that case, we bail out since we can't run anything."]}),"\n",(0,r.jsxs)(n.p,{children:["Otherwise, we store the function on the stack and prepare an initial CallFrame\r\nto execute its code. Now you can see why the compiler sets aside stack slot zero\r\n-- that stores the function being called. In the new CallFrame, we point to the\r\nfunction, initialize its ",(0,r.jsx)(n.code,{children:"ip"})," to point to the beginning of the function's\r\nbytecode, and set up its stack window to start at the very bottom of the VM's\r\nvalue stack."]}),"\n",(0,r.jsxs)(n.p,{children:["This gets the interpreter ready to start executing code. After finishing, the VM\r\nused to free the hardcoded chunk. Now that the ObjFunction owns that code, we\r\ndon't need to do that anymore, so the end of ",(0,r.jsx)(n.code,{children:"interpret()"})," is simply this:"]}),"\n",(0,r.jsx)(n.p,{children:"^code end-interpret (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["The last piece of code referring to the old VM fields is ",(0,r.jsx)(n.code,{children:"runtimeError()"}),". We'll\r\nrevisit that later in the chapter, but for now let's change it to this:"]}),"\n",(0,r.jsx)(n.p,{children:"^code runtime-error-temp (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Instead of reading the chunk and ",(0,r.jsx)(n.code,{children:"ip"})," directly from the VM, it pulls those from\r\nthe topmost CallFrame on the stack. That should get the function working again\r\nand behaving as it did before."]}),"\n",(0,r.jsx)(n.p,{children:"Assuming we did all of that correctly, we got clox back to a runnable\r\nstate. Fire it up and it does... exactly what it did before. We haven't added\r\nany new features yet, so this is kind of a let down. But all of the\r\ninfrastructure is there and ready for us now. Let's take advantage of it."}),"\n",(0,r.jsx)(n.h2,{id:"function-declarations",children:"Function Declarations"}),"\n",(0,r.jsxs)(n.p,{children:["Before we can do call expressions, we need something to call, so we'll do\r\nfunction declarations first. The ",(0,r.jsx)(n.span,{name:"fun",children:"fun"})," starts with a\r\nkeyword."]}),"\n",(0,r.jsxs)(n.aside,{name:"fun",children:["\n",(0,r.jsxs)(n.p,{children:["Yes, I am going to make a dumb joke about the ",(0,r.jsx)(n.code,{children:"fun"})," keyword every time it\r\ncomes up."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code match-fun (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"That passes control to here:"}),"\n",(0,r.jsx)(n.p,{children:"^code fun-declaration"}),"\n",(0,r.jsx)(n.p,{children:"Functions are first-class values, and a function declaration simply creates and\r\nstores one in a newly declared variable. So we parse the name just like any\r\nother variable declaration. A function declaration at the top level will bind\r\nthe function to a global variable. Inside a block or other function, a function\r\ndeclaration creates a local variable."}),"\n",(0,r.jsxs)(n.p,{children:["In an earlier chapter, I explained how variables ",(0,r.jsx)(n.a,{href:"local-variables.html#another-scope-edge-case",children:"get defined in two\r\nstages"}),". This ensures you can't access a variable's value inside the\r\nvariable's own initializer. That would be bad because the variable doesn't\r\n",(0,r.jsx)(n.em,{children:"have"})," a value yet."]}),"\n",(0,r.jsxs)(n.p,{children:["Functions don't suffer from this problem. It's safe for a function to refer to\r\nits own name inside its body. You can't ",(0,r.jsx)(n.em,{children:"call"})," the function and execute the body\r\nuntil after it's fully defined, so you'll never see the variable in an\r\nuninitialized state. Practically speaking, it's useful to allow this in order to\r\nsupport recursive local functions."]}),"\n",(0,r.jsx)(n.p,{children:'To make that work, we mark the function declaration\'s variable "initialized" as\r\nsoon as we compile the name, before we compile the body. That way the name can\r\nbe referenced inside the body without generating an error.'}),"\n",(0,r.jsx)(n.p,{children:"We do need one check, though."}),"\n",(0,r.jsx)(n.p,{children:"^code check-depth (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Before, we called ",(0,r.jsx)(n.code,{children:"markInitialized()"})," only when we already knew we were in a\r\nlocal scope. Now, a top-level function declaration will also call this function.\r\nWhen that happens, there is no local variable to mark initialized -- the\r\nfunction is bound to a global variable."]}),"\n",(0,r.jsxs)(n.p,{children:["Next, we compile the function itself -- its parameter list and block body. For\r\nthat, we use a separate helper function. That helper generates code that\r\nleaves the resulting function object on top of the stack. After that, we call\r\n",(0,r.jsx)(n.code,{children:"defineVariable()"})," to store that function back into the variable we declared for\r\nit."]}),"\n",(0,r.jsx)(n.p,{children:"I split out the code to compile the parameters and body because we'll reuse it\r\nlater for parsing method declarations inside classes. Let's build it\r\nincrementally, starting with this:"}),"\n",(0,r.jsx)(n.p,{children:"^code compile-function"}),"\n",(0,r.jsxs)(n.aside,{name:"no-end-scope",children:["\n",(0,r.jsxs)(n.p,{children:["This ",(0,r.jsx)(n.code,{children:"beginScope()"})," doesn't have a corresponding ",(0,r.jsx)(n.code,{children:"endScope()"})," call. Because we\r\nend Compiler completely when we reach the end of the function body, there's no\r\nneed to close the lingering outermost scope."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["For now, we won't worry about parameters. We parse an empty pair of parentheses\r\nfollowed by the body. The body starts with a left curly brace, which we parse\r\nhere. Then we call our existing ",(0,r.jsx)(n.code,{children:"block()"})," function, which knows how to compile\r\nthe rest of a block including the closing brace."]}),"\n",(0,r.jsx)(n.h3,{id:"a-stack-of-compilers",children:"A stack of compilers"}),"\n",(0,r.jsxs)(n.p,{children:["The interesting parts are the compiler stuff at the top and bottom. The Compiler\r\nstruct stores data like which slots are owned by which local variables, how many\r\nblocks of nesting we're currently in, etc. All of that is specific to a single\r\nfunction. But now the front end needs to handle compiling multiple functions\r\n",(0,r.jsx)(n.span,{name:"nested",children:"nested"})," within each other."]}),"\n",(0,r.jsxs)(n.aside,{name:"nested",children:["\n",(0,r.jsxs)(n.p,{children:["Remember that the compiler treats top-level code as the body of an implicit\r\nfunction, so as soon as we add ",(0,r.jsx)(n.em,{children:"any"})," function declarations, we're in a world of\r\nnested functions."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The trick for managing that is to create a separate Compiler for each function\r\nbeing compiled. When we start compiling a function declaration, we create a new\r\nCompiler on the C stack and initialize it. ",(0,r.jsx)(n.code,{children:"initCompiler()"})," sets that Compiler\r\nto be the current one. Then, as we compile the body, all of the functions that\r\nemit bytecode write to the chunk owned by the new Compiler's function."]}),"\n",(0,r.jsxs)(n.p,{children:["After we reach the end of the function's block body, we call ",(0,r.jsx)(n.code,{children:"endCompiler()"}),".\r\nThat yields the newly compiled function object, which we store as a constant in\r\nthe ",(0,r.jsx)(n.em,{children:"surrounding"})," function's constant table. But, wait, how do we get back to\r\nthe surrounding function? We lost it when ",(0,r.jsx)(n.code,{children:"initCompiler()"})," overwrote the current\r\ncompiler pointer."]}),"\n",(0,r.jsx)(n.p,{children:"We fix that by treating the series of nested Compiler structs as a stack. Unlike\r\nthe Value and CallFrame stacks in the VM, we won't use an array. Instead, we use\r\na linked list. Each Compiler points back to the Compiler for the function that\r\nencloses it, all the way back to the root Compiler for the top-level code."}),"\n",(0,r.jsx)(n.p,{children:"^code enclosing-field (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Inside the Compiler struct, we can't reference the Compiler ",(0,r.jsx)(n.em,{children:"typedef"})," since that\r\ndeclaration hasn't finished yet. Instead, we give a name to the struct itself\r\nand use that for the field's type. C is weird."]}),"\n",(0,r.jsx)(n.p,{children:"When initializing a new Compiler, we capture the about-to-no-longer-be-current\r\none in that pointer."}),"\n",(0,r.jsx)(n.p,{children:"^code store-enclosing (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Then when a Compiler finishes, it pops itself off the stack by restoring the\r\nprevious compiler to be the new current one."}),"\n",(0,r.jsx)(n.p,{children:"^code restore-enclosing (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Note that we don't even need to ",(0,r.jsx)(n.span,{name:"compiler",children:"dynamically"}),"\r\nallocate the Compiler structs. Each is stored as a local variable in the C stack\r\n-- either in ",(0,r.jsx)(n.code,{children:"compile()"})," or ",(0,r.jsx)(n.code,{children:"function()"}),". The linked list of Compilers threads\r\nthrough the C stack. The reason we can get an unbounded number of them is\r\nbecause our compiler uses recursive descent, so ",(0,r.jsx)(n.code,{children:"function()"})," ends up calling\r\nitself recursively when you have nested function declarations."]}),"\n",(0,r.jsxs)(n.aside,{name:"compiler",children:["\n",(0,r.jsx)(n.p,{children:"Using the native stack for Compiler structs does mean our compiler has a\r\npractical limit on how deeply nested function declarations can be. Go too far\r\nand you could overflow the C stack. If we want the compiler to be more robust\r\nagainst pathological or even malicious code -- a real concern for tools like\r\nJavaScript VMs -- it would be good to have our compiler artificially limit the\r\namount of function nesting it permits."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"function-parameters",children:"Function parameters"}),"\n",(0,r.jsx)(n.p,{children:"Functions aren't very useful if you can't pass arguments to them, so let's do\r\nparameters next."}),"\n",(0,r.jsx)(n.p,{children:"^code parameters (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Semantically, a parameter is simply a local variable declared in the outermost\r\nlexical scope of the function body. We get to use the existing compiler support\r\nfor declaring named local variables to parse and compile parameters. Unlike\r\nlocal variables, which have initializers, there's no code here to initialize the\r\nparameter's value. We'll see how they are initialized later when we do argument\r\npassing in function calls."}),"\n",(0,r.jsxs)(n.p,{children:["While we're at it, we note the function's arity by counting how many parameters\r\nwe parse. The other piece of metadata we store with a function is its name. When\r\ncompiling a function declaration, we call ",(0,r.jsx)(n.code,{children:"initCompiler()"})," right after we parse\r\nthe function's name. That means we can grab the name right then from the\r\nprevious token."]}),"\n",(0,r.jsx)(n.p,{children:"^code init-function-name (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"Note that we're careful to create a copy of the name string. Remember, the\r\nlexeme points directly into the original source code string. That string may get\r\nfreed once the code is finished compiling. The function object we create in the\r\ncompiler outlives the compiler and persists until runtime. So it needs its own\r\nheap-allocated name string that it can keep around."}),"\n",(0,r.jsx)(n.p,{children:"Rad. Now we can compile function declarations, like this:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'fun areWeHavingItYet() {\r\n  print "Yes we are!";\r\n}\r\n\r\nprint areWeHavingItYet;\n'})}),"\n",(0,r.jsxs)(n.p,{children:["We just can't do anything ",(0,r.jsx)(n.span,{name:"useful",children:"useful"})," with them."]}),"\n",(0,r.jsxs)(n.aside,{name:"useful",children:["\n",(0,r.jsx)(n.p,{children:"We can print them! I guess that's not very useful, though."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"function-calls",children:"Function Calls"}),"\n",(0,r.jsxs)(n.p,{children:["By the end of this section, we'll start to see some interesting behavior. The\r\nnext step is calling functions. We don't usually think of it this way, but a\r\nfunction call expression is kind of an infix ",(0,r.jsx)(n.code,{children:"("})," operator. You have a\r\nhigh-precedence expression on the left for the thing being called -- usually\r\njust a single identifier. Then the ",(0,r.jsx)(n.code,{children:"("})," in the middle, followed by the argument\r\nexpressions separated by commas, and a final ",(0,r.jsx)(n.code,{children:")"})," to wrap it up at the end."]}),"\n",(0,r.jsx)(n.p,{children:"That odd grammatical perspective explains how to hook the syntax into our\r\nparsing table."}),"\n",(0,r.jsx)(n.p,{children:"^code infix-left-paren (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"When the parser encounters a left parenthesis following an expression, it\r\ndispatches to a new parser function."}),"\n",(0,r.jsx)(n.p,{children:"^code compile-call"}),"\n",(0,r.jsxs)(n.p,{children:["We've already consumed the ",(0,r.jsx)(n.code,{children:"("})," token, so next we compile the arguments using a\r\nseparate ",(0,r.jsx)(n.code,{children:"argumentList()"})," helper. That function returns the number of arguments\r\nit compiled. Each argument expression generates code that leaves its value on\r\nthe stack in preparation for the call. After that, we emit a new ",(0,r.jsx)(n.code,{children:"OP_CALL"}),"\r\ninstruction to invoke the function, using the argument count as an operand."]}),"\n",(0,r.jsx)(n.p,{children:"We compile the arguments using this friend:"}),"\n",(0,r.jsx)(n.p,{children:"^code argument-list"}),"\n",(0,r.jsx)(n.p,{children:"That code should look familiar from jlox. We chew through arguments as long as\r\nwe find commas after each expression. Once we run out, we consume the final\r\nclosing parenthesis and we're done."}),"\n",(0,r.jsx)(n.p,{children:"Well, almost. Back in jlox, we added a compile-time check that you don't pass\r\nmore than 255 arguments to a call. At the time, I said that was because clox\r\nwould need a similar limit. Now you can see why -- since we stuff the argument\r\ncount into the bytecode as a single-byte operand, we can only go up to 255. We\r\nneed to verify that in this compiler too."}),"\n",(0,r.jsx)(n.p,{children:"^code arg-limit (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"That's the front end. Let's skip over to the back end, with a quick stop in the\r\nmiddle to declare the new instruction."}),"\n",(0,r.jsx)(n.p,{children:"^code op-call (1 before, 1 after)"}),"\n",(0,r.jsx)(n.h3,{id:"binding-arguments-to-parameters",children:"Binding arguments to parameters"}),"\n",(0,r.jsx)(n.p,{children:"Before we get to the implementation, we should think about what the stack looks\r\nlike at the point of a call and what we need to do from there. When we reach the\r\ncall instruction, we have already executed the expression for the function being\r\ncalled, followed by its arguments. Say our program looks like this:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"fun sum(a, b, c) {\r\n  return a + b + c;\r\n}\r\n\r\nprint 4 + sum(5, 6, 7);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["If we pause the VM right on the ",(0,r.jsx)(n.code,{children:"OP_CALL"})," instruction for that call to ",(0,r.jsx)(n.code,{children:"sum()"}),",\r\nthe stack looks like this:"]}),"\n",(0,r.jsx)(n.img,{src:"image/calls-and-functions/argument-stack.png",alt:"Stack: 4, fn sum, 5, 6, 7."}),"\n",(0,r.jsxs)(n.p,{children:["Picture this from the perspective of ",(0,r.jsx)(n.code,{children:"sum()"})," itself. When the compiler compiled\r\n",(0,r.jsx)(n.code,{children:"sum()"}),", it automatically allocated slot zero. Then, after that, it allocated\r\nlocal slots for the parameters ",(0,r.jsx)(n.code,{children:"a"}),", ",(0,r.jsx)(n.code,{children:"b"}),", and ",(0,r.jsx)(n.code,{children:"c"}),", in order. To perform a call to\r\n",(0,r.jsx)(n.code,{children:"sum()"}),", we need a CallFrame initialized with the function being called and a\r\nregion of stack slots that it can use. Then we need to collect the arguments\r\npassed to the function and get them into the corresponding slots for the\r\nparameters."]}),"\n",(0,r.jsxs)(n.p,{children:["When the VM starts executing the body of ",(0,r.jsx)(n.code,{children:"sum()"}),", we want its stack window to\r\nlook like this:"]}),"\n",(0,r.jsx)(n.img,{src:"image/calls-and-functions/parameter-window.png",alt:"The same stack with the sum() function's call frame window surrounding fn sum, 5, 6, and 7."}),"\n",(0,r.jsxs)(n.p,{children:["Do you notice how the argument slots that the caller sets up and the parameter\r\nslots the callee needs are both in exactly the right order? How convenient! This\r\nis no coincidence. When I talked about each CallFrame having its own window into\r\nthe stack, I never said those windows must be ",(0,r.jsx)(n.em,{children:"disjoint"}),". There's nothing\r\npreventing us from overlapping them, like this:"]}),"\n",(0,r.jsx)(n.img,{src:"image/calls-and-functions/overlapping-windows.png",alt:"The same stack with the top-level call frame covering the entire stack and the sum() function's call frame window surrounding fn sum, 5, 6, and 7."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.span,{name:"lua",children:"The"})," top of the caller's stack contains the function\r\nbeing called followed by the arguments in order. We know the caller doesn't have\r\nany other slots above those in use because any temporaries needed when\r\nevaluating argument expressions have been discarded by now. The bottom of the\r\ncallee's stack overlaps so that the parameter slots exactly line up with where\r\nthe argument values already live."]}),"\n",(0,r.jsxs)(n.aside,{name:"lua",children:["\n",(0,r.jsxs)(n.p,{children:["Different bytecode VMs and real CPU architectures have different ",(0,r.jsx)(n.em,{children:"calling\r\nconventions"}),", which is the specific mechanism they use to pass arguments, store\r\nthe return address, etc. The mechanism I use here is based on Lua's clean, fast\r\nvirtual machine."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This means that we don't need to do ",(0,r.jsx)(n.em,{children:"any"})," work to \"bind an argument to a\r\nparameter\". There's no copying values between slots or across environments. The\r\narguments are already exactly where they need to be. It's hard to beat that for\r\nperformance."]}),"\n",(0,r.jsx)(n.p,{children:"Time to implement the call instruction."}),"\n",(0,r.jsx)(n.p,{children:"^code interpret-call (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["We need to know the function being called and the number of arguments passed to\r\nit. We get the latter from the instruction's operand. That also tells us where\r\nto find the function on the stack by counting past the argument slots from the\r\ntop of the stack. We hand that data off to a separate ",(0,r.jsx)(n.code,{children:"callValue()"})," function. If\r\nthat returns ",(0,r.jsx)(n.code,{children:"false"}),", it means the call caused some sort of runtime error. When\r\nthat happens, we abort the interpreter."]}),"\n",(0,r.jsxs)(n.p,{children:["If ",(0,r.jsx)(n.code,{children:"callValue()"})," is successful, there will be a new frame on the CallFrame stack\r\nfor the called function. The ",(0,r.jsx)(n.code,{children:"run()"})," function has its own cached pointer to the\r\ncurrent frame, so we need to update that."]}),"\n",(0,r.jsx)(n.p,{children:"^code update-frame-after-call (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Since the bytecode dispatch loop reads from that ",(0,r.jsx)(n.code,{children:"frame"})," variable, when the VM\r\ngoes to execute the next instruction, it will read the ",(0,r.jsx)(n.code,{children:"ip"})," from the newly\r\ncalled function's CallFrame and jump to its code. The work for executing that\r\ncall begins here:"]}),"\n",(0,r.jsx)(n.p,{children:"^code call-value"}),"\n",(0,r.jsxs)(n.aside,{name:"switch",children:["\n",(0,r.jsxs)(n.p,{children:["Using a ",(0,r.jsx)(n.code,{children:"switch"})," statement to check a single type is overkill now, but will make\r\nsense when we add cases to handle other callable types."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"There's more going on here than just initializing a new CallFrame. Because Lox\r\nis dynamically typed, there's nothing to prevent a user from writing bad code\r\nlike:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"var notAFunction = 123;\r\nnotAFunction();\n"})}),"\n",(0,r.jsx)(n.p,{children:"If that happens, the runtime needs to safely report an error and halt. So the\r\nfirst thing we do is check the type of the value that we're trying to call. If\r\nit's not a function, we error out. Otherwise, the actual call happens here:"}),"\n",(0,r.jsx)(n.p,{children:"^code call"}),"\n",(0,r.jsxs)(n.p,{children:["This simply initializes the next CallFrame on the stack. It stores a pointer to\r\nthe function being called and points the frame's ",(0,r.jsx)(n.code,{children:"ip"})," to the beginning of the\r\nfunction's bytecode. Finally, it sets up the ",(0,r.jsx)(n.code,{children:"slots"})," pointer to give the frame\r\nits window into the stack. The arithmetic there ensures that the arguments\r\nalready on the stack line up with the function's parameters:"]}),"\n",(0,r.jsx)(n.img,{src:"image/calls-and-functions/arithmetic.png",alt:"The arithmetic to calculate frame->slots from stackTop and argCount."}),"\n",(0,r.jsxs)(n.p,{children:["The funny little ",(0,r.jsx)(n.code,{children:"- 1"})," is to account for stack slot zero which the compiler set\r\naside for when we add methods later. The parameters start at slot one so we\r\nmake the window start one slot earlier to align them with the arguments."]}),"\n",(0,r.jsx)(n.p,{children:"Before we move on, let's add the new instruction to our disassembler."}),"\n",(0,r.jsx)(n.p,{children:"^code disassemble-call (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"And one more quick side trip. Now that we have a handy function for initiating a\r\nCallFrame, we may as well use it to set up the first frame for executing the\r\ntop-level code."}),"\n",(0,r.jsx)(n.p,{children:"^code interpret (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"OK, now back to calls..."}),"\n",(0,r.jsx)(n.h3,{id:"runtime-error-checking",children:"Runtime error checking"}),"\n",(0,r.jsx)(n.p,{children:"The overlapping stack windows work based on the assumption that a call passes\r\nexactly one argument for each of the function's parameters. But, again, because\r\nLox ain't statically typed, a foolish user could pass too many or too few\r\narguments. In Lox, we've defined that to be a runtime error, which we report\r\nlike so:"}),"\n",(0,r.jsx)(n.p,{children:"^code check-arity (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Pretty straightforward. This is why we store the arity of each function inside\r\nthe ObjFunction for it."}),"\n",(0,r.jsx)(n.p,{children:"There's another error we need to report that's less to do with the user's\r\nfoolishness than our own. Because the CallFrame array has a fixed size, we need\r\nto ensure a deep call chain doesn't overflow it."}),"\n",(0,r.jsx)(n.p,{children:"^code check-overflow (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"In practice, if a program gets anywhere close to this limit, there's most likely\r\na bug in some runaway recursive code."}),"\n",(0,r.jsx)(n.h3,{id:"printing-stack-traces",children:"Printing stack traces"}),"\n",(0,r.jsxs)(n.p,{children:["While we're on the subject of runtime errors, let's spend a little time making\r\nthem more useful. Stopping on a runtime error is important to prevent the VM\r\nfrom crashing and burning in some ill-defined way. But simply aborting doesn't\r\nhelp the user fix their code that ",(0,r.jsx)(n.em,{children:"caused"})," that error."]}),"\n",(0,r.jsxs)(n.p,{children:["The classic tool to aid debugging runtime failures is a ",(0,r.jsx)(n.strong,{children:"stack trace"})," -- a\r\nprint out of each function that was still executing when the program died, and\r\nwhere the execution was at the point that it died. Now that we have a call stack\r\nand we've conveniently stored each function's name, we can show that entire\r\nstack when a runtime error disrupts the harmony of the user's existence. It\r\nlooks like this:"]}),"\n",(0,r.jsx)(n.p,{children:"^code runtime-error-stack (2 before, 2 after)"}),"\n",(0,r.jsxs)(n.aside,{name:"minus",children:["\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"- 1"})," is because the IP is already sitting on the next instruction to be\r\nexecuted but we want the stack trace to point to the previous failed\r\ninstruction."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["After printing the error message itself, we walk the call stack from ",(0,r.jsx)(n.span,{name:"top",children:"top"})," (the most recently called function) to bottom (the\r\ntop-level code). For each frame, we find the line number that corresponds to the\r\ncurrent ",(0,r.jsx)(n.code,{children:"ip"})," inside that frame's function. Then we print that line number along\r\nwith the function name."]}),"\n",(0,r.jsxs)(n.aside,{name:"top",children:["\n",(0,r.jsx)(n.p,{children:"There is some disagreement on which order stack frames should be shown in a\r\ntrace. Most put the innermost function as the first line and work their way\r\ntowards the bottom of the stack. Python prints them out in the opposite order.\r\nSo reading from top to bottom tells you how your program got to where it is, and\r\nthe last line is where the error actually occurred."}),"\n",(0,r.jsxs)(n.p,{children:["There's a logic to that style. It ensures you can always see the innermost\r\nfunction even if the stack trace is too long to fit on one screen. On the other\r\nhand, the \"",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Inverted_pyramid_(journalism)",children:"inverted pyramid"}),'" from journalism tells us we should put the most\r\nimportant information ',(0,r.jsx)(n.em,{children:"first"})," in a block of text. In a stack trace, that's the\r\nfunction where the error actually occurred. Most other language implementations\r\ndo that."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"For example, if you run this broken program:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'fun a() { b(); }\r\nfun b() { c(); }\r\nfun c() {\r\n  c("too", "many");\r\n}\r\n\r\na();\n'})}),"\n",(0,r.jsx)(n.p,{children:"It prints out:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"Expected 0 arguments but got 2.\r\n[line 4] in c()\r\n[line 2] in b()\r\n[line 1] in a()\r\n[line 7] in script\n"})}),"\n",(0,r.jsx)(n.p,{children:"That doesn't look too bad, does it?"}),"\n",(0,r.jsx)(n.h3,{id:"returning-from-functions",children:"Returning from functions"}),"\n",(0,r.jsxs)(n.p,{children:["We're getting close. We can call functions, and the VM will execute them. But we\r\ncan't ",(0,r.jsx)(n.em,{children:"return"})," from them yet. We've had an ",(0,r.jsx)(n.code,{children:"OP_RETURN"})," instruction for quite\r\nsome time, but it's always had some kind of temporary code hanging out in it\r\njust to get us out of the bytecode loop. The time has arrived for a real\r\nimplementation."]}),"\n",(0,r.jsx)(n.p,{children:"^code interpret-return (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"When a function returns a value, that value will be on top of the stack. We're\r\nabout to discard the called function's entire stack window, so we pop that\r\nreturn value off and hang on to it. Then we discard the CallFrame for the\r\nreturning function. If that was the very last CallFrame, it means we've finished\r\nexecuting the top-level code. The entire program is done, so we pop the main\r\nscript function from the stack and then exit the interpreter."}),"\n",(0,r.jsx)(n.p,{children:"Otherwise, we discard all of the slots the callee was using for its parameters\r\nand local variables. That includes the same slots the caller used to pass the\r\narguments. Now that the call is done, the caller doesn't need them anymore. This\r\nmeans the top of the stack ends up right at the beginning of the returning\r\nfunction's stack window."}),"\n",(0,r.jsxs)(n.p,{children:["We push the return value back onto the stack at that new, lower location. Then\r\nwe update the ",(0,r.jsx)(n.code,{children:"run()"})," function's cached pointer to the current frame. Just like\r\nwhen we began a call, on the next iteration of the bytecode dispatch loop, the\r\nVM will read ",(0,r.jsx)(n.code,{children:"ip"})," from that frame, and execution will jump back to the caller,\r\nright where it left off, immediately after the ",(0,r.jsx)(n.code,{children:"OP_CALL"})," instruction."]}),"\n",(0,r.jsx)(n.img,{src:"image/calls-and-functions/return.png",alt:"Each step of the return process: popping the return value, discarding the call frame, pushing the return value."}),"\n",(0,r.jsxs)(n.p,{children:["Note that we assume here that the function ",(0,r.jsx)(n.em,{children:"did"})," actually return a value, but\r\na function can implicitly return by reaching the end of its body:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'fun noReturn() {\r\n  print "Do stuff";\r\n  // No return here.\r\n}\r\n\r\nprint noReturn(); // ???\n'})}),"\n",(0,r.jsxs)(n.p,{children:["We need to handle that correctly too. The language is specified to implicitly\r\nreturn ",(0,r.jsx)(n.code,{children:"nil"})," in that case. To make that happen, we add this:"]}),"\n",(0,r.jsx)(n.p,{children:"^code return-nil (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["The compiler calls ",(0,r.jsx)(n.code,{children:"emitReturn()"})," to write the ",(0,r.jsx)(n.code,{children:"OP_RETURN"})," instruction at the\r\nend of a function body. Now, before that, it emits an instruction to push ",(0,r.jsx)(n.code,{children:"nil"}),"\r\nonto the stack. And with that, we have working function calls! They can even\r\ntake parameters! It almost looks like we know what we're doing here."]}),"\n",(0,r.jsx)(n.h2,{id:"return-statements",children:"Return Statements"}),"\n",(0,r.jsxs)(n.p,{children:["If you want a function that returns something other than the implicit ",(0,r.jsx)(n.code,{children:"nil"}),", you\r\nneed a ",(0,r.jsx)(n.code,{children:"return"})," statement. Let's get that working."]}),"\n",(0,r.jsx)(n.p,{children:"^code match-return (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["When the compiler sees a ",(0,r.jsx)(n.code,{children:"return"})," keyword, it goes here:"]}),"\n",(0,r.jsx)(n.p,{children:"^code return-statement"}),"\n",(0,r.jsxs)(n.p,{children:["The return value expression is optional, so the parser looks for a semicolon\r\ntoken to tell if a value was provided. If there is no return value, the\r\nstatement implicitly returns ",(0,r.jsx)(n.code,{children:"nil"}),". We implement that by calling ",(0,r.jsx)(n.code,{children:"emitReturn()"}),",\r\nwhich emits an ",(0,r.jsx)(n.code,{children:"OP_NIL"})," instruction. Otherwise, we compile the return value\r\nexpression and return it with an ",(0,r.jsx)(n.code,{children:"OP_RETURN"})," instruction."]}),"\n",(0,r.jsxs)(n.p,{children:["This is the same ",(0,r.jsx)(n.code,{children:"OP_RETURN"})," instruction we've already implemented -- we don't\r\nneed any new runtime code. This is quite a difference from jlox. There, we had\r\nto use exceptions to unwind the stack when a ",(0,r.jsx)(n.code,{children:"return"})," statement was executed.\r\nThat was because you could return from deep inside some nested blocks. Since\r\njlox recursively walks the AST, that meant there were a bunch of Java method\r\ncalls we needed to escape out of."]}),"\n",(0,r.jsx)(n.p,{children:"Our bytecode compiler flattens that all out. We do recursive descent during\r\nparsing, but at runtime, the VM's bytecode dispatch loop is completely flat.\r\nThere is no recursion going on at the C level at all. So returning, even from\r\nwithin some nested blocks, is as straightforward as returning from the end of\r\nthe function's body."}),"\n",(0,r.jsxs)(n.p,{children:["We're not totally done, though. The new ",(0,r.jsx)(n.code,{children:"return"})," statement gives us a new\r\ncompile error to worry about. Returns are useful for returning from functions\r\nbut the top level of a Lox program is imperative code too. You shouldn't be able\r\nto ",(0,r.jsx)(n.span,{name:"worst",children:"return"})," from there."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'return "What?!";\n'})}),"\n",(0,r.jsxs)(n.aside,{name:"worst",children:["\n",(0,r.jsxs)(n.p,{children:["Allowing ",(0,r.jsx)(n.code,{children:"return"})," at the top level isn't the worst idea in the world. It would\r\ngive you a natural way to terminate a script early. You could maybe even use a\r\nreturned number to indicate the process's exit code."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["We've specified that it's a compile error to have a ",(0,r.jsx)(n.code,{children:"return"})," statement outside\r\nof any function, which we implement like so:"]}),"\n",(0,r.jsx)(n.p,{children:"^code return-from-script (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"This is one of the reasons we added that FunctionType enum to the compiler."}),"\n",(0,r.jsx)(n.h2,{id:"native-functions",children:"Native Functions"}),"\n",(0,r.jsxs)(n.p,{children:["Our VM is getting more powerful. We've got functions, calls, parameters,\r\nreturns. You can define lots of different functions that can call each other in\r\ninteresting ways. But, ultimately, they can't really ",(0,r.jsx)(n.em,{children:"do"})," anything. The only\r\nuser-visible thing a Lox program can do, regardless of its complexity, is print.\r\nTo add more capabilities, we need to expose them to the user."]}),"\n",(0,r.jsxs)(n.p,{children:["A programming language implementation reaches out and touches the material world\r\nthrough ",(0,r.jsx)(n.strong,{children:"native functions"}),". If you want to be able to write programs that\r\ncheck the time, read user input, or access the file system, we need to add\r\nnative functions -- callable from Lox but implemented in C -- that expose those\r\ncapabilities."]}),"\n",(0,r.jsx)(n.p,{children:"At the language level, Lox is fairly complete -- it's got closures, classes,\r\ninheritance, and other fun stuff. One reason it feels like a toy language is\r\nbecause it has almost no native capabilities. We could turn it into a real\r\nlanguage by adding a long list of them."}),"\n",(0,r.jsxs)(n.p,{children:["However, grinding through a pile of OS operations isn't actually very\r\neducational. Once you've seen how to bind one piece of C code to Lox, you get\r\nthe idea. But you do need to see ",(0,r.jsx)(n.em,{children:"one"}),", and even a single native function\r\nrequires us to build out all the machinery for interfacing Lox with C. So we'll\r\ngo through that and do all the hard work. Then, when that's done, we'll add one\r\ntiny native function just to prove that it works."]}),"\n",(0,r.jsx)(n.p,{children:"The reason we need new machinery is because, from the implementation's\r\nperspective, native functions are different from Lox functions. When they are\r\ncalled, they don't push a CallFrame, because there's no bytecode code for that\r\nframe to point to. They have no bytecode chunk. Instead, they somehow reference\r\na piece of native C code."}),"\n",(0,r.jsx)(n.p,{children:"We handle this in clox by defining native functions as an entirely different\r\nobject type."}),"\n",(0,r.jsx)(n.p,{children:"^code obj-native (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"The representation is simpler than ObjFunction -- merely an Obj header and a\r\npointer to the C function that implements the native behavior. The native\r\nfunction takes the argument count and a pointer to the first argument on the\r\nstack. It accesses the arguments through that pointer. Once it's done, it\r\nreturns the result value."}),"\n",(0,r.jsx)(n.p,{children:"As always, a new object type carries some accoutrements with it. To create an\r\nObjNative, we declare a constructor-like function."}),"\n",(0,r.jsx)(n.p,{children:"^code new-native-h (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"We implement that like so:"}),"\n",(0,r.jsx)(n.p,{children:"^code new-native"}),"\n",(0,r.jsx)(n.p,{children:"The constructor takes a C function pointer to wrap in an ObjNative. It sets up\r\nthe object header and stores the function. For the header, we need a new object\r\ntype."}),"\n",(0,r.jsx)(n.p,{children:"^code obj-type-native (2 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"The VM also needs to know how to deallocate a native function object."}),"\n",(0,r.jsx)(n.p,{children:"^code free-native (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"There isn't much here since ObjNative doesn't own any extra memory. The other\r\ncapability all Lox objects support is being printed."}),"\n",(0,r.jsx)(n.p,{children:"^code print-native (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"In order to support dynamic typing, we have a macro to see if a value is a\r\nnative function."}),"\n",(0,r.jsx)(n.p,{children:"^code is-native (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Assuming that returns true, this macro extracts the C function pointer from a\r\nValue representing a native function:"}),"\n",(0,r.jsx)(n.p,{children:"^code as-native (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["All of this baggage lets the VM treat native functions like any other object.\r\nYou can store them in variables, pass them around, throw them birthday parties,\r\netc. Of course, the operation we actually care about is ",(0,r.jsx)(n.em,{children:"calling"})," them -- using\r\none as the left-hand operand in a call expression."]}),"\n",(0,r.jsxs)(n.p,{children:["Over in ",(0,r.jsx)(n.code,{children:"callValue()"})," we add another type case."]}),"\n",(0,r.jsx)(n.p,{children:"^code call-native (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"If the object being called is a native function, we invoke the C function right\r\nthen and there. There's no need to muck with CallFrames or anything. We just\r\nhand off to C, get the result, and stuff it back in the stack. This makes native\r\nfunctions as fast as we can get."}),"\n",(0,r.jsx)(n.p,{children:"With this, users should be able to call native functions, but there aren't any\r\nto call. Without something like a foreign function interface, users can't define\r\ntheir own native functions. That's our job as VM implementers. We'll start with\r\na helper to define a new native function exposed to Lox programs."}),"\n",(0,r.jsx)(n.p,{children:"^code define-native"}),"\n",(0,r.jsx)(n.p,{children:"It takes a pointer to a C function and the name it will be known as in Lox.\r\nWe wrap the function in an ObjNative and then store that in a global variable\r\nwith the given name."}),"\n",(0,r.jsxs)(n.p,{children:["You're probably wondering why we push and pop the name and function on the\r\nstack. That looks weird, right? This is the kind of stuff you have to worry\r\nabout when ",(0,r.jsx)(n.span,{name:"worry",children:"garbage"})," collection gets involved. Both\r\n",(0,r.jsx)(n.code,{children:"copyString()"})," and ",(0,r.jsx)(n.code,{children:"newNative()"})," dynamically allocate memory. That means once we\r\nhave a GC, they can potentially trigger a collection. If that happens, we need\r\nto ensure the collector knows we're not done with the name and ObjFunction so\r\nthat it doesn't free them out from under us. Storing them on the value stack\r\naccomplishes that."]}),"\n",(0,r.jsxs)(n.aside,{name:"worry",children:["\n",(0,r.jsxs)(n.p,{children:["Don't worry if you didn't follow all that. It will make a lot more sense once we\r\nget around to ",(0,r.jsx)(n.a,{href:"garbage-collection.html",children:"implementing the GC"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"It feels silly, but after all of that work, we're going to add only one\r\nlittle native function."}),"\n",(0,r.jsx)(n.p,{children:"^code clock-native"}),"\n",(0,r.jsxs)(n.p,{children:["This returns the elapsed time since the program started running, in seconds. It's\r\nhandy for benchmarking Lox programs. In Lox, we'll name it ",(0,r.jsx)(n.code,{children:"clock()"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"^code define-native-clock (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["To get to the C standard library ",(0,r.jsx)(n.code,{children:"clock()"}),' function, the "vm" module needs an\r\ninclude.']}),"\n",(0,r.jsx)(n.p,{children:"^code vm-include-time (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"That was a lot of material to work through, but we did it! Type this in and try\r\nit out:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"fun fib(n) {\r\n  if (n < 2) return n;\r\n  return fib(n - 2) + fib(n - 1);\r\n}\r\n\r\nvar start = clock();\r\nprint fib(35);\r\nprint clock() - start;\n"})}),"\n",(0,r.jsxs)(n.p,{children:["We can write a really inefficient recursive Fibonacci function. Even better, we\r\ncan measure just ",(0,r.jsx)(n.span,{name:"faster",children:(0,r.jsx)(n.em,{children:"how"})})," inefficient it is. This is, of\r\ncourse, not the smartest way to calculate a Fibonacci number. But it is a good\r\nway to stress test a language implementation's support for function calls. On my\r\nmachine, running this in clox is about five times faster than in jlox. That's\r\nquite an improvement."]}),"\n",(0,r.jsxs)(n.aside,{name:"faster",children:["\n",(0,r.jsx)(n.p,{children:"It's a little slower than a comparable Ruby program run in Ruby 2.4.3p205, and\r\nabout 3x faster than one run in Python 3.7.3. And we still have a lot of simple\r\noptimizations we can do in our VM."}),"\n"]}),"\n",(0,r.jsxs)(n.div,{className:"challenges",children:["\n",(0,r.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Reading and writing the ",(0,r.jsx)(n.code,{children:"ip"})," field is one of the most frequent operations\r\ninside the bytecode loop. Right now, we access it through a pointer to the\r\ncurrent CallFrame. That requires a pointer indirection which may force the\r\nCPU to bypass the cache and hit main memory. That can be a real performance\r\nsink."]}),"\n",(0,r.jsxs)(n.p,{children:["Ideally, we'd keep the ",(0,r.jsx)(n.code,{children:"ip"})," in a native CPU register. C doesn't let us\r\n",(0,r.jsx)(n.em,{children:"require"})," that without dropping into inline assembly, but we can structure\r\nthe code to encourage the compiler to make that optimization. If we store\r\nthe ",(0,r.jsx)(n.code,{children:"ip"})," directly in a C local variable and mark it ",(0,r.jsx)(n.code,{children:"register"}),", there's a\r\ngood chance the C compiler will accede to our polite request."]}),"\n",(0,r.jsxs)(n.p,{children:["This does mean we need to be careful to load and store the local ",(0,r.jsx)(n.code,{children:"ip"})," back\r\ninto the correct CallFrame when starting and ending function calls.\r\nImplement this optimization. Write a couple of benchmarks and see how it\r\naffects the performance. Do you think the extra code complexity is worth it?"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Native function calls are fast in part because we don't validate that the\r\ncall passes as many arguments as the function expects. We really should, or\r\nan incorrect call to a native function without enough arguments could cause\r\nthe function to read uninitialized memory. Add arity checking."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Right now, there's no way for a native function to signal a runtime error.\r\nIn a real implementation, this is something we'd need to support because\r\nnative functions live in the statically typed world of C but are called\r\nfrom dynamically typed Lox land. If a user, say, tries to pass a string to\r\n",(0,r.jsx)(n.code,{children:"sqrt()"}),", that native function needs to report a runtime error."]}),"\n",(0,r.jsx)(n.p,{children:"Extend the native function system to support that. How does this capability\r\naffect the performance of native calls?"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Add some more native functions to do things you find useful. Write some\r\nprograms using those. What did you add? How do they affect the feel of the\r\nlanguage and how practical it is?"}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>s});var r=t(6540);const i={},o=r.createContext(i);function a(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);