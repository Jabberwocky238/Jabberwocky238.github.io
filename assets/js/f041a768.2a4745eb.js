"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[1826],{7531:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>a,metadata:()=>o,toc:()=>h});var r=t(4848),s=t(8453);const a={},i=void 0,o={id:"Craftinginterpreters/not-translated-yet/representing-code",title:"representing-code",description:"To dwellers in a wood, almost every species of tree has its voice as well as",source:"@site/docs/Craftinginterpreters/not-translated-yet/representing-code.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/representing-code",permalink:"/docs/Craftinginterpreters/not-translated-yet/representing-code",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/representing-code.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"parsing-expressions",permalink:"/docs/Craftinginterpreters/not-translated-yet/parsing-expressions"},next:{title:"resolving-and-binding",permalink:"/docs/Craftinginterpreters/not-translated-yet/resolving-and-binding"}},l={},h=[{value:"Context-Free Grammars",id:"context-free-grammars",level:2},{value:"Rules for grammars",id:"rules-for-grammars",level:3},{value:"Enhancing our notation",id:"enhancing-our-notation",level:3},{value:"A Grammar for Lox expressions",id:"a-grammar-for-lox-expressions",level:3},{value:"Implementing Syntax Trees",id:"implementing-syntax-trees",level:2},{value:"Disoriented objects",id:"disoriented-objects",level:3},{value:"Metaprogramming the trees",id:"metaprogramming-the-trees",level:3},{value:"Working with Trees",id:"working-with-trees",level:2},{value:"The expression problem",id:"the-expression-problem",level:3},{value:"The Visitor pattern",id:"the-visitor-pattern",level:3},{value:"Visitors for expressions",id:"visitors-for-expressions",level:3},{value:"A (Not Very) Pretty Printer",id:"a-not-very-pretty-printer",level:2},{value:"Challenges",id:"challenges",level:2}];function d(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["To dwellers in a wood, almost every species of tree has its voice as well as\r\nits feature.\r\n",(0,r.jsxs)(n.cite,{children:["Thomas Hardy, ",(0,r.jsx)(n.em,{children:"Under the Greenwood Tree"})]})]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["In the ",(0,r.jsx)(n.a,{href:"scanning.html",children:"last chapter"}),", we took the raw source code as a string and\r\ntransformed it into a slightly higher-level representation: a series of tokens.\r\nThe parser we'll write in the ",(0,r.jsx)(n.a,{href:"parsing-expressions.html",children:"next chapter"})," takes those tokens and\r\ntransforms them yet again, into an even richer, more complex representation."]}),"\n",(0,r.jsxs)(n.p,{children:["Before we can produce that representation, we need to define it. That's the\r\nsubject of this chapter. Along the way, we'll ",(0,r.jsx)(n.span,{name:"boring",children:"cover"}),"\r\nsome theory around formal grammars, feel the difference between functional and\r\nobject-oriented programming, go over a couple of design patterns, and do some\r\nmetaprogramming."]}),"\n",(0,r.jsxs)(n.aside,{name:"boring",children:["\n",(0,r.jsx)(n.p,{children:"I was so worried about this being one of the most boring chapters in the book\r\nthat I kept stuffing more fun ideas into it until I ran out of room."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Before we do all that, let's focus on the main goal -- a representation for\r\ncode. It should be simple for the parser to produce and easy for the\r\ninterpreter to consume. If you haven't written a parser or interpreter yet,\r\nthose requirements aren't exactly illuminating. Maybe your intuition can help.\r\nWhat is your brain doing when you play the part of a ",(0,r.jsx)(n.em,{children:"human"})," interpreter? How do\r\nyou mentally evaluate an arithmetic expression like this:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"1 + 2 * 3 - 4\n"})}),"\n",(0,r.jsxs)(n.p,{children:['Because you understand the order of operations -- the old "',(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Order_of_operations#Mnemonics",children:"Please Excuse My\r\nDear Aunt Sally"}),'" stuff -- you know that the multiplication is evaluated\r\nbefore the addition or subtraction. One way to visualize that precedence is\r\nusing a tree. Leaf nodes are numbers, and interior nodes are operators with\r\nbranches for each of their operands.']}),"\n",(0,r.jsxs)(n.p,{children:["In order to evaluate an arithmetic node, you need to know the numeric values of\r\nits subtrees, so you have to evaluate those first. That means working your way\r\nfrom the leaves up to the root -- a ",(0,r.jsx)(n.em,{children:"post-order"})," traversal:"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"tree-steps"})}),"\n",(0,r.jsx)(n.img,{src:"image/representing-code/tree-evaluate.png",alt:"Evaluating the tree from the bottom up."}),"\n",(0,r.jsxs)(n.aside,{name:"tree-steps",children:["\n",(0,r.jsxs)(n.p,{children:["A. Starting with the full tree, evaluate the bottom-most operation, ",(0,r.jsx)(n.code,{children:"2 * 3"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["B. Now we can evaluate the ",(0,r.jsx)(n.code,{children:"+"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["C. Next, the ",(0,r.jsx)(n.code,{children:"-"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"D. The final answer."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["If I gave you an arithmetic expression, you could draw one of these trees pretty\r\neasily. Given a tree, you can evaluate it without breaking a sweat. So it\r\nintuitively seems like a workable representation of our code is a ",(0,r.jsx)(n.span,{name:"only",children:"tree"})," that matches the grammatical structure -- the operator\r\nnesting -- of the language."]}),"\n",(0,r.jsxs)(n.aside,{name:"only",children:["\n",(0,r.jsxs)(n.p,{children:["That's not to say a tree is the ",(0,r.jsx)(n.em,{children:"only"})," possible representation of our code. In\r\n",(0,r.jsx)(n.a,{href:"a-bytecode-virtual-machine.html",children:"Part III"}),", we'll generate bytecode, another representation that isn't as\r\nhuman friendly but is closer to the machine."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["We need to get more precise about what that grammar is then. Like lexical\r\ngrammars in the last chapter, there is a long ton of theory around syntactic\r\ngrammars. We're going into that theory a little more than we did when scanning\r\nbecause it turns out to be a useful tool throughout much of the interpreter.\r\nWe start by moving one level up the ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Chomsky_hierarchy",children:"Chomsky hierarchy"}),"..."]}),"\n",(0,r.jsx)(n.h2,{id:"context-free-grammars",children:"Context-Free Grammars"}),"\n",(0,r.jsxs)(n.p,{children:["In the last chapter, the formalism we used for defining the lexical grammar --\r\nthe rules for how characters get grouped into tokens -- was called a ",(0,r.jsx)(n.em,{children:"regular\r\nlanguage"}),". That was fine for our scanner, which emits a flat sequence of tokens.\r\nBut regular languages aren't powerful enough to handle expressions which can\r\nnest arbitrarily deeply."]}),"\n",(0,r.jsxs)(n.p,{children:["We need a bigger hammer, and that hammer is a ",(0,r.jsx)(n.strong,{children:"context-free grammar"}),"\r\n(",(0,r.jsx)(n.strong,{children:"CFG"}),"). It's the next heaviest tool in the toolbox of\r\n",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Formal_grammar",children:"formal grammars"})}),'. A formal grammar takes a set of atomic pieces it calls\r\nits "alphabet". Then it defines a (usually infinite) set of "strings" that are\r\n"in" the grammar. Each string is a sequence of "letters" in the alphabet.']}),"\n",(0,r.jsxs)(n.p,{children:['I\'m using all those quotes because the terms get a little confusing as you move\r\nfrom lexical to syntactic grammars. In our scanner\'s grammar, the alphabet\r\nconsists of individual characters and the strings are the valid lexemes --\r\nroughly "words". In the syntactic grammar we\'re talking about now, we\'re at a\r\ndifferent level of granularity. Now each "letter" in the alphabet is an entire\r\ntoken and a "string" is a sequence of ',(0,r.jsx)(n.em,{children:"tokens"})," -- an entire expression."]}),"\n",(0,r.jsx)(n.p,{children:"Oof. Maybe a table will help:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:["\n  ",(0,r.jsx)(n.td,{children:"Terminology"}),"\n  ",(0,r.jsx)(n.td,{}),"\n  ",(0,r.jsx)(n.td,{children:"Lexical grammar"}),"\n  ",(0,r.jsx)(n.td,{children:"Syntactic grammar"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:["\n  ",(0,r.jsxs)(n.td,{children:["The \u201calphabet\u201d is",(0,r.jsx)(n.span,{className:"ellipse",children:"\u2009.\u2009.\u2009."})]}),"\n  ",(0,r.jsx)(n.td,{children:"\u2192\u2002"}),"\n  ",(0,r.jsx)(n.td,{children:"Characters"}),"\n  ",(0,r.jsx)(n.td,{children:"Tokens"})]}),(0,r.jsxs)(n.tr,{children:["\n  ",(0,r.jsxs)(n.td,{children:["A \u201cstring\u201d is",(0,r.jsx)(n.span,{className:"ellipse",children:"\u2009.\u2009.\u2009."})]}),"\n  ",(0,r.jsx)(n.td,{children:"\u2192\u2002"}),"\n  ",(0,r.jsx)(n.td,{children:"Lexeme or token"}),"\n  ",(0,r.jsx)(n.td,{children:"Expression"})]}),(0,r.jsxs)(n.tr,{children:["\n  ",(0,r.jsxs)(n.td,{children:["It\u2019s implemented by the",(0,r.jsx)(n.span,{className:"ellipse",children:"\u2009.\u2009.\u2009."})]}),"\n  ",(0,r.jsx)(n.td,{children:"\u2192\u2002"}),"\n  ",(0,r.jsx)(n.td,{children:"Scanner"}),"\n  ",(0,r.jsx)(n.td,{children:"Parser"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:'A formal grammar\'s job is to specify which strings are valid and which aren\'t.\r\nIf we were defining a grammar for English sentences, "eggs are tasty for\r\nbreakfast" would be in the grammar, but "tasty breakfast for are eggs" would\r\nprobably not.'}),"\n",(0,r.jsx)(n.h3,{id:"rules-for-grammars",children:"Rules for grammars"}),"\n",(0,r.jsx)(n.p,{children:'How do we write down a grammar that contains an infinite number of valid\r\nstrings? We obviously can\'t list them all out. Instead, we create a finite set\r\nof rules. You can think of them as a game that you can "play" in one of two\r\ndirections.'}),"\n",(0,r.jsxs)(n.p,{children:["If you start with the rules, you can use them to ",(0,r.jsx)(n.em,{children:"generate"})," strings that are in\r\nthe grammar. Strings created this way are called ",(0,r.jsx)(n.strong,{children:"derivations"})," because each is\r\n",(0,r.jsx)(n.em,{children:"derived"})," from the rules of the grammar. In each step of the game, you pick a\r\nrule and follow what it tells you to do. Most of the lingo around formal\r\ngrammars comes from playing them in this direction. Rules are called\r\n",(0,r.jsx)(n.strong,{children:"productions"})," because they ",(0,r.jsx)(n.em,{children:"produce"})," strings in the grammar."]}),"\n",(0,r.jsxs)(n.p,{children:["Each production in a context-free grammar has a ",(0,r.jsx)(n.strong,{children:"head"})," -- its ",(0,r.jsx)(n.span,{name:"name",children:"name"})," -- and a ",(0,r.jsx)(n.strong,{children:"body"}),", which describes what it generates. In\r\nits pure form, the body is simply a list of symbols. Symbols come in two\r\ndelectable flavors:"]}),"\n",(0,r.jsxs)(n.aside,{name:"name",children:["\n",(0,r.jsxs)(n.p,{children:["Restricting heads to a single symbol is a defining feature of context-free\r\ngrammars. More powerful formalisms like ",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Unrestricted_grammar",children:"unrestricted grammars"})})," allow a\r\nsequence of symbols in the head as well as in the body."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"terminal"})," is a letter from the grammar's alphabet. You can think of it\r\nlike a literal value. In the syntactic grammar we're defining, the terminals\r\nare individual lexemes -- tokens coming from the scanner like ",(0,r.jsx)(n.code,{children:"if"})," or\r\n",(0,r.jsx)(n.code,{children:"1234"}),"."]}),"\n",(0,r.jsx)(n.p,{children:'These are called "terminals", in the sense of an "end point" because they\r\ndon\'t lead to any further "moves" in the game. You simply produce that one\r\nsymbol.'}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"nonterminal"}),' is a named reference to another rule in the grammar. It\r\nmeans "play that rule and insert whatever it produces here". In this way,\r\nthe grammar composes.']}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"There is one last refinement: you may have multiple rules with the same name.\r\nWhen you reach a nonterminal with that name, you are allowed to pick any of the\r\nrules for it, whichever floats your boat."}),"\n",(0,r.jsxs)(n.p,{children:["To make this concrete, we need a ",(0,r.jsx)(n.span,{name:"turtles",children:"way"})," to write down\r\nthese production rules. People have been trying to crystallize grammar all the\r\nway back to P\u0101\u1e47ini's ",(0,r.jsx)(n.em,{children:"Ashtadhyayi"}),", which codified Sanskrit grammar a mere\r\ncouple thousand years ago. Not much progress happened until John Backus and\r\ncompany needed a notation for specifying ALGOL 58 and came up with\r\n",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form",children:(0,r.jsx)(n.strong,{children:"Backus-Naur form"})})," (",(0,r.jsx)(n.strong,{children:"BNF"}),"). Since then, nearly everyone uses some\r\nflavor of BNF, tweaked to their own tastes."]}),"\n",(0,r.jsxs)(n.p,{children:["I tried to come up with something clean. Each rule is a name, followed by an\r\narrow (",(0,r.jsx)(n.code,{children:"\u2192"}),"), followed by a sequence of symbols, and finally ending with a\r\nsemicolon (",(0,r.jsx)(n.code,{children:";"}),"). Terminals are quoted strings, and nonterminals are lowercase\r\nwords."]}),"\n",(0,r.jsxs)(n.aside,{name:"turtles",children:["\n",(0,r.jsxs)(n.p,{children:["Yes, we need to define a syntax to use for the rules that define our syntax.\r\nShould we specify that ",(0,r.jsx)(n.em,{children:"metasyntax"})," too? What notation do we use for ",(0,r.jsx)(n.em,{children:"it?"})," It's\r\nlanguages all the way down!"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Using that, here's a grammar for ",(0,r.jsx)(n.span,{name:"breakfast",children:"breakfast"})," menus:"]}),"\n",(0,r.jsxs)(n.aside,{name:"breakfast",children:["\n",(0,r.jsx)(n.p,{children:"Yes, I really am going to be using breakfast examples throughout this entire\r\nbook. Sorry."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'breakfast  \u2192 protein "with" breakfast "on the side" ;\r\nbreakfast  \u2192 protein ;\r\nbreakfast  \u2192 bread ;\r\n\r\nprotein    \u2192 crispiness "crispy" "bacon" ;\r\nprotein    \u2192 "sausage" ;\r\nprotein    \u2192 cooked "eggs" ;\r\n\r\ncrispiness \u2192 "really" ;\r\ncrispiness \u2192 "really" crispiness ;\r\n\r\ncooked     \u2192 "scrambled" ;\r\ncooked     \u2192 "poached" ;\r\ncooked     \u2192 "fried" ;\r\n\r\nbread      \u2192 "toast" ;\r\nbread      \u2192 "biscuits" ;\r\nbread      \u2192 "English muffin" ;\n'})}),"\n",(0,r.jsxs)(n.p,{children:["We can use this grammar to generate random breakfasts. Let's play a round and\r\nsee how it works. By age-old convention, the game starts with the first rule in\r\nthe grammar, here ",(0,r.jsx)(n.code,{children:"breakfast"}),". There are three productions for that, and we\r\nrandomly pick the first one. Our resulting string looks like:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:'protein "with" breakfast "on the side"\n'})}),"\n",(0,r.jsxs)(n.p,{children:["We need to expand that first nonterminal, ",(0,r.jsx)(n.code,{children:"protein"}),", so we pick a production for\r\nthat. Let's pick:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'protein \u2192 cooked "eggs" ;\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Next, we need a production for ",(0,r.jsx)(n.code,{children:"cooked"}),", and so we pick ",(0,r.jsx)(n.code,{children:'"poached"'}),". That's a\r\nterminal, so we add that. Now our string looks like:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:'"poached" "eggs" "with" breakfast "on the side"\n'})}),"\n",(0,r.jsxs)(n.p,{children:["The next non-terminal is ",(0,r.jsx)(n.code,{children:"breakfast"})," again. The first ",(0,r.jsx)(n.code,{children:"breakfast"})," production we\r\nchose recursively refers back to the ",(0,r.jsx)(n.code,{children:"breakfast"})," rule. Recursion in the grammar\r\nis a good sign that the language being defined is context-free instead of\r\nregular. In particular, recursion where the recursive nonterminal has\r\nproductions on ",(0,r.jsx)(n.span,{name:"nest",children:"both"})," sides implies that the language is\r\nnot regular."]}),"\n",(0,r.jsxs)(n.aside,{name:"nest",children:["\n",(0,r.jsxs)(n.p,{children:["Imagine that we've recursively expanded the ",(0,r.jsx)(n.code,{children:"breakfast"}),' rule here several times,\r\nlike "bacon with bacon with bacon with..." In order to complete the string\r\ncorrectly, we need to add an ',(0,r.jsx)(n.em,{children:"equal"}),' number of "on the side" bits to the end.\r\nTracking the number of required trailing parts is beyond the capabilities of a\r\nregular grammar. Regular grammars can express ',(0,r.jsx)(n.em,{children:"repetition"}),", but they can't ",(0,r.jsx)(n.em,{children:"keep\r\ncount"})," of how many repetitions there are, which is necessary to ensure that the\r\nstring has the same number of ",(0,r.jsx)(n.code,{children:"with"})," and ",(0,r.jsx)(n.code,{children:"on the side"})," parts."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["We could keep picking the first production for ",(0,r.jsx)(n.code,{children:"breakfast"})," over and over again\r\nyielding all manner of breakfasts like \"bacon with sausage with scrambled eggs\r\nwith bacon...\" We won't though. This time we'll pick ",(0,r.jsx)(n.code,{children:"bread"}),'. There are three\r\nrules for that, each of which contains only a terminal. We\'ll pick "English\r\nmuffin".']}),"\n",(0,r.jsx)(n.p,{children:"With that, every nonterminal in the string has been expanded until it finally\r\ncontains only terminals and we're left with:"}),"\n",(0,r.jsx)(n.img,{src:"image/representing-code/breakfast.png",alt:'"Playing" the grammar to generate a string.'}),"\n",(0,r.jsx)(n.p,{children:"Throw in some ham and Hollandaise, and you've got eggs Benedict."}),"\n",(0,r.jsx)(n.p,{children:"Any time we hit a rule that had multiple productions, we just picked one\r\narbitrarily. It is this flexibility that allows a short number of grammar rules\r\nto encode a combinatorially larger set of strings. The fact that a rule can\r\nrefer to itself -- directly or indirectly -- kicks it up even more, letting us\r\npack an infinite number of strings into a finite grammar."}),"\n",(0,r.jsx)(n.h3,{id:"enhancing-our-notation",children:"Enhancing our notation"}),"\n",(0,r.jsx)(n.p,{children:"Stuffing an infinite set of strings in a handful of rules is pretty fantastic,\r\nbut let's take it further. Our notation works, but it's tedious. So, like any\r\ngood language designer, we'll sprinkle a little syntactic sugar on top -- some\r\nextra convenience notation. In addition to terminals and nonterminals, we'll\r\nallow a few other kinds of expressions in the body of a rule:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Instead of repeating the rule name each time we want to add another\r\nproduction for it, we'll allow a series of productions separated by a pipe\r\n(",(0,r.jsx)(n.code,{children:"|"}),")."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'bread \u2192 "toast" | "biscuits" | "English muffin" ;\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Further, we'll allow parentheses for grouping and then allow ",(0,r.jsx)(n.code,{children:"|"})," within that\r\nto select one from a series of options within the middle of a production."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'protein \u2192 ( "scrambled" | "poached" | "fried" ) "eggs" ;\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Using recursion to support repeated sequences of symbols has a certain\r\nappealing ",(0,r.jsx)(n.span,{name:"purity",children:"purity"}),", but it's kind of a chore to\r\nmake a separate named sub-rule each time we want to loop. So, we also use a\r\npostfix ",(0,r.jsx)(n.code,{children:"*"})," to allow the previous symbol or group to be repeated zero or\r\nmore times."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'crispiness \u2192 "really" "really"* ;\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.aside,{name:"purity",children:["\n",(0,r.jsxs)(n.p,{children:["This is how the Scheme programming language works. It has no built-in looping\r\nfunctionality at all. Instead, ",(0,r.jsx)(n.em,{children:"all"})," repetition is expressed in terms of\r\nrecursion."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["A postfix ",(0,r.jsx)(n.code,{children:"+"})," is similar, but requires the preceding production to appear\r\nat least once."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'crispiness \u2192 "really"+ ;\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["A postfix ",(0,r.jsx)(n.code,{children:"?"})," is for an optional production. The thing before it can appear\r\nzero or one time, but not more."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'breakfast \u2192 protein ( "with" breakfast "on the side" )? ;\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"With all of those syntactic niceties, our breakfast grammar condenses down to:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'breakfast \u2192 protein ( "with" breakfast "on the side" )?\r\n          | bread ;\r\n\r\nprotein   \u2192 "really"+ "crispy" "bacon"\r\n          | "sausage"\r\n          | ( "scrambled" | "poached" | "fried" ) "eggs" ;\r\n\r\nbread     \u2192 "toast" | "biscuits" | "English muffin" ;\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Not too bad, I hope. If you're used to grep or using ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Regular_expression#Standards",children:"regular\r\nexpressions"})," in your text editor, most of the punctuation should be\r\nfamiliar. The main difference is that symbols here represent entire tokens, not\r\nsingle characters."]}),"\n",(0,r.jsxs)(n.p,{children:["We'll use this notation throughout the rest of the book to precisely describe\r\nLox's grammar. As you work on programming languages, you'll find that\r\ncontext-free grammars (using this or ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form",children:"EBNF"})," or some other notation) help you\r\ncrystallize your informal syntax design ideas. They are also a handy medium for\r\ncommunicating with other language hackers about syntax."]}),"\n",(0,r.jsx)(n.p,{children:"The rules and productions we define for Lox are also our guide to the tree data\r\nstructure we're going to implement to represent code in memory. Before we can do\r\nthat, we need an actual grammar for Lox, or at least enough of one for us to get\r\nstarted."}),"\n",(0,r.jsx)(n.h3,{id:"a-grammar-for-lox-expressions",children:"A Grammar for Lox expressions"}),"\n",(0,r.jsx)(n.p,{children:"In the previous chapter, we did Lox's entire lexical grammar in one fell swoop.\r\nEvery keyword and bit of punctuation is there. The syntactic grammar is larger,\r\nand it would be a real bore to grind through the entire thing before we actually\r\nget our interpreter up and running."}),"\n",(0,r.jsx)(n.p,{children:"Instead, we'll crank through a subset of the language in the next couple of\r\nchapters. Once we have that mini-language represented, parsed, and interpreted,\r\nthen later chapters will progressively add new features to it, including the new\r\nsyntax. For now, we are going to worry about only a handful of expressions:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Literals."})," Numbers, strings, Booleans, and ",(0,r.jsx)(n.code,{children:"nil"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Unary expressions."})," A prefix ",(0,r.jsx)(n.code,{children:"!"})," to perform a logical not, and ",(0,r.jsx)(n.code,{children:"-"})," to\r\nnegate a number."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Binary expressions."})," The infix arithmetic (",(0,r.jsx)(n.code,{children:"+"}),", ",(0,r.jsx)(n.code,{children:"-"}),", ",(0,r.jsx)(n.code,{children:"*"}),", ",(0,r.jsx)(n.code,{children:"/"}),") and logic\r\noperators (",(0,r.jsx)(n.code,{children:"=="}),", ",(0,r.jsx)(n.code,{children:"!="}),", ",(0,r.jsx)(n.code,{children:"<"}),", ",(0,r.jsx)(n.code,{children:"<="}),", ",(0,r.jsx)(n.code,{children:">"}),", ",(0,r.jsx)(n.code,{children:">="}),") we know and love."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Parentheses."})," A pair of ",(0,r.jsx)(n.code,{children:"("})," and ",(0,r.jsx)(n.code,{children:")"})," wrapped around an expression."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"That gives us enough syntax for expressions like:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"1 - (2 * 3) < 4 == false\n"})}),"\n",(0,r.jsx)(n.p,{children:"Using our handy dandy new notation, here's a grammar for those:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'expression     \u2192 literal\r\n               | unary\r\n               | binary\r\n               | grouping ;\r\n\r\nliteral        \u2192 NUMBER | STRING | "true" | "false" | "nil" ;\r\ngrouping       \u2192 "(" expression ")" ;\r\nunary          \u2192 ( "-" | "!" ) expression ;\r\nbinary         \u2192 expression operator expression ;\r\noperator       \u2192 "==" | "!=" | "<" | "<=" | ">" | ">="\r\n               | "+"  | "-"  | "*" | "/" ;\n'})}),"\n",(0,r.jsxs)(n.p,{children:["There's one bit of extra ",(0,r.jsx)(n.span,{name:"play",children:"metasyntax"})," here. In addition\r\nto quoted strings for terminals that match exact lexemes, we ",(0,r.jsx)(n.code,{children:"CAPITALIZE"}),"\r\nterminals that are a single lexeme whose text representation may vary. ",(0,r.jsx)(n.code,{children:"NUMBER"}),"\r\nis any number literal, and ",(0,r.jsx)(n.code,{children:"STRING"})," is any string literal. Later, we'll do the\r\nsame for ",(0,r.jsx)(n.code,{children:"IDENTIFIER"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"This grammar is actually ambiguous, which we'll see when we get to parsing it.\r\nBut it's good enough for now."}),"\n",(0,r.jsxs)(n.aside,{name:"play",children:["\n",(0,r.jsxs)(n.p,{children:["If you're so inclined, try using this grammar to generate a few expressions like\r\nwe did with the breakfast grammar before. Do the resulting expressions look\r\nright to you? Can you make it generate anything wrong like ",(0,r.jsx)(n.code,{children:"1 + / 3"}),"?"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"implementing-syntax-trees",children:"Implementing Syntax Trees"}),"\n",(0,r.jsxs)(n.p,{children:["Finally, we get to write some code. That little expression grammar is our\r\nskeleton. Since the grammar is recursive -- note how ",(0,r.jsx)(n.code,{children:"grouping"}),", ",(0,r.jsx)(n.code,{children:"unary"}),", and\r\n",(0,r.jsx)(n.code,{children:"binary"})," all refer back to ",(0,r.jsx)(n.code,{children:"expression"})," -- our data structure will form a tree.\r\nSince this structure represents the syntax of our language, it's called a ",(0,r.jsx)(n.span,{name:"ast",children:(0,r.jsx)(n.strong,{children:"syntax tree"})}),"."]}),"\n",(0,r.jsxs)(n.aside,{name:"ast",children:["\n",(0,r.jsxs)(n.p,{children:["In particular, we're defining an ",(0,r.jsx)(n.strong,{children:"abstract syntax tree"})," (",(0,r.jsx)(n.strong,{children:"AST"}),"). In a\r\n",(0,r.jsx)(n.strong,{children:"parse tree"}),", every single grammar production becomes a node in the tree. An\r\nAST elides productions that aren't needed by later phases."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Our scanner used a single Token class to represent all kinds of lexemes. To\r\ndistinguish the different kinds -- think the number ",(0,r.jsx)(n.code,{children:"123"})," versus the string\r\n",(0,r.jsx)(n.code,{children:'"123"'})," -- we included a simple TokenType enum. Syntax trees are not so ",(0,r.jsx)(n.span,{name:"token-data",children:"homogeneous"}),". Unary expressions have a single operand,\r\nbinary expressions have two, and literals have none."]}),"\n",(0,r.jsxs)(n.p,{children:["We ",(0,r.jsx)(n.em,{children:"could"})," mush that all together into a single Expression class with an\r\narbitrary list of children. Some compilers do. But I like getting the most out\r\nof Java's type system. So we'll define a base class for expressions. Then, for\r\neach kind of expression -- each production under ",(0,r.jsx)(n.code,{children:"expression"})," -- we create a\r\nsubclass that has fields for the nonterminals specific to that rule. This way,\r\nwe get a compile error if we, say, try to access the second operand of a unary\r\nexpression."]}),"\n",(0,r.jsxs)(n.aside,{name:"token-data",children:["\n",(0,r.jsx)(n.p,{children:"Tokens aren't entirely homogeneous either. Tokens for literals store the value,\r\nbut other kinds of lexemes don't need that state. I have seen scanners that use\r\ndifferent classes for literals and other kinds of lexemes, but I figured I'd\r\nkeep things simpler."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Something like this:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"package com.craftinginterpreters.lox;\r\n\r\nabstract class Expr { // [expr]\r\n  static class Binary extends Expr {\r\n    Binary(Expr left, Token operator, Expr right) {\r\n      this.left = left;\r\n      this.operator = operator;\r\n      this.right = right;\r\n    }\r\n\r\n    final Expr left;\r\n    final Token operator;\r\n    final Expr right;\r\n  }\r\n\r\n  // Other expressions...\r\n}\n"})}),"\n",(0,r.jsxs)(n.aside,{name:"expr",children:["\n",(0,r.jsx)(n.p,{children:'I avoid abbreviations in my code because they trip up a reader who doesn\'t know\r\nwhat they stand for. But in compilers I\'ve looked at, "Expr" and "Stmt" are so\r\nubiquitous that I may as well start getting you used to them now.'}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Expr is the base class that all expression classes inherit from. As you can see\r\nfrom ",(0,r.jsx)(n.code,{children:"Binary"}),", the subclasses are nested inside of it. There's no technical need\r\nfor this, but it lets us cram all of the classes into a single Java file."]}),"\n",(0,r.jsx)(n.h3,{id:"disoriented-objects",children:"Disoriented objects"}),"\n",(0,r.jsxs)(n.p,{children:["You'll note that, much like the Token class, there aren't any methods here. It's\r\na dumb structure. Nicely typed, but merely a bag of data. This feels strange in\r\nan object-oriented language like Java. Shouldn't the class ",(0,r.jsx)(n.em,{children:"do stuff"}),"?"]}),"\n",(0,r.jsxs)(n.p,{children:["The problem is that these tree classes aren't owned by any single domain. Should\r\nthey have methods for parsing since that's where the trees are created? Or\r\ninterpreting since that's where they are consumed? Trees span the border between\r\nthose territories, which means they are really owned by ",(0,r.jsx)(n.em,{children:"neither"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["In fact, these types exist to enable the parser and interpreter to\r\n",(0,r.jsx)(n.em,{children:"communicate"}),". That lends itself to types that are simply data with no\r\nassociated behavior. This style is very natural in functional languages like\r\nLisp and ML where ",(0,r.jsx)(n.em,{children:"all"})," data is separate from behavior, but it feels odd in\r\nJava."]}),"\n",(0,r.jsx)(n.p,{children:"Functional programming aficionados right now are jumping up to exclaim \"See!\r\nObject-oriented languages are a bad fit for an interpreter!\" I won't go that\r\nfar. You'll recall that the scanner itself was admirably suited to\r\nobject-orientation. It had all of the mutable state to keep track of where it\r\nwas in the source code, a well-defined set of public methods, and a handful of\r\nprivate helpers."}),"\n",(0,r.jsx)(n.p,{children:"My feeling is that each phase or part of the interpreter works fine in an\r\nobject-oriented style. It is the data structures that flow between them that are\r\nstripped of behavior."}),"\n",(0,r.jsx)(n.h3,{id:"metaprogramming-the-trees",children:"Metaprogramming the trees"}),"\n",(0,r.jsx)(n.p,{children:"Java can express behavior-less classes, but I wouldn't say that it's\r\nparticularly great at it. Eleven lines of code to stuff three fields in an\r\nobject is pretty tedious, and when we're all done, we're going to have 21 of\r\nthese classes."}),"\n",(0,r.jsxs)(n.p,{children:["I don't want to waste your time or my ink writing all that down. Really, what is\r\nthe essence of each subclass? A name, and a list of typed fields. That's it.\r\nWe're smart language hackers, right? Let's ",(0,r.jsx)(n.span,{name:"automate",children:"automate"}),"."]}),"\n",(0,r.jsxs)(n.aside,{name:"automate",children:["\n",(0,r.jsx)(n.p,{children:'Picture me doing an awkward robot dance when you read that. "AU-TO-MATE."'}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Instead of tediously handwriting each class definition, field declaration,\r\nconstructor, and initializer, we'll hack together a ",(0,r.jsx)(n.span,{name:"python",children:"script"})," that does it for us. It has a description of each\r\ntree type -- its name and fields -- and it prints out the Java code needed to\r\ndefine a class with that name and state."]}),"\n",(0,r.jsx)(n.p,{children:'This script is a tiny Java command-line app that generates a file named\r\n"Expr.java":'}),"\n",(0,r.jsxs)(n.aside,{name:"python",children:["\n",(0,r.jsx)(n.p,{children:"I got the idea of scripting the syntax tree classes from Jim Hugunin, creator of\r\nJython and IronPython."}),"\n",(0,r.jsx)(n.p,{children:"An actual scripting language would be a better fit for this than Java, but I'm\r\ntrying not to throw too many languages at you."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code generate-ast"}),"\n",(0,r.jsxs)(n.p,{children:["Note that this file is in a different package, ",(0,r.jsx)(n.code,{children:".tool"})," instead of ",(0,r.jsx)(n.code,{children:".lox"}),". This\r\nscript isn't part of the interpreter itself. It's a tool ",(0,r.jsx)(n.em,{children:"we"}),', the people\r\nhacking on the interpreter, run ourselves to generate the syntax tree classes.\r\nWhen it\'s done, we treat "Expr.java" like any other file in the implementation.\r\nWe are merely automating how that file gets authored.']}),"\n",(0,r.jsx)(n.p,{children:"To generate the classes, it needs to have some description of each type and its\r\nfields."}),"\n",(0,r.jsx)(n.p,{children:"^code call-define-ast (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["For brevity's sake, I jammed the descriptions of the expression types into\r\nstrings. Each is the name of the class followed by ",(0,r.jsx)(n.code,{children:":"})," and the list of fields,\r\nseparated by commas. Each field has a type and a name."]}),"\n",(0,r.jsxs)(n.p,{children:["The first thing ",(0,r.jsx)(n.code,{children:"defineAst()"})," needs to do is output the base Expr class."]}),"\n",(0,r.jsx)(n.p,{children:"^code define-ast"}),"\n",(0,r.jsxs)(n.p,{children:["When we call this, ",(0,r.jsx)(n.code,{children:"baseName"}),' is "Expr", which is both the name of the class and\r\nthe name of the file it outputs. We pass this as an argument instead of\r\nhardcoding the name because we\'ll add a separate family of classes later for\r\nstatements.']}),"\n",(0,r.jsx)(n.p,{children:"Inside the base class, we define each subclass."}),"\n",(0,r.jsx)(n.p,{children:"^code nested-classes (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.aside,{name:"robust",children:["\n",(0,r.jsx)(n.p,{children:"This isn't the world's most elegant string manipulation code, but that's fine.\r\nIt only runs on the exact set of class definitions we give it. Robustness ain't\r\na priority."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"That code, in turn, calls:"}),"\n",(0,r.jsx)(n.p,{children:"^code define-type"}),"\n",(0,r.jsx)(n.p,{children:"There we go. All of that glorious Java boilerplate is done. It declares each\r\nfield in the class body. It defines a constructor for the class with parameters\r\nfor each field and initializes them in the body."}),"\n",(0,r.jsxs)(n.p,{children:["Compile and run this Java program now and it ",(0,r.jsx)(n.span,{name:"longer",children:"blasts"}),"\r\nout a new \u201c.java\" file containing a few dozen lines of code. That file's\r\nabout to get even longer."]}),"\n",(0,r.jsxs)(n.aside,{name:"longer",children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"appendix-ii.html",children:"Appendix II"})," contains the code generated by this script once we've finished\r\nimplementing jlox and defined all of its syntax tree nodes."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"working-with-trees",children:"Working with Trees"}),"\n",(0,r.jsx)(n.p,{children:"Put on your imagination hat for a moment. Even though we aren't there yet,\r\nconsider what the interpreter will do with the syntax trees. Each kind of\r\nexpression in Lox behaves differently at runtime. That means the interpreter\r\nneeds to select a different chunk of code to handle each expression type. With\r\ntokens, we can simply switch on the TokenType. But we don't have a \"type\" enum\r\nfor the syntax trees, just a separate Java class for each one."}),"\n",(0,r.jsx)(n.p,{children:"We could write a long chain of type tests:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"if (expr instanceof Expr.Binary) {\r\n  // ...\r\n} else if (expr instanceof Expr.Grouping) {\r\n  // ...\r\n} else // ...\n"})}),"\n",(0,r.jsxs)(n.p,{children:["But all of those sequential type tests are slow. Expression types whose names\r\nare alphabetically later would take longer to execute because they'd fall\r\nthrough more ",(0,r.jsx)(n.code,{children:"if"})," cases before finding the right type. That's not my idea of an\r\nelegant solution."]}),"\n",(0,r.jsxs)(n.p,{children:["We have a family of classes and we need to associate a chunk of behavior with\r\neach one. The natural solution in an object-oriented language like Java is to\r\nput those behaviors into methods on the classes themselves. We could add an\r\nabstract ",(0,r.jsx)(n.span,{name:"interpreter-pattern",children:(0,r.jsx)(n.code,{children:"interpret()"})})," method on Expr\r\nwhich each subclass would then implement to interpret itself."]}),"\n",(0,r.jsxs)(n.aside,{name:"interpreter-pattern",children:["\n",(0,r.jsxs)(n.p,{children:["This exact thing is literally called the ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Interpreter_pattern",children:'"Interpreter pattern"'})," in\r\n",(0,r.jsx)(n.em,{children:"Design Patterns: Elements of Reusable Object-Oriented Software"}),", by Erich\r\nGamma, et al."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This works alright for tiny projects, but it scales poorly. Like I noted before,\r\nthese tree classes span a few domains. At the very least, both the parser and\r\ninterpreter will mess with them. As ",(0,r.jsx)(n.a,{href:"resolving-and-binding.html",children:"you'll see later"}),", we need to\r\ndo name resolution on them. If our language was statically typed, we'd have a\r\ntype checking pass."]}),"\n",(0,r.jsxs)(n.p,{children:["If we added instance methods to the expression classes for every one of those\r\noperations, that would smush a bunch of different domains together. That\r\nviolates ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Separation_of_concerns",children:"separation of concerns"})," and leads to hard-to-maintain code."]}),"\n",(0,r.jsx)(n.h3,{id:"the-expression-problem",children:"The expression problem"}),"\n",(0,r.jsx)(n.p,{children:'This problem is more fundamental than it may seem at first. We have a handful of\r\ntypes, and a handful of high-level operations like "interpret". For each pair of\r\ntype and operation, we need a specific implementation. Picture a table:'}),"\n",(0,r.jsx)(n.img,{src:"image/representing-code/table.png",alt:"A table where rows are labeled with expression classes, and columns are function names."}),"\n",(0,r.jsx)(n.p,{children:"Rows are types, and columns are operations. Each cell represents the unique\r\npiece of code to implement that operation on that type."}),"\n",(0,r.jsx)(n.p,{children:"An object-oriented language like Java assumes that all of the code in one row\r\nnaturally hangs together. It figures all the things you do with a type are\r\nlikely related to each other, and the language makes it easy to define them\r\ntogether as methods inside the same class."}),"\n",(0,r.jsx)(n.img,{src:"image/representing-code/rows.png",alt:"The table split into rows for each class."}),"\n",(0,r.jsxs)(n.p,{children:["This makes it easy to extend the table by adding new rows. Simply define a new\r\nclass. No existing code has to be touched. But imagine if you want to add a new\r\n",(0,r.jsx)(n.em,{children:"operation"})," -- a new column. In Java, that means cracking open each of those\r\nexisting classes and adding a method to it."]}),"\n",(0,r.jsxs)(n.p,{children:["Functional paradigm languages in the ",(0,r.jsx)(n.span,{name:"ml",children:"ML"})," family flip that\r\naround. There, you don't have classes with methods. Types and functions are\r\ntotally distinct. To implement an operation for a number of different types, you\r\ndefine a single function. In the body of that function, you use ",(0,r.jsx)(n.em,{children:"pattern\r\nmatching"})," -- sort of a type-based switch on steroids -- to implement the\r\noperation for each type all in one place."]}),"\n",(0,r.jsxs)(n.aside,{name:"ml",children:["\n",(0,r.jsx)(n.p,{children:'ML, short for "metalanguage" was created by Robin Milner and friends and forms\r\none of the main branches in the great programming language family tree. Its\r\nchildren include SML, Caml, OCaml, Haskell, and F#. Even Scala, Rust, and Swift\r\nbear a strong resemblance.'}),"\n",(0,r.jsx)(n.p,{children:"Much like Lisp, it is one of those languages that is so full of good ideas that\r\nlanguage designers today are still rediscovering them over forty years later."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This makes it trivial to add new operations -- simply define another function\r\nthat pattern matches on all of the types."}),"\n",(0,r.jsx)(n.img,{src:"image/representing-code/columns.png",alt:"The table split into columns for each function."}),"\n",(0,r.jsx)(n.p,{children:"But, conversely, adding a new type is hard. You have to go back and add a new\r\ncase to all of the pattern matches in all of the existing functions."}),"\n",(0,r.jsxs)(n.p,{children:['Each style has a certain "grain" to it. That\'s what the paradigm name literally\r\nsays -- an object-oriented language wants you to ',(0,r.jsx)(n.em,{children:"orient"})," your code along the\r\nrows of types. A functional language instead encourages you to lump each\r\ncolumn's worth of code together into a ",(0,r.jsx)(n.em,{children:"function"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["A bunch of smart language nerds noticed that neither style made it easy to add\r\n",(0,r.jsx)(n.em,{children:"both"})," rows and columns to the ",(0,r.jsx)(n.span,{name:"multi",children:"table"}),'. They called this\r\ndifficulty the "expression problem" because -- like we are now -- they first ran\r\ninto it when they were trying to figure out the best way to model expression\r\nsyntax tree nodes in a compiler.']}),"\n",(0,r.jsxs)(n.aside,{name:"multi",children:["\n",(0,r.jsxs)(n.p,{children:["Languages with ",(0,r.jsx)(n.em,{children:"multimethods"}),", like Common Lisp's CLOS, Dylan, and Julia do\r\nsupport adding both new types and operations easily. What they typically\r\nsacrifice is either static type checking, or separate compilation."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"People have thrown all sorts of language features, design patterns, and\r\nprogramming tricks to try to knock that problem down but no perfect language has\r\nfinished it off yet. In the meantime, the best we can do is try to pick a\r\nlanguage whose orientation matches the natural architectural seams in the\r\nprogram we're writing."}),"\n",(0,r.jsx)(n.p,{children:"Object-orientation works fine for many parts of our interpreter, but these tree\r\nclasses rub against the grain of Java. Fortunately, there's a design pattern we\r\ncan bring to bear on it."}),"\n",(0,r.jsx)(n.h3,{id:"the-visitor-pattern",children:"The Visitor pattern"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"Visitor pattern"})," is the most widely misunderstood pattern in all of\r\n",(0,r.jsx)(n.em,{children:"Design Patterns"}),", which is really saying something when you look at the\r\nsoftware architecture excesses of the past couple of decades."]}),"\n",(0,r.jsxs)(n.p,{children:['The trouble starts with terminology. The pattern isn\'t about "visiting", and the\r\n"accept" method in it doesn\'t conjure up any helpful imagery either. Many think\r\nthe pattern has to do with traversing trees, which isn\'t the case at all. We\r\n',(0,r.jsx)(n.em,{children:"are"})," going to use it on a set of classes that are tree-like, but that's a\r\ncoincidence. As you'll see, the pattern works as well on a single object."]}),"\n",(0,r.jsx)(n.p,{children:"The Visitor pattern is really about approximating the functional style within an\r\nOOP language. It lets us add new columns to that table easily. We can define all\r\nof the behavior for a new operation on a set of types in one place, without\r\nhaving to touch the types themselves. It does this the same way we solve almost\r\nevery problem in computer science: by adding a layer of indirection."}),"\n",(0,r.jsxs)(n.p,{children:["Before we apply it to our auto-generated Expr classes, let's walk through a\r\nsimpler example. Say we have two kinds of pastries: ",(0,r.jsx)(n.span,{name:"beignet",children:"beignets"})," and crullers."]}),"\n",(0,r.jsxs)(n.aside,{name:"beignet",children:["\n",(0,r.jsx)(n.p,{children:'A beignet (pronounced "ben-yay", with equal emphasis on both syllables) is a\r\ndeep-fried pastry in the same family as doughnuts. When the French colonized\r\nNorth America in the 1700s, they brought beignets with them. Today, in the US,\r\nthey are most strongly associated with the cuisine of New Orleans.'}),"\n",(0,r.jsx)(n.p,{children:"My preferred way to consume them is fresh out of the fryer at Caf\xe9 du Monde,\r\npiled high in powdered sugar, and washed down with a cup of caf\xe9 au lait while I\r\nwatch tourists staggering around trying to shake off their hangover from the\r\nprevious night's revelry."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code pastries (no location)"}),"\n",(0,r.jsx)(n.p,{children:"We want to be able to define new pastry operations -- cooking them, eating them,\r\ndecorating them, etc. -- without having to add a new method to each class every\r\ntime. Here's how we do it. First, we define a separate interface."}),"\n",(0,r.jsx)(n.p,{children:"^code pastry-visitor (no location)"}),"\n",(0,r.jsxs)(n.aside,{name:"overload",children:["\n",(0,r.jsxs)(n.p,{children:["In ",(0,r.jsx)(n.em,{children:"Design Patterns"}),", both of these methods are confusingly named ",(0,r.jsx)(n.code,{children:"visit()"}),", and\r\nthey rely on overloading to distinguish them. This leads some readers to think\r\nthat the correct visit method is chosen ",(0,r.jsx)(n.em,{children:"at runtime"})," based on its parameter\r\ntype. That isn't the case. Unlike over",(0,r.jsx)(n.em,{children:"riding"}),", over",(0,r.jsx)(n.em,{children:"loading"})," is statically\r\ndispatched at compile time."]}),"\n",(0,r.jsx)(n.p,{children:"Using distinct names for each method makes the dispatch more obvious, and also\r\nshows you how to apply this pattern in languages that don't support overloading."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Each operation that can be performed on pastries is a new class that implements\r\nthat interface. It has a concrete method for each type of pastry. That keeps the\r\ncode for the operation on both types all nestled snugly together in one class."}),"\n",(0,r.jsx)(n.p,{children:"Given some pastry, how do we route it to the correct method on the visitor based\r\non its type? Polymorphism to the rescue! We add this method to Pastry:"}),"\n",(0,r.jsx)(n.p,{children:"^code pastry-accept (1 before, 1 after, no location)"}),"\n",(0,r.jsx)(n.p,{children:"Each subclass implements it."}),"\n",(0,r.jsx)(n.p,{children:"^code beignet-accept (1 before, 1 after, no location)"}),"\n",(0,r.jsx)(n.p,{children:"And:"}),"\n",(0,r.jsx)(n.p,{children:"^code cruller-accept (1 before, 1 after, no location)"}),"\n",(0,r.jsxs)(n.p,{children:["To perform an operation on a pastry, we call its ",(0,r.jsx)(n.code,{children:"accept()"})," method and pass in\r\nthe visitor for the operation we want to execute. The pastry -- the specific\r\nsubclass's overriding implementation of ",(0,r.jsx)(n.code,{children:"accept()"})," -- turns around and calls the\r\nappropriate visit method on the visitor and passes ",(0,r.jsx)(n.em,{children:"itself"})," to it."]}),"\n",(0,r.jsxs)(n.p,{children:["That's the heart of the trick right there. It lets us use polymorphic dispatch\r\non the ",(0,r.jsx)(n.em,{children:"pastry"})," classes to select the appropriate method on the ",(0,r.jsx)(n.em,{children:"visitor"})," class.\r\nIn the table, each pastry class is a row, but if you look at all of the methods\r\nfor a single visitor, they form a ",(0,r.jsx)(n.em,{children:"column"}),"."]}),"\n",(0,r.jsx)(n.img,{src:"image/representing-code/visitor.png",alt:"Now all of the cells for one operation are part of the same class, the visitor."}),"\n",(0,r.jsxs)(n.p,{children:["We added one ",(0,r.jsx)(n.code,{children:"accept()"})," method to each class, and we can use it for as many\r\nvisitors as we want without ever having to touch the pastry classes again. It's\r\na clever pattern."]}),"\n",(0,r.jsx)(n.h3,{id:"visitors-for-expressions",children:"Visitors for expressions"}),"\n",(0,r.jsxs)(n.p,{children:["OK, let's weave it into our expression classes. We'll also ",(0,r.jsx)(n.span,{name:"context",children:"refine"})," the pattern a little. In the pastry example, the\r\nvisit and ",(0,r.jsx)(n.code,{children:"accept()"})," methods don't return anything. In practice, visitors often\r\nwant to define operations that produce values. But what return type should\r\n",(0,r.jsx)(n.code,{children:"accept()"})," have? We can't assume every visitor class wants to produce the same\r\ntype, so we'll use generics to let each implementation fill in a return type."]}),"\n",(0,r.jsxs)(n.aside,{name:"context",children:["\n",(0,r.jsxs)(n.p,{children:['Another common refinement is an additional "context" parameter that is passed to\r\nthe visit methods and then sent back through as a parameter to ',(0,r.jsx)(n.code,{children:"accept()"}),". That\r\nlets operations take an additional parameter. The visitors we'll define in the\r\nbook don't need that, so I omitted it."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"First, we define the visitor interface. Again, we nest it inside the base class\r\nso that we can keep everything in one file."}),"\n",(0,r.jsx)(n.p,{children:"^code call-define-visitor (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"That function generates the visitor interface."}),"\n",(0,r.jsx)(n.p,{children:"^code define-visitor"}),"\n",(0,r.jsx)(n.p,{children:"Here, we iterate through all of the subclasses and declare a visit method for\r\neach one. When we define new expression types later, this will automatically\r\ninclude them."}),"\n",(0,r.jsxs)(n.p,{children:["Inside the base class, we define the abstract ",(0,r.jsx)(n.code,{children:"accept()"})," method."]}),"\n",(0,r.jsx)(n.p,{children:"^code base-accept-method (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Finally, each subclass implements that and calls the right visit method for its\r\nown type."}),"\n",(0,r.jsx)(n.p,{children:"^code accept-method (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:'There we go. Now we can define operations on expressions without having to muck\r\nwith the classes or our generator script. Compile and run this generator script\r\nto output an updated "Expr.java" file. It contains a generated Visitor\r\ninterface and a set of expression node classes that support the Visitor pattern\r\nusing it.'}),"\n",(0,r.jsx)(n.p,{children:"Before we end this rambling chapter, let's implement that Visitor interface and\r\nsee the pattern in action."}),"\n",(0,r.jsx)(n.h2,{id:"a-not-very-pretty-printer",children:"A (Not Very) Pretty Printer"}),"\n",(0,r.jsx)(n.p,{children:"When we debug our parser and interpreter, it's often useful to look at a parsed\r\nsyntax tree and make sure it has the structure we expect. We could inspect it in\r\nthe debugger, but that can be a chore."}),"\n",(0,r.jsx)(n.p,{children:'Instead, we\'d like some code that, given a syntax tree, produces an unambiguous\r\nstring representation of it. Converting a tree to a string is sort of the\r\nopposite of a parser, and is often called "pretty printing" when the goal is to\r\nproduce a string of text that is valid syntax in the source language.'}),"\n",(0,r.jsxs)(n.p,{children:["That's not our goal here. We want the string to very explicitly show the nesting\r\nstructure of the tree. A printer that returned ",(0,r.jsx)(n.code,{children:"1 + 2 * 3"})," isn't super helpful\r\nif what we're trying to debug is whether operator precedence is handled\r\ncorrectly. We want to know if the ",(0,r.jsx)(n.code,{children:"+"})," or ",(0,r.jsx)(n.code,{children:"*"})," is at the top of the tree."]}),"\n",(0,r.jsx)(n.p,{children:"To that end, the string representation we produce isn't going to be Lox syntax.\r\nInstead, it will look a lot like, well, Lisp. Each expression is explicitly\r\nparenthesized, and all of its subexpressions and tokens are contained in that."}),"\n",(0,r.jsx)(n.p,{children:"Given a syntax tree like:"}),"\n",(0,r.jsx)(n.img,{src:"image/representing-code/expression.png",alt:"An example syntax tree."}),"\n",(0,r.jsx)(n.p,{children:"It produces:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"(* (- 123) (group 45.67))\n"})}),"\n",(0,r.jsx)(n.p,{children:'Not exactly "pretty", but it does show the nesting and grouping explicitly. To\r\nimplement this, we define a new class.'}),"\n",(0,r.jsx)(n.p,{children:"^code ast-printer"}),"\n",(0,r.jsx)(n.p,{children:"As you can see, it implements the visitor interface. That means we need visit\r\nmethods for each of the expression types we have so far."}),"\n",(0,r.jsx)(n.p,{children:"^code visit-methods (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Literal expressions are easy -- they convert the value to a string with a little\r\ncheck to handle Java's ",(0,r.jsx)(n.code,{children:"null"})," standing in for Lox's ",(0,r.jsx)(n.code,{children:"nil"}),". The other expressions\r\nhave subexpressions, so they use this ",(0,r.jsx)(n.code,{children:"parenthesize()"})," helper method:"]}),"\n",(0,r.jsx)(n.p,{children:"^code print-utilities"}),"\n",(0,r.jsx)(n.p,{children:"It takes a name and a list of subexpressions and wraps them all up in\r\nparentheses, yielding a string like:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"(+ 1 2)\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Note that it calls ",(0,r.jsx)(n.code,{children:"accept()"})," on each subexpression and passes in itself. This\r\nis the ",(0,r.jsx)(n.span,{name:"tree",children:"recursive"})," step that lets us print an entire\r\ntree."]}),"\n",(0,r.jsxs)(n.aside,{name:"tree",children:["\n",(0,r.jsx)(n.p,{children:"This recursion is also why people think the Visitor pattern itself has to do\r\nwith trees."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["We don't have a parser yet, so it's hard to see this in action. For now, we'll\r\nhack together a little ",(0,r.jsx)(n.code,{children:"main()"})," method that manually instantiates a tree and\r\nprints it."]}),"\n",(0,r.jsx)(n.p,{children:"^code printer-main"}),"\n",(0,r.jsx)(n.p,{children:"If we did everything right, it prints:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"(* (- 123) (group 45.67))\n"})}),"\n",(0,r.jsx)(n.p,{children:"You can go ahead and delete this method. We won't need it. Also, as we add new\r\nsyntax tree types, I won't bother showing the necessary visit methods for them\r\nin AstPrinter. If you want to (and you want the Java compiler to not yell at\r\nyou), go ahead and add them yourself. It will come in handy in the next chapter\r\nwhen we start parsing Lox code into syntax trees. Or, if you don't care to\r\nmaintain AstPrinter, feel free to delete it. We won't need it again."}),"\n",(0,r.jsxs)(n.div,{className:"challenges",children:["\n",(0,r.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Earlier, I said that the ",(0,r.jsx)(n.code,{children:"|"}),", ",(0,r.jsx)(n.code,{children:"*"}),", and ",(0,r.jsx)(n.code,{children:"+"})," forms we added to our grammar\r\nmetasyntax were just syntactic sugar. Take this grammar:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ebnf",children:'expr \u2192 expr ( "(" ( expr ( "," expr )* )? ")" | "." IDENTIFIER )+\r\n     | IDENTIFIER\r\n     | NUMBER\n'})}),"\n",(0,r.jsx)(n.p,{children:"Produce a grammar that matches the same language but does not use any of\r\nthat notational sugar."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.em,{children:"Bonus:"})," What kind of expression does this bit of grammar encode?"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The Visitor pattern lets you emulate the functional style in an\r\nobject-oriented language. Devise a complementary pattern for a functional\r\nlanguage. It should let you bundle all of the operations on one type\r\ntogether and let you define new types easily."}),"\n",(0,r.jsx)(n.p,{children:"(SML or Haskell would be ideal for this exercise, but Scheme or another Lisp\r\nworks as well.)"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["In ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Reverse_Polish_notation",children:"reverse Polish notation"})," (RPN), the operands to an arithmetic\r\noperator are both placed before the operator, so ",(0,r.jsx)(n.code,{children:"1 + 2"})," becomes ",(0,r.jsx)(n.code,{children:"1 2 +"}),".\r\nEvaluation proceeds from left to right. Numbers are pushed onto an implicit\r\nstack. An arithmetic operator pops the top two numbers, performs the\r\noperation, and pushes the result. Thus, this:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"(1 + 2) * (4 - 3)\n"})}),"\n",(0,r.jsx)(n.p,{children:"in RPN becomes:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:"1 2 + 4 3 - *\n"})}),"\n",(0,r.jsx)(n.p,{children:"Define a visitor class for our syntax tree classes that takes an expression,\r\nconverts it to RPN, and returns the resulting string."}),"\n"]}),"\n"]}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>o});var r=t(6540);const s={},a=r.createContext(s);function i(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);