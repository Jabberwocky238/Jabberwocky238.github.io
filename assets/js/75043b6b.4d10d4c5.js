"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[2328],{3207:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>h});var r=t(4848),a=t(8453);const o={},s=void 0,i={id:"Craftinginterpreters/not-translated-yet/garbage-collection",title:"garbage-collection",description:"I wanna, I wanna,",source:"@site/docs/Craftinginterpreters/not-translated-yet/garbage-collection.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/garbage-collection",permalink:"/docs/Craftinginterpreters/not-translated-yet/garbage-collection",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/garbage-collection.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"functions",permalink:"/docs/Craftinginterpreters/not-translated-yet/functions"},next:{title:"global-variables",permalink:"/docs/Craftinginterpreters/not-translated-yet/global-variables"}},l={},h=[{value:"Reachability",id:"reachability",level:2},{value:"Mark-Sweep Garbage Collection",id:"mark-sweep-garbage-collection",level:2},{value:"Collecting garbage",id:"collecting-garbage",level:3},{value:"Debug logging",id:"debug-logging",level:3},{value:"Marking the Roots",id:"marking-the-roots",level:2},{value:"Less obvious roots",id:"less-obvious-roots",level:3},{value:"Tracing Object References",id:"tracing-object-references",level:2},{value:"The tricolor abstraction",id:"the-tricolor-abstraction",level:3},{value:"A worklist for gray objects",id:"a-worklist-for-gray-objects",level:3},{value:"Processing gray objects",id:"processing-gray-objects",level:3},{value:"Sweeping Unused Objects",id:"sweeping-unused-objects",level:2},{value:"Weak references and the string pool",id:"weak-references-and-the-string-pool",level:3},{value:"When to Collect",id:"when-to-collect",level:2},{value:"Latency and throughput",id:"latency-and-throughput",level:3},{value:"Self-adjusting heap",id:"self-adjusting-heap",level:3},{value:"Garbage Collection Bugs",id:"garbage-collection-bugs",level:2},{value:"Adding to the constant table",id:"adding-to-the-constant-table",level:3},{value:"Interning strings",id:"interning-strings",level:3},{value:"Concatenating strings",id:"concatenating-strings",level:3},{value:"Challenges",id:"challenges",level:2},{value:"Design Note: Generational Collectors",id:"design-note-generational-collectors",level:2}];function c(e){const n={a:"a",aside:"aside",blockquote:"blockquote",br:"br",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["I wanna, I wanna,",(0,r.jsx)(n.br,{}),"\r\nI wanna, I wanna,",(0,r.jsx)(n.br,{}),"\r\nI wanna be trash.",(0,r.jsx)(n.br,{})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.cite,{children:"The Whip, \u201cTrash\u201d"})}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:'We say Lox is a "high-level" language because it frees programmers from worrying\r\nabout details irrelevant to the problem they\'re solving. The user becomes an\r\nexecutive, giving the machine abstract goals and letting the lowly computer\r\nfigure out how to get there.'}),"\n",(0,r.jsx)(n.p,{children:"Dynamic memory allocation is a perfect candidate for automation. It's necessary\r\nfor a working program, tedious to do by hand, and yet still error-prone. The\r\ninevitable mistakes can be catastrophic, leading to crashes, memory corruption,\r\nor security violations. It's the kind of risky-yet-boring work that machines\r\nexcel at over humans."}),"\n",(0,r.jsxs)(n.p,{children:["This is why Lox is a ",(0,r.jsx)(n.strong,{children:"managed language"}),", which means that the language\r\nimplementation manages memory allocation and freeing on the user's behalf. When\r\na user performs an operation that requires some dynamic memory, the VM\r\nautomatically allocates it. The programmer never worries about deallocating\r\nanything. The machine ensures any memory the program is using sticks around as\r\nlong as needed."]}),"\n",(0,r.jsxs)(n.p,{children:["Lox provides the illusion that the computer has an infinite amount of memory.\r\nUsers can allocate and allocate and allocate and never once think about where\r\nall these bytes are coming from. Of course, computers do not yet ",(0,r.jsx)(n.em,{children:"have"})," infinite\r\nmemory. So the way managed languages maintain this illusion is by going behind\r\nthe programmer's back and reclaiming memory that the program no longer needs.\r\nThe component that does this is called a ",(0,r.jsxs)(n.strong,{children:["garbage ",(0,r.jsx)(n.span,{name:"recycle",children:"collector"})]}),"."]}),"\n",(0,r.jsxs)(n.aside,{name:"recycle",children:["\n",(0,r.jsxs)(n.p,{children:["Recycling would really be a better metaphor for this. The GC doesn't ",(0,r.jsx)(n.em,{children:"throw\r\naway"})," the memory, it reclaims it to be reused for new data. But managed\r\nlanguages are older than Earth Day, so the inventors went with the analogy they\r\nknew."]}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/recycle.png",className:"above",alt:"A recycle bin full of bits."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"reachability",children:"Reachability"}),"\n",(0,r.jsxs)(n.p,{children:["This raises a surprisingly difficult question: how does a VM tell what memory is\r\n",(0,r.jsx)(n.em,{children:"not"})," needed? Memory is only needed if it is read in the future, but short of\r\nhaving a time machine, how can an implementation tell what code the program\r\n",(0,r.jsx)(n.em,{children:"will"})," execute and which data it ",(0,r.jsx)(n.em,{children:"will"})," use? Spoiler alert: VMs cannot travel\r\ninto the future. Instead, the language makes a ",(0,r.jsx)(n.span,{name:"conservative",children:"conservative"})," approximation: it considers a piece of\r\nmemory to still be in use if it ",(0,r.jsx)(n.em,{children:"could possibly"})," be read in the future."]}),"\n",(0,r.jsxs)(n.aside,{name:"conservative",children:["\n",(0,r.jsxs)(n.p,{children:['I\'m using "conservative" in the general sense. There is such a thing as a\r\n"conservative garbage collector" which means something more specific. All\r\ngarbage collectors are "conservative" in that they keep memory alive if it\r\n',(0,r.jsx)(n.em,{children:"could"})," be accessed, instead of having a Magic 8-Ball that lets them more\r\nprecisely know what data ",(0,r.jsx)(n.em,{children:"will"})," be accessed."]}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"conservative GC"})," is a special kind of collector that considers any piece of\r\nmemory to be a pointer if the value in there looks like it could be an address.\r\nThis is in contrast to a ",(0,r.jsx)(n.strong,{children:"precise GC"})," -- which is what we'll implement -- that\r\nknows exactly which words in memory are pointers and which store other kinds of\r\nvalues like numbers or strings."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["That sounds ",(0,r.jsx)(n.em,{children:"too"})," conservative. Couldn't ",(0,r.jsx)(n.em,{children:"any"})," bit of memory potentially be\r\nread? Actually, no, at least not in a memory-safe language like Lox. Here's an\r\nexample:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'var a = "first value";\r\na = "updated";\r\n// GC here.\r\nprint a;\n'})}),"\n",(0,r.jsxs)(n.p,{children:['Say we run the GC after the assignment has completed on the second line. The\r\nstring "first value" is still sitting in memory, but there is no way for the\r\nuser\'s program to ever get to it. Once ',(0,r.jsx)(n.code,{children:"a"})," got reassigned, the program lost any\r\nreference to that string. We can safely free it. A value is ",(0,r.jsx)(n.strong,{children:"reachable"}),' if\r\nthere is some way for a user program to reference it. Otherwise, like the string\r\n"first value" here, it is ',(0,r.jsx)(n.strong,{children:"unreachable"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Many values can be directly accessed by the VM. Take a look at:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'var global = "string";\r\n{\r\n  var local = "another";\r\n  print global + local;\r\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Pause the program right after the two strings have been concatenated but before\r\nthe ",(0,r.jsx)(n.code,{children:"print"})," statement has executed. The VM can reach ",(0,r.jsx)(n.code,{children:'"string"'})," by looking\r\nthrough the global variable table and finding the entry for ",(0,r.jsx)(n.code,{children:"global"}),". It can\r\nfind ",(0,r.jsx)(n.code,{children:'"another"'})," by walking the value stack and hitting the slot for the local\r\nvariable ",(0,r.jsx)(n.code,{children:"local"}),". It can even find the concatenated string ",(0,r.jsx)(n.code,{children:'"stringanother"'}),"\r\nsince that temporary value is also sitting on the VM's stack at the point when\r\nwe paused our program."]}),"\n",(0,r.jsxs)(n.p,{children:["All of these values are called ",(0,r.jsx)(n.strong,{children:"roots"}),". A root is any object that the VM can\r\nreach directly without going through a reference in some other object. Most\r\nroots are global variables or on the stack, but as we'll see, there are a couple\r\nof other places the VM stores references to objects that it can find."]}),"\n",(0,r.jsxs)(n.p,{children:["Other values can be found by going through a reference inside another value.\r\n",(0,r.jsx)(n.span,{name:"class",children:"Fields"})," on instances of classes are the most obvious\r\ncase, but we don't have those yet. Even without those, our VM still has indirect\r\nreferences. Consider:"]}),"\n",(0,r.jsxs)(n.aside,{name:"class",children:["\n",(0,r.jsxs)(n.p,{children:["We'll get there ",(0,r.jsx)(n.a,{href:"classes-and-instances.html",children:"soon"}),", though!"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-lox",children:'fun makeClosure() {\r\n  var a = "data";\r\n\r\n  fun f() { print a; }\r\n  return f;\r\n}\r\n\r\n{\r\n  var closure = makeClosure();\r\n  // GC here.\r\n  closure();\r\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Say we pause the program on the marked line and run the garbage collector. When\r\nthe collector is done and the program resumes, it will call the closure, which\r\nwill in turn print ",(0,r.jsx)(n.code,{children:'"data"'}),". So the collector needs to ",(0,r.jsx)(n.em,{children:"not"})," free that string.\r\nBut here's what the stack looks like when we pause the program:"]}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/stack.png",alt:"The stack, containing only the script and closure."}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:'"data"'})," string is nowhere on it. It has already been hoisted off the stack\r\nand moved into the closed upvalue that the closure uses. The closure itself is\r\non the stack. But to get to the string, we need to trace through the closure and\r\nits upvalue array. Since it ",(0,r.jsx)(n.em,{children:"is"})," possible for the user's program to do that, all\r\nof these indirectly accessible objects are also considered reachable."]}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/reachable.png",className:"wide",alt:"All of the referenced objects from the closure, and the path to the 'data' string from the stack."}),"\n",(0,r.jsx)(n.p,{children:"This gives us an inductive definition of reachability:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"All roots are reachable."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Any object referred to from a reachable object is itself reachable."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:['These are the values that are still "live" and need to stay in memory. Any value\r\nthat ',(0,r.jsx)(n.em,{children:"doesn't"})," meet this definition is fair game for the collector to reap.\r\nThat recursive pair of rules hints at a recursive algorithm we can use to free\r\nup unneeded memory:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Starting with the roots, traverse through object references to find the\r\nfull set of reachable objects."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Free all objects ",(0,r.jsx)(n.em,{children:"not"})," in that set."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Many ",(0,r.jsx)(n.span,{name:"handbook",children:"different"})," garbage collection algorithms are in\r\nuse today, but they all roughly follow that same structure. Some may interleave\r\nthe steps or mix them, but the two fundamental operations are there. They mostly\r\ndiffer in ",(0,r.jsx)(n.em,{children:"how"})," they perform each step."]}),"\n",(0,r.jsxs)(n.aside,{name:"handbook",children:["\n",(0,r.jsxs)(n.p,{children:["If you want to explore other GC algorithms,\r\n",(0,r.jsx)(n.a,{href:"http://gchandbook.org/",children:(0,r.jsx)(n.em,{children:"The Garbage Collection Handbook"})})," (Jones, et al.) is the canonical\r\nreference. For a large book on such a deep, narrow topic, it is quite enjoyable\r\nto read. Or perhaps I have a strange idea of fun."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"mark-sweep-garbage-collection",children:"Mark-Sweep Garbage Collection"}),"\n",(0,r.jsxs)(n.p,{children:['The first managed language was Lisp, the second "high-level" language to be\r\ninvented, right after Fortran. John McCarthy considered using manual memory\r\nmanagement or reference counting, but ',(0,r.jsx)(n.span,{name:"procrastination",children:"eventually"})," settled on (and coined) garbage\r\ncollection -- once the program was out of memory, it would go back and find\r\nunused storage it could reclaim."]}),"\n",(0,r.jsxs)(n.aside,{name:"procrastination",children:["\n",(0,r.jsx)(n.p,{children:'In John McCarthy\'s "History of Lisp", he notes: "Once we decided on garbage\r\ncollection, its actual implementation could be postponed, because only toy\r\nexamples were being done." Our choice to procrastinate adding the GC to clox\r\nfollows in the footsteps of giants.'}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["He designed the very first, simplest garbage collection algorithm, called\r\n",(0,r.jsx)(n.strong,{children:"mark-and-sweep"})," or just ",(0,r.jsx)(n.strong,{children:"mark-sweep"}),". Its description fits in three short\r\nparagraphs in the initial paper on Lisp. Despite its age and simplicity, the\r\nsame fundamental algorithm underlies many modern memory managers. Some corners\r\nof CS seem to be timeless."]}),"\n",(0,r.jsx)(n.p,{children:"As the name implies, mark-sweep works in two phases:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Marking:"})," We start with the roots and traverse or ",(0,r.jsx)(n.span,{name:"trace",children:(0,r.jsx)(n.em,{children:"trace"})})," through all of the objects those roots refer to.\r\nThis is a classic graph traversal of all of the reachable objects. Each time\r\nwe visit an object, we ",(0,r.jsx)(n.em,{children:"mark"})," it in some way. (Implementations differ in how\r\nthey record the mark.)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Sweeping:"})," Once the mark phase completes, every reachable object\r\nin the heap has been marked. That means any unmarked object is unreachable and\r\nripe for reclamation. We go through all the unmarked objects and free each\r\none."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"It looks something like this:"}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/mark-sweep.png",className:"wide",alt:"Starting from a graph of objects, first the reachable ones are marked, the remaining are swept, and then only the reachable remain."}),"\n",(0,r.jsxs)(n.aside,{name:"trace",children:["\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"tracing garbage collector"})," is any algorithm that traces through the graph\r\nof object references. This is in contrast with reference counting, which has a\r\ndifferent strategy for tracking the reachable objects."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"That's what we're gonna implement. Whenever we decide it's time to reclaim some\r\nbytes, we'll trace everything and mark all the reachable objects, free what\r\ndidn't get marked, and then resume the user's program."}),"\n",(0,r.jsx)(n.h3,{id:"collecting-garbage",children:"Collecting garbage"}),"\n",(0,r.jsxs)(n.p,{children:["This entire chapter is about implementing this one ",(0,r.jsx)(n.span,{name:"one",children:"function"}),":"]}),"\n",(0,r.jsxs)(n.aside,{name:"one",children:["\n",(0,r.jsx)(n.p,{children:"Of course, we'll end up adding a bunch of helper functions too."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code collect-garbage-h (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"We'll work our way up to a full implementation starting with this empty shell:"}),"\n",(0,r.jsx)(n.p,{children:"^code collect-garbage"}),"\n",(0,r.jsx)(n.p,{children:"The first question you might ask is, When does this function get called? It\r\nturns out that's a subtle question that we'll spend some time on later in the\r\nchapter. For now we'll sidestep the issue and build ourselves a handy diagnostic\r\ntool in the process."}),"\n",(0,r.jsx)(n.p,{children:"^code define-stress-gc (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["We'll add an optional \"stress test\" mode for the garbage collector. When this\r\nflag is defined, the GC runs as often as it possibly can. This is, obviously,\r\nhorrendous for performance. But it's great for flushing out memory management\r\nbugs that occur only when a GC is triggered at just the right moment. If ",(0,r.jsx)(n.em,{children:"every"}),"\r\nmoment triggers a GC, you're likely to find those bugs."]}),"\n",(0,r.jsx)(n.p,{children:"^code call-collect (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Whenever we call ",(0,r.jsx)(n.code,{children:"reallocate()"})," to acquire more memory, we force a collection to\r\nrun. The if check is because ",(0,r.jsx)(n.code,{children:"reallocate()"})," is also called to free or shrink an\r\nallocation. We don't want to trigger a GC for that -- in particular because the\r\nGC itself will call ",(0,r.jsx)(n.code,{children:"reallocate()"})," to free memory."]}),"\n",(0,r.jsxs)(n.p,{children:["Collecting right before ",(0,r.jsx)(n.span,{name:"demand",children:"allocation"})," is the classic way\r\nto wire a GC into a VM. You're already calling into the memory manager, so it's\r\nan easy place to hook in the code. Also, allocation is the only time when you\r\nreally ",(0,r.jsx)(n.em,{children:"need"})," some freed up memory so that you can reuse it. If you ",(0,r.jsx)(n.em,{children:"don't"})," use\r\nallocation to trigger a GC, you have to make sure every possible place in code\r\nwhere you can loop and allocate memory also has a way to trigger the collector.\r\nOtherwise, the VM can get into a starved state where it needs more memory but\r\nnever collects any."]}),"\n",(0,r.jsxs)(n.aside,{name:"demand",children:["\n",(0,r.jsx)(n.p,{children:"More sophisticated collectors might run on a separate thread or be interleaved\r\nperiodically during program execution -- often at function call boundaries or\r\nwhen a backward jump occurs."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"debug-logging",children:"Debug logging"}),"\n",(0,r.jsxs)(n.p,{children:["While we're on the subject of diagnostics, let's put some more in. A real\r\nchallenge I've found with garbage collectors is that they are opaque. We've been\r\nrunning lots of Lox programs just fine without any GC ",(0,r.jsx)(n.em,{children:"at all"})," so far. Once we\r\nadd one, how do we tell if it's doing anything useful? Can we tell only if we\r\nwrite programs that plow through acres of memory? How do we debug that?"]}),"\n",(0,r.jsx)(n.p,{children:"An easy way to shine a light into the GC's inner workings is with some logging."}),"\n",(0,r.jsx)(n.p,{children:"^code define-log-gc (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"When this is enabled, clox prints information to the console when it does\r\nsomething with dynamic memory."}),"\n",(0,r.jsx)(n.p,{children:"We need a couple of includes."}),"\n",(0,r.jsx)(n.p,{children:"^code debug-log-includes (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"We don't have a collector yet, but we can start putting in some of the logging\r\nnow. We'll want to know when a collection run starts."}),"\n",(0,r.jsx)(n.p,{children:"^code log-before-collect (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Eventually we will log some other operations during the collection, so we'll\r\nalso want to know when the show's over."}),"\n",(0,r.jsx)(n.p,{children:"^code log-after-collect (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"We don't have any code for the collector yet, but we do have functions for\r\nallocating and freeing, so we can instrument those now."}),"\n",(0,r.jsx)(n.p,{children:"^code debug-log-allocate (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"And at the end of an object's lifespan:"}),"\n",(0,r.jsx)(n.p,{children:"^code log-free-object (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"With these two flags, we should be able to see that we're making progress as we\r\nwork through the rest of the chapter."}),"\n",(0,r.jsx)(n.h2,{id:"marking-the-roots",children:"Marking the Roots"}),"\n",(0,r.jsx)(n.p,{children:"Objects are scattered across the heap like stars in the inky night sky. A\r\nreference from one object to another forms a connection, and these\r\nconstellations are the graph that the mark phase traverses. Marking begins at\r\nthe roots."}),"\n",(0,r.jsx)(n.p,{children:"^code call-mark-roots (3 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"Most roots are local variables or temporaries sitting right in the VM's stack,\r\nso we start by walking that."}),"\n",(0,r.jsx)(n.p,{children:"^code mark-roots"}),"\n",(0,r.jsx)(n.p,{children:"To mark a Lox value, we use this new function:"}),"\n",(0,r.jsx)(n.p,{children:"^code mark-value-h (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Its implementation is here:"}),"\n",(0,r.jsx)(n.p,{children:"^code mark-value"}),"\n",(0,r.jsxs)(n.p,{children:["Some Lox values -- numbers, Booleans, and ",(0,r.jsx)(n.code,{children:"nil"})," -- are stored directly inline in\r\nValue and require no heap allocation. The garbage collector doesn't need to\r\nworry about them at all, so the first thing we do is ensure that the value is an\r\nactual heap object. If so, the real work happens in this function:"]}),"\n",(0,r.jsx)(n.p,{children:"^code mark-object-h (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Which is defined here:"}),"\n",(0,r.jsx)(n.p,{children:"^code mark-object"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"NULL"})," check is unnecessary when called from ",(0,r.jsx)(n.code,{children:"markValue()"}),". A Lox Value that\r\nis some kind of Obj type will always have a valid pointer. But later we will\r\ncall this function directly from other code, and in some of those places, the\r\nobject being pointed to is optional."]}),"\n",(0,r.jsx)(n.p,{children:"Assuming we do have a valid object, we mark it by setting a flag. That new field\r\nlives in the Obj header struct all objects share."}),"\n",(0,r.jsx)(n.p,{children:"^code is-marked-field (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Every new object begins life unmarked because we haven't yet determined if it is\r\nreachable or not."}),"\n",(0,r.jsx)(n.p,{children:"^code init-is-marked (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Before we go any farther, let's add some logging to ",(0,r.jsx)(n.code,{children:"markObject()"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"^code log-mark-object (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"This way we can see what the mark phase is doing. Marking the stack takes care\r\nof local variables and temporaries. The other main source of roots are the\r\nglobal variables."}),"\n",(0,r.jsx)(n.p,{children:"^code mark-globals (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Those live in a hash table owned by the VM, so we'll declare another helper\r\nfunction for marking all of the objects in a table."}),"\n",(0,r.jsx)(n.p,{children:"^code mark-table-h (2 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:'We implement that in the "table" module here:'}),"\n",(0,r.jsx)(n.p,{children:"^code mark-table"}),"\n",(0,r.jsx)(n.p,{children:"Pretty straightforward. We walk the entry array. For each one, we mark its\r\nvalue. We also mark the key strings for each entry since the GC manages those\r\nstrings too."}),"\n",(0,r.jsx)(n.h3,{id:"less-obvious-roots",children:"Less obvious roots"}),"\n",(0,r.jsx)(n.p,{children:"Those cover the roots that we typically think of -- the values that are\r\nobviously reachable because they're stored in variables the user's program can\r\nsee. But the VM has a few of its own hidey-holes where it squirrels away\r\nreferences to values that it directly accesses."}),"\n",(0,r.jsx)(n.p,{children:"Most function call state lives in the value stack, but the VM maintains a\r\nseparate stack of CallFrames. Each CallFrame contains a pointer to the closure\r\nbeing called. The VM uses those pointers to access constants and upvalues, so\r\nthose closures need to be kept around too."}),"\n",(0,r.jsx)(n.p,{children:"^code mark-closures (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"Speaking of upvalues, the open upvalue list is another set of values that the\r\nVM can directly reach."}),"\n",(0,r.jsx)(n.p,{children:"^code mark-open-upvalues (3 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Remember also that a collection can begin during ",(0,r.jsx)(n.em,{children:"any"})," allocation. Those\r\nallocations don't just happen while the user's program is running. The compiler\r\nitself periodically grabs memory from the heap for literals and the constant\r\ntable. If the GC runs while we're in the middle of compiling, then any values\r\nthe compiler directly accesses need to be treated as roots too."]}),"\n",(0,r.jsx)(n.p,{children:"To keep the compiler module cleanly separated from the rest of the VM, we'll do\r\nthat in a separate function."}),"\n",(0,r.jsx)(n.p,{children:"^code call-mark-compiler-roots (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"It's declared here:"}),"\n",(0,r.jsx)(n.p,{children:"^code mark-compiler-roots-h (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:'Which means the "memory" module needs an include.'}),"\n",(0,r.jsx)(n.p,{children:"^code memory-include-compiler (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:'And the definition is over in the "compiler" module.'}),"\n",(0,r.jsx)(n.p,{children:"^code mark-compiler-roots"}),"\n",(0,r.jsx)(n.p,{children:"Fortunately, the compiler doesn't have too many values that it hangs on to. The\r\nonly object it uses is the ObjFunction it is compiling into. Since function\r\ndeclarations can nest, the compiler has a linked list of those and we walk the\r\nwhole list."}),"\n",(0,r.jsxs)(n.p,{children:['Since the "compiler" module is calling ',(0,r.jsx)(n.code,{children:"markObject()"}),", it also needs an include."]}),"\n",(0,r.jsx)(n.p,{children:"^code compiler-include-memory (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Those are all the roots. After running this, every object that the VM -- runtime\r\nand compiler -- can get to ",(0,r.jsx)(n.em,{children:"without"})," going through some other object has its\r\nmark bit set."]}),"\n",(0,r.jsx)(n.h2,{id:"tracing-object-references",children:"Tracing Object References"}),"\n",(0,r.jsxs)(n.p,{children:["The next step in the marking process is tracing through the graph of references\r\nbetween objects to find the indirectly reachable values. We don't have instances\r\nwith fields yet, so there aren't many objects that contain references, but we do\r\nhave ",(0,r.jsx)(n.span,{name:"some",children:"some"}),". In particular, ObjClosure has the list of\r\nObjUpvalues it closes over as well as a reference to the raw ObjFunction that it\r\nwraps. ObjFunction, in turn, has a constant table containing references to all\r\nof the literals created in the function's body. This is enough to build a fairly\r\ncomplex web of objects for our collector to crawl through."]}),"\n",(0,r.jsxs)(n.aside,{name:"some",children:["\n",(0,r.jsxs)(n.p,{children:["I slotted this chapter into the book right here specifically ",(0,r.jsx)(n.em,{children:"because"})," we now\r\nhave closures which give us interesting objects for the garbage collector to\r\nprocess."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Now it's time to implement that traversal. We can go breadth-first, depth-first,\r\nor in some other order. Since we just need to find the ",(0,r.jsx)(n.em,{children:"set"})," of all reachable\r\nobjects, the order we visit them ",(0,r.jsx)(n.span,{name:"dfs",children:"mostly"})," doesn't matter."]}),"\n",(0,r.jsxs)(n.aside,{name:"dfs",children:["\n",(0,r.jsx)(n.p,{children:'I say "mostly" because some garbage collectors move objects in the order that\r\nthey are visited, so traversal order determines which objects end up adjacent in\r\nmemory. That impacts performance because the CPU uses locality to determine\r\nwhich memory to preload into the caches.'}),"\n",(0,r.jsxs)(n.p,{children:["Even when traversal order does matter, it's not clear which order is ",(0,r.jsx)(n.em,{children:"best"}),".\r\nIt's very difficult to determine which order objects will be used in in the\r\nfuture, so it's hard for the GC to know which order will help performance."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"the-tricolor-abstraction",children:"The tricolor abstraction"}),"\n",(0,r.jsx)(n.p,{children:"As the collector wanders through the graph of objects, we need to make sure it\r\ndoesn't lose track of where it is or get stuck going in circles. This is\r\nparticularly a concern for advanced implementations like incremental GCs that\r\ninterleave marking with running pieces of the user's program. The collector\r\nneeds to be able to pause and then pick up where it left off later."}),"\n",(0,r.jsxs)(n.p,{children:["To help us soft-brained humans reason about this complex process, VM hackers\r\ncame up with a metaphor called the ",(0,r.jsx)(n.span,{name:"color"}),(0,r.jsx)(n.strong,{children:"tricolor\r\nabstraction"}),'. Each object has a conceptual "color" that tracks what state the\r\nobject is in, and what work is left to do.']}),"\n",(0,r.jsxs)(n.aside,{name:"color",children:["\n",(0,r.jsx)(n.p,{children:"Advanced garbage collection algorithms often add other colors to the\r\nabstraction. I've seen multiple shades of gray, and even purple in some designs.\r\nMy puce-chartreuse-fuchsia-malachite collector paper was, alas, not accepted for\r\npublication."}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.img,{src:"image/garbage-collection/white.png",alt:"A white circle.",className:"dot"})," White:"]})," At the beginning of a garbage collection, every\r\nobject is white. This color means we have not reached or processed the\r\nobject at all."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.img,{src:"image/garbage-collection/gray.png",alt:"A gray circle.",className:"dot"})," Gray:"]})," During marking, when we first reach an object, we\r\ndarken it gray. This color means we know the object itself is reachable and\r\nshould not be collected. But we have not yet traced ",(0,r.jsx)(n.em,{children:"through"})," it to see what\r\n",(0,r.jsx)(n.em,{children:"other"})," objects it references. In graph algorithm terms, this is the\r\n",(0,r.jsx)(n.em,{children:"worklist"})," -- the set of objects we know about but haven't processed yet."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsxs)(n.strong,{children:[(0,r.jsx)(n.img,{src:"image/garbage-collection/black.png",alt:"A black circle.",className:"dot"})," Black:"]})," When\r\nwe take a gray object and mark all of the objects it references, we then\r\nturn the gray object black. This color means the mark phase is done\r\nprocessing that object."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"In terms of that abstraction, the marking process now looks like this:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Start off with all objects white."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Find all the roots and mark them gray."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Repeat as long as there are still gray objects:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Pick a gray object. Turn any white objects that the object mentions to\r\ngray."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Mark the original gray object black."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"I find it helps to visualize this. You have a web of objects with references\r\nbetween them. Initially, they are all little white dots. Off to the side are\r\nsome incoming edges from the VM that point to the roots. Those roots turn gray.\r\nThen each gray object's siblings turn gray while the object itself turns black.\r\nThe full effect is a gray wavefront that passes through the graph, leaving a\r\nfield of reachable black objects behind it. Unreachable objects are not touched\r\nby the wavefront and stay white."}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/tricolor-trace.png",className:"wide",alt:"A gray wavefront working through a graph of nodes."}),"\n",(0,r.jsxs)(n.p,{children:["At the ",(0,r.jsx)(n.span,{name:"invariant",children:"end"}),", you're left with a sea of reached,\r\nblack objects sprinkled with islands of white objects that can be swept up and\r\nfreed. Once the unreachable objects are freed, the remaining objects -- all\r\nblack -- are reset to white for the next garbage collection cycle."]}),"\n",(0,r.jsxs)(n.aside,{name:"invariant",children:["\n",(0,r.jsxs)(n.p,{children:["Note that at every step of this process no black node ever points to a white\r\nnode. This property is called the ",(0,r.jsx)(n.strong,{children:"tricolor invariant"}),". The traversal process\r\nmaintains this invariant to ensure that no reachable object is ever collected."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"a-worklist-for-gray-objects",children:"A worklist for gray objects"}),"\n",(0,r.jsx)(n.p,{children:"In our implementation we have already marked the roots. They're all gray. The\r\nnext step is to start picking them and traversing their references. But we don't\r\nhave any easy way to find them. We set a field on the object, but that's it. We\r\ndon't want to have to traverse the entire object list looking for objects with\r\nthat field set."}),"\n",(0,r.jsx)(n.p,{children:"Instead, we'll create a separate worklist to keep track of all of the gray\r\nobjects. When an object turns gray, in addition to setting the mark field we'll\r\nalso add it to the worklist."}),"\n",(0,r.jsx)(n.p,{children:"^code add-to-gray-stack (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["We could use any kind of data structure that lets us put items in and take them\r\nout easily. I picked a stack because that's the simplest to implement with a\r\ndynamic array in C. It works mostly like other dynamic arrays we've built in\r\nLox, ",(0,r.jsx)(n.em,{children:"except"}),", note that it calls the ",(0,r.jsx)(n.em,{children:"system"})," ",(0,r.jsx)(n.code,{children:"realloc()"})," function and not our\r\nown ",(0,r.jsx)(n.code,{children:"reallocate()"})," wrapper. The memory for the gray stack itself is ",(0,r.jsx)(n.em,{children:"not"}),"\r\nmanaged by the garbage collector. We don't want growing the gray stack during a\r\nGC to cause the GC to recursively start a new GC. That could tear a hole in the\r\nspace-time continuum."]}),"\n",(0,r.jsx)(n.p,{children:"We'll manage its memory ourselves, explicitly. The VM owns the gray stack."}),"\n",(0,r.jsx)(n.p,{children:"^code vm-gray-stack (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"It starts out empty."}),"\n",(0,r.jsx)(n.p,{children:"^code init-gray-stack (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"And we need to free it when the VM shuts down."}),"\n",(0,r.jsx)(n.p,{children:"^code free-gray-stack (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.span,{name:"robust",children:"We"})," take full responsibility for this array. That\r\nincludes allocation failure. If we can't create or grow the gray stack, then we\r\ncan't finish the garbage collection. This is bad news for the VM, but\r\nfortunately rare since the gray stack tends to be pretty small. It would be nice\r\nto do something more graceful, but to keep the code in this book simple, we just\r\nabort."]}),"\n",(0,r.jsxs)(n.aside,{name:"robust",children:["\n",(0,r.jsx)(n.p,{children:'To be more robust, we can allocate a "rainy day fund" block of memory when we\r\nstart the VM. If the gray stack allocation fails, we free the rainy day block\r\nand try again. That may give us enough wiggle room on the heap to create the\r\ngray stack, finish the GC, and free up more memory.'}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"^code exit-gray-stack (2 before, 1 after)"}),"\n",(0,r.jsx)(n.h3,{id:"processing-gray-objects",children:"Processing gray objects"}),"\n",(0,r.jsx)(n.p,{children:"OK, now when we're done marking the roots, we have both set a bunch of fields\r\nand filled our work list with objects to chew through. It's time for the next\r\nphase."}),"\n",(0,r.jsx)(n.p,{children:"^code call-trace-references (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"Here's the implementation:"}),"\n",(0,r.jsx)(n.p,{children:"^code trace-references"}),"\n",(0,r.jsx)(n.p,{children:"It's as close to that textual algorithm as you can get. Until the stack empties,\r\nwe keep pulling out gray objects, traversing their references, and then marking\r\nthem black. Traversing an object's references may turn up new white objects that\r\nget marked gray and added to the stack. So this function swings back and forth\r\nbetween turning white objects gray and gray objects black, gradually advancing\r\nthe entire wavefront forward."}),"\n",(0,r.jsx)(n.p,{children:"Here's where we traverse a single object's references:"}),"\n",(0,r.jsx)(n.p,{children:"^code blacken-object"}),"\n",(0,r.jsxs)(n.p,{children:["Each object ",(0,r.jsx)(n.span,{name:"leaf",children:"kind"})," has different fields that might\r\nreference other objects, so we need a specific blob of code for each type. We\r\nstart with the easy ones -- strings and native function objects contain no\r\noutgoing references so there is nothing to traverse."]}),"\n",(0,r.jsxs)(n.aside,{name:"leaf",children:["\n",(0,r.jsxs)(n.p,{children:["An easy optimization we could do in ",(0,r.jsx)(n.code,{children:"markObject()"})," is to skip adding strings and\r\nnative functions to the gray stack at all since we know they don't need to be\r\nprocessed. Instead, they could darken from white straight to black."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Note that we don't set any state in the traversed object itself. There is no\r\ndirect encoding of \"black\" in the object's state. A black object is any object\r\nwhose ",(0,r.jsx)(n.code,{children:"isMarked"})," field is ",(0,r.jsx)(n.span,{name:"field",children:"set"})," and that is no longer in\r\nthe gray stack."]}),"\n",(0,r.jsxs)(n.aside,{name:"field",children:["\n",(0,r.jsxs)(n.p,{children:["You may rightly wonder why we have the ",(0,r.jsx)(n.code,{children:"isMarked"})," field at all. All in good\r\ntime, friend."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Now let's start adding in the other object types. The simplest is upvalues."}),"\n",(0,r.jsx)(n.p,{children:"^code blacken-upvalue (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"When an upvalue is closed, it contains a reference to the closed-over value.\r\nSince the value is no longer on the stack, we need to make sure we trace the\r\nreference to it from the upvalue."}),"\n",(0,r.jsx)(n.p,{children:"Next are functions."}),"\n",(0,r.jsx)(n.p,{children:"^code blacken-function (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Each function has a reference to an ObjString containing the function's name.\r\nMore importantly, the function has a constant table packed full of references to\r\nother objects. We trace all of those using this helper:"}),"\n",(0,r.jsx)(n.p,{children:"^code mark-array"}),"\n",(0,r.jsx)(n.p,{children:"The last object type we have now -- we'll add more in later chapters -- is\r\nclosures."}),"\n",(0,r.jsx)(n.p,{children:"^code blacken-closure (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Each closure has a reference to the bare function it wraps, as well as an array\r\nof pointers to the upvalues it captures. We trace all of those."}),"\n",(0,r.jsx)(n.p,{children:"That's the basic mechanism for processing a gray object, but there are two loose\r\nends to tie up. First, some logging."}),"\n",(0,r.jsx)(n.p,{children:"^code log-blacken-object (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["This way, we can watch the tracing percolate through the object graph. Speaking\r\nof which, note that I said ",(0,r.jsx)(n.em,{children:"graph"}),". References between objects are directed, but\r\nthat doesn't mean they're ",(0,r.jsx)(n.em,{children:"acyclic!"})," It's entirely possible to have cycles of\r\nobjects. When that happens, we need to ensure our collector doesn't get stuck in\r\nan infinite loop as it continually re-adds the same series of objects to the\r\ngray stack."]}),"\n",(0,r.jsx)(n.p,{children:"The fix is easy."}),"\n",(0,r.jsx)(n.p,{children:"^code check-is-marked (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"If the object is already marked, we don't mark it again and thus don't add it to\r\nthe gray stack. This ensures that an already-gray object is not redundantly\r\nadded and that a black object is not inadvertently turned back to gray. In other\r\nwords, it keeps the wavefront moving forward through only the white objects."}),"\n",(0,r.jsx)(n.h2,{id:"sweeping-unused-objects",children:"Sweeping Unused Objects"}),"\n",(0,r.jsxs)(n.p,{children:["When the loop in ",(0,r.jsx)(n.code,{children:"traceReferences()"})," exits, we have processed all the objects we\r\ncould get our hands on. The gray stack is empty, and every object in the heap is\r\neither black or white. The black objects are reachable, and we want to hang on to\r\nthem. Anything still white never got touched by the trace and is thus garbage.\r\nAll that's left is to reclaim them."]}),"\n",(0,r.jsx)(n.p,{children:"^code call-sweep (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"All of the logic lives in one function."}),"\n",(0,r.jsx)(n.p,{children:"^code sweep"}),"\n",(0,r.jsxs)(n.p,{children:["I know that's kind of a lot of code and pointer shenanigans, but there isn't\r\nmuch to it once you work through it. The outer ",(0,r.jsx)(n.code,{children:"while"})," loop walks the linked\r\nlist of every object in the heap, checking their mark bits. If an object is\r\nmarked (black), we leave it alone and continue past it. If it is unmarked\r\n(white), we unlink it from the list and free it using the ",(0,r.jsx)(n.code,{children:"freeObject()"}),"\r\nfunction we already wrote."]}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/unlink.png",alt:"A recycle bin full of bits."}),"\n",(0,r.jsx)(n.p,{children:"Most of the other code in here deals with the fact that removing a node from a\r\nsingly linked list is cumbersome. We have to continuously remember the previous\r\nnode so we can unlink its next pointer, and we have to handle the edge case\r\nwhere we are freeing the first node. But, otherwise, it's pretty simple --\r\ndelete every node in a linked list that doesn't have a bit set in it."}),"\n",(0,r.jsx)(n.p,{children:"There's one little addition:"}),"\n",(0,r.jsx)(n.p,{children:"^code unmark (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["After ",(0,r.jsx)(n.code,{children:"sweep()"})," completes, the only remaining objects are the live black ones\r\nwith their mark bits set. That's correct, but when the ",(0,r.jsx)(n.em,{children:"next"})," collection cycle\r\nstarts, we need every object to be white. So whenever we reach a black object,\r\nwe go ahead and clear the bit now in anticipation of the next run."]}),"\n",(0,r.jsx)(n.h3,{id:"weak-references-and-the-string-pool",children:"Weak references and the string pool"}),"\n",(0,r.jsx)(n.p,{children:"We are almost done collecting. There is one remaining corner of the VM that has\r\nsome unusual requirements around memory. Recall that when we added strings to\r\nclox we made the VM intern them all. That means the VM has a hash table\r\ncontaining a pointer to every single string in the heap. The VM uses this to\r\nde-duplicate strings."}),"\n",(0,r.jsxs)(n.p,{children:["During the mark phase, we deliberately did ",(0,r.jsx)(n.em,{children:"not"})," treat the VM's string table as\r\na source of roots. If we had, no ",(0,r.jsx)(n.span,{name:"intern",children:"string"})," would ",(0,r.jsx)(n.em,{children:"ever"}),"\r\nbe collected. The string table would grow and grow and never yield a single byte\r\nof memory back to the operating system. That would be bad."]}),"\n",(0,r.jsxs)(n.aside,{name:"intern",children:["\n",(0,r.jsxs)(n.p,{children:["This can be a real problem. Java does not intern ",(0,r.jsx)(n.em,{children:"all"})," strings, but it does\r\nintern string ",(0,r.jsx)(n.em,{children:"literals"}),". It also provides an API to add strings to the string\r\ntable. For many years, the capacity of that table was fixed, and strings added\r\nto it could never be removed. If users weren't careful about their use of\r\n",(0,r.jsx)(n.code,{children:"String.intern()"}),", they could run out of memory and crash."]}),"\n",(0,r.jsx)(n.p,{children:"Ruby had a similar problem for years where symbols -- interned string-like\r\nvalues -- were not garbage collected. Both eventually enabled the GC to collect\r\nthese strings."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["At the same time, if we ",(0,r.jsx)(n.em,{children:"do"})," let the GC free strings, then the VM's string table\r\nwill be left with dangling pointers to freed memory. That would be even worse."]}),"\n",(0,r.jsxs)(n.p,{children:["The string table is special and we need special support for it. In particular,\r\nit needs a special kind of reference. The table should be able to refer to a\r\nstring, but that link should not be considered a root when determining\r\nreachability. That implies that the referenced object can be freed. When that\r\nhappens, the dangling reference must be fixed too, sort of like a magic,\r\nself-clearing pointer. This particular set of semantics comes up frequently\r\nenough that it has a name: a ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Weak_reference",children:(0,r.jsx)(n.strong,{children:"weak reference"})}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["We have already implicitly implemented half of the string table's unique\r\nbehavior by virtue of the fact that we ",(0,r.jsx)(n.em,{children:"don't"})," traverse it during marking. That\r\nmeans it doesn't force strings to be reachable. The remaining piece is clearing\r\nout any dangling pointers for strings that are freed."]}),"\n",(0,r.jsxs)(n.p,{children:["To remove references to unreachable strings, we need to know which strings ",(0,r.jsx)(n.em,{children:"are"}),"\r\nunreachable. We don't know that until after the mark phase has completed. But we\r\ncan't wait until after the sweep phase is done because by then the objects --\r\nand their mark bits -- are no longer around to check. So the right time is\r\nexactly between the marking and sweeping phases."]}),"\n",(0,r.jsx)(n.p,{children:"^code sweep-strings (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:'The logic for removing the about-to-be-deleted strings exists in a new function\r\nin the "table" module.'}),"\n",(0,r.jsx)(n.p,{children:"^code table-remove-white-h (2 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"The implementation is here:"}),"\n",(0,r.jsx)(n.p,{children:"^code table-remove-white"}),"\n",(0,r.jsxs)(n.p,{children:["We walk every entry in the table. The string intern table uses only the key of\r\neach entry -- it's basically a hash ",(0,r.jsx)(n.em,{children:"set"})," not a hash ",(0,r.jsx)(n.em,{children:"map"}),". If the key string\r\nobject's mark bit is not set, then it is a white object that is moments from\r\nbeing swept away. We delete it from the hash table first and thus ensure we\r\nwon't see any dangling pointers."]}),"\n",(0,r.jsx)(n.h2,{id:"when-to-collect",children:"When to Collect"}),"\n",(0,r.jsx)(n.p,{children:"We have a fully functioning mark-sweep garbage collector now. When the stress\r\ntesting flag is enabled, it gets called all the time, and with the logging\r\nenabled too, we can watch it do its thing and see that it is indeed reclaiming\r\nmemory. But, when the stress testing flag is off, it never runs at all. It's\r\ntime to decide when the collector should be invoked during normal program\r\nexecution."}),"\n",(0,r.jsx)(n.p,{children:"As far as I can tell, this question is poorly answered by the literature. When\r\ngarbage collectors were first invented, computers had a tiny, fixed amount of\r\nmemory. Many of the early GC papers assumed that you set aside a few thousand\r\nwords of memory -- in other words, most of it -- and invoked the collector\r\nwhenever you ran out. Simple."}),"\n",(0,r.jsx)(n.p,{children:'Modern machines have gigs of physical RAM, hidden behind the operating system\'s\r\neven larger virtual memory abstraction, which is shared among a slew of other\r\nprograms all fighting for their chunk of memory. The operating system will let\r\nyour program request as much as it wants and then page in and out from the disc\r\nwhen physical memory gets full. You never really "run out" of memory, you just\r\nget slower and slower.'}),"\n",(0,r.jsx)(n.h3,{id:"latency-and-throughput",children:"Latency and throughput"}),"\n",(0,r.jsxs)(n.p,{children:["It no longer makes sense to wait until you \"have to\", to run the GC, so we need\r\na more subtle timing strategy. To reason about this more precisely, it's time to\r\nintroduce two fundamental numbers used when measuring a memory manager's\r\nperformance: ",(0,r.jsx)(n.em,{children:"throughput"})," and ",(0,r.jsx)(n.em,{children:"latency"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Every managed language pays a performance price compared to explicit,\r\nuser-authored deallocation. The time spent actually freeing memory is the same,\r\nbut the GC spends cycles figuring out ",(0,r.jsx)(n.em,{children:"which"})," memory to free. That is time ",(0,r.jsx)(n.em,{children:"not"}),"\r\nspent running the user's code and doing useful work. In our implementation,\r\nthat's the entirety of the mark phase. The goal of a sophisticated garbage\r\ncollector is to minimize that overhead."]}),"\n",(0,r.jsx)(n.p,{children:"There are two key metrics we can use to understand that cost better:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Throughput"})," is the total fraction of time spent running user code versus\r\ndoing garbage collection work. Say you run a clox program for ten seconds\r\nand it spends a second of that inside ",(0,r.jsx)(n.code,{children:"collectGarbage()"}),". That means the\r\nthroughput is 90% -- it spent 90% of the time running the program and 10%\r\non GC overhead."]}),"\n",(0,r.jsxs)(n.p,{children:["Throughput is the most fundamental measure because it tracks the total cost\r\nof collection overhead. All else being equal, you want to maximize\r\nthroughput. Up until this chapter, clox had no GC at all and thus ",(0,r.jsx)(n.span,{name:"hundred",children:"100%"})," throughput. That's pretty hard to beat. Of\r\ncourse, it came at the slight expense of potentially running out of memory\r\nand crashing if the user's program ran long enough. You can look at the goal\r\nof a GC as fixing that \"glitch\" while sacrificing as little throughput as\r\npossible."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.aside,{name:"hundred",children:["\n",(0,r.jsxs)(n.p,{children:["Well, not ",(0,r.jsx)(n.em,{children:"exactly"})," 100%. It did still put the allocated objects into a linked\r\nlist, so there was some tiny overhead for setting those pointers."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Latency"})," is the longest ",(0,r.jsx)(n.em,{children:"continuous"})," chunk of time where the user's\r\nprogram is completely paused while garbage collection happens. It's a\r\nmeasure of how \"chunky\" the collector is. Latency is an entirely different\r\nmetric than throughput."]}),"\n",(0,r.jsxs)(n.p,{children:["Consider two runs of a clox program that both take ten seconds. In the first\r\nrun, the GC kicks in once and spends a solid second in ",(0,r.jsx)(n.code,{children:"collectGarbage()"})," in\r\none massive collection. In the second run, the GC gets invoked five times,\r\neach for a fifth of a second. The ",(0,r.jsx)(n.em,{children:"total"})," amount of time spent collecting is\r\nstill a second, so the throughput is 90% in both cases. But in the second\r\nrun, the latency is only 1/5th of a second, five times less than in the\r\nfirst."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"latency"})}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/latency-throughput.png",alt:"A bar representing execution time with slices for running user code and running the GC. The largest GC slice is latency. The size of all of the user code slices is throughput."}),"\n",(0,r.jsxs)(n.aside,{name:"latency",children:["\n",(0,r.jsx)(n.p,{children:"The bar represents the execution of a program, divided into time spent running\r\nuser code and time spent in the GC. The size of the largest single slice of time\r\nrunning the GC is the latency. The size of all of the user code slices added up\r\nis the throughput."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"If you like analogies, imagine your program is a bakery selling fresh-baked\r\nbread to customers. Throughput is the total number of warm, crusty baguettes you\r\ncan serve to customers in a single day. Latency is how long the unluckiest\r\ncustomer has to wait in line before they get served."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.span,{name:"dishwasher",children:"Running"})," the garbage collector is like shutting\r\ndown the bakery temporarily to go through all of the dishes, sort out the dirty\r\nfrom the clean, and then wash the used ones. In our analogy, we don't have\r\ndedicated dishwashers, so while this is going on, no baking is happening. The\r\nbaker is washing up."]}),"\n",(0,r.jsxs)(n.aside,{name:"dishwasher",children:["\n",(0,r.jsxs)(n.p,{children:["If each person represents a thread, then an obvious optimization is to have\r\nseparate threads running garbage collection, giving you a ",(0,r.jsx)(n.strong,{children:"concurrent garbage\r\ncollector"}),". In other words, hire some dishwashers to clean while others bake.\r\nThis is how very sophisticated GCs work because it does let the bakers\r\n-- the worker threads -- keep running user code with little interruption."]}),"\n",(0,r.jsx)(n.p,{children:"However, coordination is required. You don't want a dishwasher grabbing a bowl\r\nout of a baker's hands! This coordination adds overhead and a lot of complexity.\r\nConcurrent collectors are fast, but challenging to implement correctly."}),"\n",(0,r.jsx)(n.img,{src:"image/garbage-collection/baguette.png",className:"above",alt:"Un baguette."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Selling fewer loaves of bread a day is bad, and making any particular customer\r\nsit and wait while you clean all the dishes is too. The goal is to maximize\r\nthroughput and minimize latency, but there is no free lunch, even inside a\r\nbakery. Garbage collectors make different trade-offs between how much throughput\r\nthey sacrifice and latency they tolerate."}),"\n",(0,r.jsxs)(n.p,{children:["Being able to make these trade-offs is useful because different user programs\r\nhave different needs. An overnight batch job that is generating a report from a\r\nterabyte of data just needs to get as much work done as fast as possible.\r\nThroughput is queen. Meanwhile, an app running on a user's smartphone needs to\r\nalways respond immediately to user input so that dragging on the screen feels\r\n",(0,r.jsx)(n.span,{name:"butter",children:"buttery"})," smooth. The app can't freeze for a few\r\nseconds while the GC mucks around in the heap."]}),"\n",(0,r.jsxs)(n.aside,{name:"butter",children:["\n",(0,r.jsx)(n.p,{children:"Clearly the baking analogy is going to my head."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["As a garbage collector author, you control some of the trade-off between\r\nthroughput and latency by your choice of collection algorithm. But even within a\r\nsingle algorithm, we have a lot of control over ",(0,r.jsx)(n.em,{children:"how frequently"})," the collector\r\nruns."]}),"\n",(0,r.jsxs)(n.p,{children:["Our collector is a ",(0,r.jsx)(n.span,{name:"incremental",children:(0,r.jsx)(n.strong,{children:"stop-the-world GC"})})," which\r\nmeans the user's program is paused until the entire garbage collection process\r\nhas completed. If we wait a long time before we run the collector, then a large\r\nnumber of dead objects will accumulate. That leads to a very long pause while\r\nthe collector runs, and thus high latency. So, clearly, we want to run the\r\ncollector really frequently."]}),"\n",(0,r.jsxs)(n.aside,{name:"incremental",children:["\n",(0,r.jsxs)(n.p,{children:["In contrast, an ",(0,r.jsx)(n.strong,{children:"incremental garbage collector"})," can do a little collection,\r\nthen run some user code, then collect a little more, and so on."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["But every time the collector runs, it spends some time visiting live objects.\r\nThat doesn't really ",(0,r.jsx)(n.em,{children:"do"})," anything useful (aside from ensuring that they don't\r\nincorrectly get deleted). Time visiting live objects is time not freeing memory\r\nand also time not running user code. If you run the GC ",(0,r.jsx)(n.em,{children:"really"})," frequently, then\r\nthe user's program doesn't have enough time to even generate new garbage for the\r\nVM to collect. The VM will spend all of its time obsessively revisiting the same\r\nset of live objects over and over, and throughput will suffer. So, clearly, we\r\nwant to run the collector really ",(0,r.jsx)(n.em,{children:"in"}),"frequently."]}),"\n",(0,r.jsx)(n.p,{children:"In fact, we want something in the middle, and the frequency of when the\r\ncollector runs is one of our main knobs for tuning the trade-off between latency\r\nand throughput."}),"\n",(0,r.jsx)(n.h3,{id:"self-adjusting-heap",children:"Self-adjusting heap"}),"\n",(0,r.jsx)(n.p,{children:"We want our GC to run frequently enough to minimize latency but infrequently\r\nenough to maintain decent throughput. But how do we find the balance between\r\nthese when we have no idea how much memory the user's program needs and how\r\noften it allocates? We could pawn the problem onto the user and force them to\r\npick by exposing GC tuning parameters. Many VMs do this. But if we, the GC\r\nauthors, don't know how to tune it well, odds are good most users won't either.\r\nThey deserve a reasonable default behavior."}),"\n",(0,r.jsx)(n.p,{children:"I'll be honest with you, this is not my area of expertise. I've talked to a\r\nnumber of professional GC hackers -- this is something you can build an entire\r\ncareer on -- and read a lot of the literature, and all of the answers I got\r\nwere... vague. The strategy I ended up picking is common, pretty simple, and (I\r\nhope!) good enough for most uses."}),"\n",(0,r.jsxs)(n.p,{children:["The idea is that the collector frequency automatically adjusts based on the live\r\nsize of the heap. We track the total number of bytes of managed memory that the\r\nVM has allocated. When it goes above some threshold, we trigger a GC. After\r\nthat, we note how many bytes of memory remain -- how many were ",(0,r.jsx)(n.em,{children:"not"})," freed. Then\r\nwe adjust the threshold to some value larger than that."]}),"\n",(0,r.jsx)(n.p,{children:"The result is that as the amount of live memory increases, we collect less\r\nfrequently in order to avoid sacrificing throughput by re-traversing the growing\r\npile of live objects. As the amount of live memory goes down, we collect more\r\nfrequently so that we don't lose too much latency by waiting too long."}),"\n",(0,r.jsx)(n.p,{children:"The implementation requires two new bookkeeping fields in the VM."}),"\n",(0,r.jsx)(n.p,{children:"^code vm-fields (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"The first is a running total of the number of bytes of managed memory the VM has\r\nallocated. The second is the threshold that triggers the next collection. We\r\ninitialize them when the VM starts up."}),"\n",(0,r.jsx)(n.p,{children:"^code init-gc-fields (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["The starting threshold here is ",(0,r.jsx)(n.span,{name:"lab",children:"arbitrary"}),". It's similar\r\nto the initial capacity we picked for our various dynamic arrays. The goal is to\r\nnot trigger the first few GCs ",(0,r.jsx)(n.em,{children:"too"})," quickly but also to not wait too long. If we\r\nhad some real-world Lox programs, we could profile those to tune this. But since\r\nall we have are toy programs, I just picked a number."]}),"\n",(0,r.jsxs)(n.aside,{name:"lab",children:["\n",(0,r.jsxs)(n.p,{children:["A challenge with learning garbage collectors is that it's ",(0,r.jsx)(n.em,{children:"very"})," hard to\r\ndiscover the best practices in an isolated lab environment. You don't see how a\r\ncollector actually performs unless you run it on the kind of large, messy\r\nreal-world programs it is actually intended for. It's like tuning a rally car\r\n-- you need to take it out on the course."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Every time we allocate or free some memory, we adjust the counter by that delta."}),"\n",(0,r.jsx)(n.p,{children:"^code updated-bytes-allocated (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"When the total crosses the limit, we run the collector."}),"\n",(0,r.jsx)(n.p,{children:"^code collect-on-next (2 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Now, finally, our garbage collector actually does something when the user runs a\r\nprogram without our hidden diagnostic flag enabled. The sweep phase frees\r\nobjects by calling ",(0,r.jsx)(n.code,{children:"reallocate()"}),", which lowers the value of ",(0,r.jsx)(n.code,{children:"bytesAllocated"}),",\r\nso after the collection completes, we know how many live bytes remain. We adjust\r\nthe threshold of the next GC based on that."]}),"\n",(0,r.jsx)(n.p,{children:"^code update-next-gc (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"The threshold is a multiple of the heap size. This way, as the amount of memory\r\nthe program uses grows, the threshold moves farther out to limit the total time\r\nspent re-traversing the larger live set. Like other numbers in this chapter, the\r\nscaling factor is basically arbitrary."}),"\n",(0,r.jsx)(n.p,{children:"^code heap-grow-factor (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"You'd want to tune this in your implementation once you had some real programs\r\nto benchmark it on. Right now, we can at least log some of the statistics that\r\nwe have. We capture the heap size before the collection."}),"\n",(0,r.jsx)(n.p,{children:"^code log-before-size (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"And then print the results at the end."}),"\n",(0,r.jsx)(n.p,{children:"^code log-collected-amount (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"This way we can see how much the garbage collector accomplished while it ran."}),"\n",(0,r.jsx)(n.h2,{id:"garbage-collection-bugs",children:"Garbage Collection Bugs"}),"\n",(0,r.jsx)(n.p,{children:"In theory, we are all done now. We have a GC. It kicks in periodically, collects\r\nwhat it can, and leaves the rest. If this were a typical textbook, we would wipe\r\nthe dust from our hands and bask in the soft glow of the flawless marble edifice\r\nwe have created."}),"\n",(0,r.jsx)(n.p,{children:"But I aim to teach you not just the theory of programming languages but the\r\nsometimes painful reality. I am going to roll over a rotten log and show you the\r\nnasty bugs that live under it, and garbage collector bugs really are some of the\r\ngrossest invertebrates out there."}),"\n",(0,r.jsx)(n.p,{children:"The collector's job is to free dead objects and preserve live ones. Mistakes are\r\neasy to make in both directions. If the VM fails to free objects that aren't\r\nneeded, it slowly leaks memory. If it frees an object that is in use, the user's\r\nprogram can access invalid memory. These failures often don't immediately cause\r\na crash, which makes it hard for us to trace backward in time to find the bug."}),"\n",(0,r.jsx)(n.p,{children:"This is made harder by the fact that we don't know when the collector will run.\r\nAny call that eventually allocates some memory is a place in the VM where a\r\ncollection could happen. It's like musical chairs. At any point, the GC might\r\nstop the music. Every single heap-allocated object that we want to keep needs to\r\nfind a chair quickly -- get marked as a root or stored as a reference in some\r\nother object -- before the sweep phase comes to kick it out of the game."}),"\n",(0,r.jsxs)(n.p,{children:["How is it possible for the VM to use an object later -- one that the GC itself\r\ndoesn't see? How can the VM find it? The most common answer is through a pointer\r\nstored in some local variable on the C stack. The GC walks the ",(0,r.jsx)(n.em,{children:"VM's"})," value and\r\nCallFrame stacks, but the C stack is ",(0,r.jsx)(n.span,{name:"c",children:"hidden"})," to it."]}),"\n",(0,r.jsxs)(n.aside,{name:"c",children:["\n",(0,r.jsxs)(n.p,{children:["Our GC can't find addresses in the C stack, but many can. Conservative garbage\r\ncollectors look all through memory, including the native stack. The most\r\nwell-known of this variety is the ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Boehm_garbage_collector",children:(0,r.jsx)(n.strong,{children:"Boehm\u2013Demers\u2013Weiser garbage\r\ncollector"})}),', usually just called the "Boehm collector". (The shortest\r\npath to fame in CS is a last name that\'s alphabetically early so that it shows\r\nup first in sorted lists of names.)']}),"\n",(0,r.jsxs)(n.p,{children:["Many precise GCs walk the C stack too. Even those have to be careful about\r\npointers to live objects that exist only in ",(0,r.jsx)(n.em,{children:"CPU registers"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"In previous chapters, we wrote seemingly pointless code that pushed an object\r\nonto the VM's value stack, did a little work, and then popped it right back off.\r\nMost times, I said this was for the GC's benefit. Now you see why. The code\r\nbetween pushing and popping potentially allocates memory and thus can trigger a\r\nGC. We had to make sure the object was on the value stack so that the\r\ncollector's mark phase would find it and keep it alive."}),"\n",(0,r.jsx)(n.p,{children:"I wrote the entire clox implementation before splitting it into chapters and\r\nwriting the prose, so I had plenty of time to find all of these corners and\r\nflush out most of these bugs. The stress testing code we put in at the beginning\r\nof this chapter and a pretty good test suite were very helpful."}),"\n",(0,r.jsxs)(n.p,{children:["But I fixed only ",(0,r.jsx)(n.em,{children:"most"})," of them. I left a couple in because I want to give you a\r\nhint of what it's like to encounter these bugs in the wild. If you enable the\r\nstress test flag and run some toy Lox programs, you can probably stumble onto a\r\nfew. Give it a try and ",(0,r.jsx)(n.em,{children:"see if you can fix any yourself"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"adding-to-the-constant-table",children:"Adding to the constant table"}),"\n",(0,r.jsx)(n.p,{children:"You are very likely to hit the first bug. The constant table each chunk owns is\r\na dynamic array. When the compiler adds a new constant to the current function's\r\ntable, that array may need to grow. The constant itself may also be some\r\nheap-allocated object like a string or a nested function."}),"\n",(0,r.jsxs)(n.p,{children:["The new object being added to the constant table is passed to ",(0,r.jsx)(n.code,{children:"addConstant()"}),".\r\nAt that moment, the object can be found only in the parameter to that function\r\non the C stack. That function appends the object to the constant table. If the\r\ntable doesn't have enough capacity and needs to grow, it calls ",(0,r.jsx)(n.code,{children:"reallocate()"}),".\r\nThat in turn triggers a GC, which fails to mark the new constant object and\r\nthus sweeps it right before we have a chance to add it to the table. Crash."]}),"\n",(0,r.jsx)(n.p,{children:"The fix, as you've seen in other places, is to push the constant onto the stack\r\ntemporarily."}),"\n",(0,r.jsx)(n.p,{children:"^code add-constant-push (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"Once the constant table contains the object, we pop it off the stack."}),"\n",(0,r.jsx)(n.p,{children:"^code add-constant-pop (1 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:'When the GC is marking roots, it walks the chain of compilers and marks each of\r\ntheir functions, so the new constant is reachable now. We do need an include\r\nto call into the VM from the "chunk" module.'}),"\n",(0,r.jsx)(n.p,{children:"^code chunk-include-vm (1 before, 2 after)"}),"\n",(0,r.jsx)(n.h3,{id:"interning-strings",children:"Interning strings"}),"\n",(0,r.jsx)(n.p,{children:"Here's another similar one. All strings are interned in clox, so whenever we\r\ncreate a new string, we also add it to the intern table. You can see where this\r\nis going. Since the string is brand new, it isn't reachable anywhere. And\r\nresizing the string pool can trigger a collection. Again, we go ahead and stash\r\nthe string on the stack first."}),"\n",(0,r.jsx)(n.p,{children:"^code push-string (2 before, 1 after)"}),"\n",(0,r.jsx)(n.p,{children:"And then pop it back off once it's safely nestled in the table."}),"\n",(0,r.jsx)(n.p,{children:"^code pop-string (1 before, 2 after)"}),"\n",(0,r.jsxs)(n.p,{children:["This ensures the string is safe while the table is being resized. Once it\r\nsurvives that, ",(0,r.jsx)(n.code,{children:"allocateString()"})," will return it to some caller which can then\r\ntake responsibility for ensuring the string is still reachable before the next\r\nheap allocation occurs."]}),"\n",(0,r.jsx)(n.h3,{id:"concatenating-strings",children:"Concatenating strings"}),"\n",(0,r.jsxs)(n.p,{children:["One last example: Over in the interpreter, the ",(0,r.jsx)(n.code,{children:"OP_ADD"})," instruction can be used\r\nto concatenate two strings. As it does with numbers, it pops the two operands\r\nfrom the stack, computes the result, and pushes that new value back onto the\r\nstack. For numbers that's perfectly safe."]}),"\n",(0,r.jsx)(n.p,{children:"But concatenating two strings requires allocating a new character array on the\r\nheap, which can in turn trigger a GC. Since we've already popped the operand\r\nstrings by that point, they can potentially be missed by the mark phase and get\r\nswept away. Instead of popping them off the stack eagerly, we peek them."}),"\n",(0,r.jsx)(n.p,{children:"^code concatenate-peek (1 before, 2 after)"}),"\n",(0,r.jsx)(n.p,{children:"That way, they are still hanging out on the stack when we create the result\r\nstring. Once that's done, we can safely pop them off and replace them with the\r\nresult."}),"\n",(0,r.jsx)(n.p,{children:"^code concatenate-pop (1 before, 1 after)"}),"\n",(0,r.jsxs)(n.p,{children:["Those were all pretty easy, especially because I ",(0,r.jsx)(n.em,{children:"showed"})," you where the fix was.\r\nIn practice, ",(0,r.jsx)(n.em,{children:"finding"})," them is the hard part. All you see is an object that\r\n",(0,r.jsx)(n.em,{children:"should"})," be there but isn't. It's not like other bugs where you're looking for\r\nthe code that ",(0,r.jsx)(n.em,{children:"causes"})," some problem. You're looking for the ",(0,r.jsx)(n.em,{children:"absence"})," of code\r\nwhich fails to ",(0,r.jsx)(n.em,{children:"prevent"})," a problem, and that's a much harder search."]}),"\n",(0,r.jsx)(n.p,{children:"But, for now at least, you can rest easy. As far as I know, we've found all of\r\nthe collection bugs in clox, and now we have a working, robust, self-tuning,\r\nmark-sweep garbage collector."}),"\n",(0,r.jsxs)(n.div,{className:"challenges",children:["\n",(0,r.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["The Obj header struct at the top of each object now has three fields:\r\n",(0,r.jsx)(n.code,{children:"type"}),", ",(0,r.jsx)(n.code,{children:"isMarked"}),", and ",(0,r.jsx)(n.code,{children:"next"}),". How much memory do those take up (on your\r\nmachine)? Can you come up with something more compact? Is there a runtime\r\ncost to doing so?"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["When the sweep phase traverses a live object, it clears the ",(0,r.jsx)(n.code,{children:"isMarked"}),"\r\nfield to prepare it for the next collection cycle. Can you come up with a\r\nmore efficient approach?"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Mark-sweep is only one of a variety of garbage collection algorithms out\r\nthere. Explore those by replacing or augmenting the current collector with\r\nanother one. Good candidates to consider are reference counting, Cheney's\r\nalgorithm, or the Lisp 2 mark-compact algorithm."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.div,{className:"design-note",children:["\n",(0,r.jsx)(n.h2,{id:"design-note-generational-collectors",children:"Design Note: Generational Collectors"}),"\n",(0,r.jsx)(n.p,{children:"A collector loses throughput if it spends a long time re-visiting objects that\r\nare still alive. But it can increase latency if it avoids collecting and\r\naccumulates a large pile of garbage to wade through. If only there were some way\r\nto tell which objects were likely to be long-lived and which weren't. Then the\r\nGC could avoid revisiting the long-lived ones as often and clean up the\r\nephemeral ones more frequently."}),"\n",(0,r.jsx)(n.p,{children:"It turns out there kind of is. Many years ago, GC researchers gathered metrics\r\non the lifetime of objects in real-world running programs. They tracked every\r\nobject when it was allocated, and eventually when it was no longer needed, and\r\nthen graphed out how long objects tended to live."}),"\n",(0,r.jsxs)(n.p,{children:["They discovered something they called the ",(0,r.jsx)(n.strong,{children:"generational hypothesis"}),", or the\r\nmuch less tactful term ",(0,r.jsx)(n.strong,{children:"infant mortality"}),". Their observation was that most\r\nobjects are very short-lived but once they survive beyond a certain age, they\r\ntend to stick around quite a long time. The longer an object ",(0,r.jsx)(n.em,{children:"has"})," lived, the\r\nlonger it likely will ",(0,r.jsx)(n.em,{children:"continue"})," to live. This observation is powerful because\r\nit gave them a handle on how to partition objects into groups that benefit from\r\nfrequent collections and those that don't."]}),"\n",(0,r.jsxs)(n.p,{children:["They designed a technique called ",(0,r.jsx)(n.strong,{children:"generational garbage collection"}),'. It works\r\nlike this: Every time a new object is allocated, it goes into a special,\r\nrelatively small region of the heap called the "nursery". Since objects tend to\r\ndie young, the garbage collector is invoked ',(0,r.jsx)(n.span,{name:"nursery",children:"frequently"})," over the objects just in this region."]}),"\n",(0,r.jsxs)(n.aside,{name:"nursery",children:["\n",(0,r.jsx)(n.p,{children:"Nurseries are also usually managed using a copying collector which is faster at\r\nallocating and freeing objects than a mark-sweep collector."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:['Each time the GC runs over the nursery is called a "generation". Any objects\r\nthat are no longer needed get freed. Those that survive are now considered one\r\ngeneration older, and the GC tracks this for each object. If an object survives\r\na certain number of generations -- often just a single collection -- it gets\r\n',(0,r.jsx)(n.em,{children:"tenured"}),". At this point, it is copied out of the nursery into a much larger\r\nheap region for long-lived objects. The garbage collector runs over that region\r\ntoo, but much less frequently since odds are good that most of those objects\r\nwill still be alive."]}),"\n",(0,r.jsxs)(n.p,{children:["Generational collectors are a beautiful marriage of empirical data -- the\r\nobservation that object lifetimes are ",(0,r.jsx)(n.em,{children:"not"})," evenly distributed -- and clever\r\nalgorithm design that takes advantage of that fact. They're also conceptually\r\nquite simple. You can think of one as just two separately tuned GCs and a pretty\r\nsimple policy for moving objects from one to the other."]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var r=t(6540);const a={},o=r.createContext(a);function s(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);