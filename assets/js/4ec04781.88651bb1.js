"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[3633],{4266:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>h});var t=r(4848),s=r(8453);const a={},i=void 0,o={id:"Craftinginterpreters/not-translated-yet/scanning",title:"scanning",description:"Take big bites. Anything worth doing is worth overdoing.",source:"@site/docs/Craftinginterpreters/not-translated-yet/scanning.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/scanning",permalink:"/docs/Craftinginterpreters/not-translated-yet/scanning",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/scanning.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"scanning-on-demand",permalink:"/docs/Craftinginterpreters/not-translated-yet/scanning-on-demand"},next:{title:"statements-and-state",permalink:"/docs/Craftinginterpreters/not-translated-yet/statements-and-state"}},l={},h=[{value:"The Interpreter Framework",id:"the-interpreter-framework",level:2},{value:"Error handling",id:"error-handling",level:3},{value:"Lexemes and Tokens",id:"lexemes-and-tokens",level:2},{value:"Token type",id:"token-type",level:3},{value:"Literal value",id:"literal-value",level:3},{value:"Location information",id:"location-information",level:3},{value:"Regular Languages and Expressions",id:"regular-languages-and-expressions",level:2},{value:"The Scanner Class",id:"the-scanner-class",level:2},{value:"Recognizing Lexemes",id:"recognizing-lexemes",level:2},{value:"Lexical errors",id:"lexical-errors",level:3},{value:"Operators",id:"operators",level:3},{value:"Longer Lexemes",id:"longer-lexemes",level:2},{value:"String literals",id:"string-literals",level:3},{value:"Number literals",id:"number-literals",level:3},{value:"Reserved Words and Identifiers",id:"reserved-words-and-identifiers",level:2},{value:"Challenges",id:"challenges",level:2},{value:"Design Note: Implicit Semicolons",id:"design-note-implicit-semicolons",level:2}];function c(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"Take big bites. Anything worth doing is worth overdoing."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.cite,{children:["Robert A. Heinlein, ",(0,t.jsx)(n.em,{children:"Time Enough for Love"})]})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The first step in any compiler or interpreter is ",(0,t.jsx)(n.span,{name:"lexing",children:"scanning"}),". The scanner takes in raw source code as a series\r\nof characters and groups it into a series of chunks we call ",(0,t.jsx)(n.strong,{children:"tokens"}),'. These\r\nare the meaningful "words" and "punctuation" that make up the language\'s\r\ngrammar.']}),"\n",(0,t.jsxs)(n.aside,{name:"lexing",children:["\n",(0,t.jsx)(n.p,{children:'This task has been variously called "scanning" and "lexing" (short for "lexical\r\nanalysis") over the years. Way back when computers were as big as Winnebagos but\r\nhad less memory than your watch, some people used "scanner" only to refer to the\r\npiece of code that dealt with reading raw source code characters from disk and\r\nbuffering them in memory. Then "lexing" was the subsequent phase that did useful\r\nstuff with the characters.'}),"\n",(0,t.jsx)(n.p,{children:"These days, reading a source file into memory is trivial, so it's rarely a\r\ndistinct phase in the compiler. Because of that, the two terms are basically\r\ninterchangeable."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Scanning is a good starting point for us too because the code isn't very hard --\r\npretty much a ",(0,t.jsx)(n.code,{children:"switch"})," statement with delusions of grandeur. It will help us\r\nwarm up before we tackle some of the more interesting material later. By the end\r\nof this chapter, we'll have a full-featured, fast scanner that can take any\r\nstring of Lox source code and produce the tokens that we'll feed into the parser\r\nin the next chapter."]}),"\n",(0,t.jsx)(n.h2,{id:"the-interpreter-framework",children:"The Interpreter Framework"}),"\n",(0,t.jsx)(n.p,{children:"Since this is our first real chapter, before we get to actually scanning some\r\ncode we need to sketch out the basic shape of our interpreter, jlox. Everything\r\nstarts with a class in Java."}),"\n",(0,t.jsx)(n.p,{children:"^code lox-class"}),"\n",(0,t.jsxs)(n.aside,{name:"64",children:["\n",(0,t.jsxs)(n.p,{children:["For exit codes, I'm using the conventions defined in the UNIX\r\n",(0,t.jsx)(n.a,{href:"https://www.freebsd.org/cgi/man.cgi?query=sysexits&apropos=0&sektion=0&manpath=FreeBSD+4.3-RELEASE&format=html",children:'"sysexits.h"'})," header. It's the closest thing to a standard I could\r\nfind."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Stick that in a text file, and go get your IDE or Makefile or whatever set up.\r\nI'll be right here when you're ready. Good? OK!"}),"\n",(0,t.jsx)(n.p,{children:"Lox is a scripting language, which means it executes directly from source. Our\r\ninterpreter supports two ways of running code. If you start jlox from the\r\ncommand line and give it a path to a file, it reads the file and executes it."}),"\n",(0,t.jsx)(n.p,{children:"^code run-file"}),"\n",(0,t.jsx)(n.p,{children:"If you want a more intimate conversation with your interpreter, you can also run\r\nit interactively. Fire up jlox without any arguments, and it drops you into a\r\nprompt where you can enter and execute code one line at a time."}),"\n",(0,t.jsxs)(n.aside,{name:"repl",children:["\n",(0,t.jsx)(n.p,{children:'An interactive prompt is also called a "REPL" (pronounced like "rebel" but with\r\na "p"). The name comes from Lisp where implementing one is as simple as\r\nwrapping a loop around a few built-in functions:'}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lisp",children:"(print (eval (read)))\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Working outwards from the most nested call, you ",(0,t.jsx)(n.strong,{children:"R"}),"ead a line of input,\r\n",(0,t.jsx)(n.strong,{children:"E"}),"valuate it, ",(0,t.jsx)(n.strong,{children:"P"}),"rint the result, then ",(0,t.jsx)(n.strong,{children:"L"}),"oop and do it all over again."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"^code prompt"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"readLine()"}),' function, as the name so helpfully implies, reads a line of\r\ninput from the user on the command line and returns the result. To kill an\r\ninteractive command-line app, you usually type Control-D. Doing so signals an\r\n"end-of-file" condition to the program. When that happens ',(0,t.jsx)(n.code,{children:"readLine()"})," returns\r\n",(0,t.jsx)(n.code,{children:"null"}),", so we check for that to exit the loop."]}),"\n",(0,t.jsx)(n.p,{children:"Both the prompt and the file runner are thin wrappers around this core function:"}),"\n",(0,t.jsx)(n.p,{children:"^code run"}),"\n",(0,t.jsx)(n.p,{children:"It's not super useful yet since we haven't written the interpreter, but baby\r\nsteps, you know? Right now, it prints out the tokens our forthcoming scanner\r\nwill emit so that we can see if we're making progress."}),"\n",(0,t.jsx)(n.h3,{id:"error-handling",children:"Error handling"}),"\n",(0,t.jsxs)(n.p,{children:["While we're setting things up, another key piece of infrastructure is ",(0,t.jsx)(n.em,{children:"error\r\nhandling"}),". Textbooks sometimes gloss over this because it's more a practical\r\nmatter than a formal computer science-y problem. But if you care about making a\r\nlanguage that's actually ",(0,t.jsx)(n.em,{children:"usable"}),", then handling errors gracefully is vital."]}),"\n",(0,t.jsxs)(n.p,{children:["The tools our language provides for dealing with errors make up a large portion\r\nof its user interface. When the user's code is working, they aren't thinking\r\nabout our language at all -- their headspace is all about ",(0,t.jsx)(n.em,{children:"their program"}),". It's\r\nusually only when things go wrong that they notice our implementation."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.span,{name:"errors",children:"When"})," that happens, it's up to us to give the user all\r\nthe information they need to understand what went wrong and guide them gently\r\nback to where they are trying to go. Doing that well means thinking about error\r\nhandling all through the implementation of our interpreter, starting now."]}),"\n",(0,t.jsxs)(n.aside,{name:"errors",children:["\n",(0,t.jsxs)(n.p,{children:["Having said all that, for ",(0,t.jsx)(n.em,{children:"this"})," interpreter, what we'll build is pretty bare\r\nbones. I'd love to talk about interactive debuggers, static analyzers, and other\r\nfun stuff, but there's only so much ink in the pen."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"^code lox-error"}),"\n",(0,t.jsxs)(n.p,{children:["This ",(0,t.jsx)(n.code,{children:"error()"})," function and its ",(0,t.jsx)(n.code,{children:"report()"})," helper tells the user some syntax\r\nerror occurred on a given line. That is really the bare minimum to be able to\r\nclaim you even ",(0,t.jsx)(n.em,{children:"have"})," error reporting. Imagine if you accidentally left a\r\ndangling comma in some function call and the interpreter printed out:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'Error: Unexpected "," somewhere in your code. Good luck finding it!\n'})}),"\n",(0,t.jsxs)(n.p,{children:["That's not very helpful. We need to at least point them to the right line. Even\r\nbetter would be the beginning and end column so they know ",(0,t.jsx)(n.em,{children:"where"})," in the line.\r\nEven better than ",(0,t.jsx)(n.em,{children:"that"})," is to ",(0,t.jsx)(n.em,{children:"show"})," the user the offending line, like:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'Error: Unexpected "," in argument list.\r\n\r\n    15 | function(first, second,);\r\n                               ^-- Here.\n'})}),"\n",(0,t.jsx)(n.p,{children:"I'd love to implement something like that in this book but the honest truth is\r\nthat it's a lot of grungy string manipulation code. Very useful for users, but\r\nnot super fun to read in a book and not very technically interesting. So we'll\r\nstick with just a line number. In your own interpreters, please do as I say and\r\nnot as I do."}),"\n",(0,t.jsxs)(n.p,{children:["The primary reason we're sticking this error reporting function in the main Lox\r\nclass is because of that ",(0,t.jsx)(n.code,{children:"hadError"})," field. It's defined here:"]}),"\n",(0,t.jsx)(n.p,{children:"^code had-error (1 before)"}),"\n",(0,t.jsx)(n.p,{children:"We'll use this to ensure we don't try to execute code that has a known error.\r\nAlso, it lets us exit with a non-zero exit code like a good command line citizen\r\nshould."}),"\n",(0,t.jsx)(n.p,{children:"^code exit-code (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"We need to reset this flag in the interactive loop. If the user makes a mistake,\r\nit shouldn't kill their entire session."}),"\n",(0,t.jsx)(n.p,{children:"^code reset-had-error (1 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:["The other reason I pulled the error reporting out here instead of stuffing it\r\ninto the scanner and other phases where the error might occur is to remind you\r\nthat it's good engineering practice to separate the code that ",(0,t.jsx)(n.em,{children:"generates"})," the\r\nerrors from the code that ",(0,t.jsx)(n.em,{children:"reports"})," them."]}),"\n",(0,t.jsx)(n.p,{children:"Various phases of the front end will detect errors, but it's not really their\r\njob to know how to present that to a user. In a full-featured language\r\nimplementation, you will likely have multiple ways errors get displayed: on\r\nstderr, in an IDE's error window, logged to a file, etc. You don't want that\r\ncode smeared all over your scanner and parser."}),"\n",(0,t.jsxs)(n.p,{children:["Ideally, we would have an actual abstraction, some kind of ",(0,t.jsx)(n.span,{name:"reporter",children:'"ErrorReporter"'})," interface that gets passed to the scanner\r\nand parser so that we can swap out different reporting strategies. For our\r\nsimple interpreter here, I didn't do that, but I did at least move the code for\r\nerror reporting into a different class."]}),"\n",(0,t.jsxs)(n.aside,{name:"reporter",children:["\n",(0,t.jsx)(n.p,{children:"I had exactly that when I first implemented jlox. I ended up tearing it out\r\nbecause it felt over-engineered for the minimal interpreter in this book."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["With some rudimentary error handling in place, our application shell is ready.\r\nOnce we have a Scanner class with a ",(0,t.jsx)(n.code,{children:"scanTokens()"})," method, we can start running\r\nit. Before we get to that, let's get more precise about what tokens are."]}),"\n",(0,t.jsx)(n.h2,{id:"lexemes-and-tokens",children:"Lexemes and Tokens"}),"\n",(0,t.jsx)(n.p,{children:"Here's a line of Lox code:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:'var language = "lox";\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Here, ",(0,t.jsx)(n.code,{children:"var"}),' is the keyword for declaring a variable. That three-character\r\nsequence "v-a-r" means something. But if we yank three letters out of the\r\nmiddle of ',(0,t.jsx)(n.code,{children:"language"}),', like "g-u-a", those don\'t mean anything on their own.']}),"\n",(0,t.jsxs)(n.p,{children:["That's what lexical analysis is about. Our job is to scan through the list of\r\ncharacters and group them together into the smallest sequences that still\r\nrepresent something. Each of these blobs of characters is called a ",(0,t.jsx)(n.strong,{children:"lexeme"}),".\r\nIn that example line of code, the lexemes are:"]}),"\n",(0,t.jsx)(n.img,{src:"image/scanning/lexemes.png",alt:"'var', 'language', '=', 'lox', ';'"}),"\n",(0,t.jsx)(n.p,{children:"The lexemes are only the raw substrings of the source code. However, in the\r\nprocess of grouping character sequences into lexemes, we also stumble upon some\r\nother useful information. When we take the lexeme and bundle it together with\r\nthat other data, the result is a token. It includes useful stuff like:"}),"\n",(0,t.jsx)(n.h3,{id:"token-type",children:"Token type"}),"\n",(0,t.jsxs)(n.p,{children:["Keywords are part of the shape of the language's grammar, so the parser often\r\nhas code like, \"If the next token is ",(0,t.jsx)(n.code,{children:"while"}),' then do..." That means the parser\r\nwants to know not just that it has a lexeme for some identifier, but that it has\r\na ',(0,t.jsx)(n.em,{children:"reserved"})," word, and ",(0,t.jsx)(n.em,{children:"which"})," keyword it is."]}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.span,{name:"ugly",children:"parser"})," could categorize tokens from the raw lexeme\r\nby comparing the strings, but that's slow and kind of ugly. Instead, at the\r\npoint that we recognize a lexeme, we also remember which ",(0,t.jsx)(n.em,{children:"kind"})," of lexeme it\r\nrepresents. We have a different type for each keyword, operator, bit of\r\npunctuation, and literal type."]}),"\n",(0,t.jsxs)(n.aside,{name:"ugly",children:["\n",(0,t.jsx)(n.p,{children:"After all, string comparison ends up looking at individual characters, and isn't\r\nthat the scanner's job?"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"^code token-type"}),"\n",(0,t.jsx)(n.h3,{id:"literal-value",children:"Literal value"}),"\n",(0,t.jsx)(n.p,{children:"There are lexemes for literal values -- numbers and strings and the like. Since\r\nthe scanner has to walk each character in the literal to correctly identify it,\r\nit can also convert that textual representation of a value to the living runtime\r\nobject that will be used by the interpreter later."}),"\n",(0,t.jsx)(n.h3,{id:"location-information",children:"Location information"}),"\n",(0,t.jsxs)(n.p,{children:["Back when I was preaching the gospel about error handling, we saw that we need\r\nto tell users ",(0,t.jsx)(n.em,{children:"where"})," errors occurred. Tracking that starts here. In our simple\r\ninterpreter, we note only which line the token appears on, but more\r\nsophisticated implementations include the column and length too."]}),"\n",(0,t.jsxs)(n.aside,{name:"location",children:["\n",(0,t.jsx)(n.p,{children:"Some token implementations store the location as two numbers: the offset from\r\nthe beginning of the source file to the beginning of the lexeme, and the length\r\nof the lexeme. The scanner needs to know these anyway, so there's no overhead to\r\ncalculate them."}),"\n",(0,t.jsxs)(n.p,{children:["An offset can be converted to line and column positions later by looking back at\r\nthe source file and counting the preceding newlines. That sounds slow, and it\r\nis. However, you need to do it ",(0,t.jsx)(n.em,{children:"only when you need to actually display a line\r\nand column to the user"}),". Most tokens never appear in an error message. For\r\nthose, the less time you spend calculating position information ahead of time,\r\nthe better."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We take all of this data and wrap it in a class."}),"\n",(0,t.jsx)(n.p,{children:"^code token-class"}),"\n",(0,t.jsx)(n.p,{children:"Now we have an object with enough structure to be useful for all of the later\r\nphases of the interpreter."}),"\n",(0,t.jsx)(n.h2,{id:"regular-languages-and-expressions",children:"Regular Languages and Expressions"}),"\n",(0,t.jsx)(n.p,{children:"Now that we know what we're trying to produce, let's, well, produce it. The core\r\nof the scanner is a loop. Starting at the first character of the source code,\r\nthe scanner figures out what lexeme the character belongs to, and consumes it\r\nand any following characters that are part of that lexeme. When it reaches the\r\nend of that lexeme, it emits a token."}),"\n",(0,t.jsx)(n.p,{children:"Then it loops back and does it again, starting from the very next character in\r\nthe source code. It keeps doing that, eating characters and occasionally, uh,\r\nexcreting tokens, until it reaches the end of the input."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.span,{name:"alligator"})}),"\n",(0,t.jsx)(n.img,{src:"image/scanning/lexigator.png",alt:"An alligator eating characters and, well, you don't want to know."}),"\n",(0,t.jsxs)(n.aside,{name:"alligator",children:["\n",(0,t.jsx)(n.p,{children:"Lexical analygator."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:'The part of the loop where we look at a handful of characters to figure out\r\nwhich kind of lexeme it "matches" may sound familiar. If you know regular\r\nexpressions, you might consider defining a regex for each kind of lexeme and\r\nusing those to match characters. For example, Lox has the same rules as C for\r\nidentifiers (variable names and the like). This regex matches one:'}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"[a-zA-Z_][a-zA-Z_0-9]*\n"})}),"\n",(0,t.jsxs)(n.p,{children:["If you did think of regular expressions, your intuition is a deep one. The rules\r\nthat determine how a particular language groups characters into lexemes are\r\ncalled its ",(0,t.jsx)(n.span,{name:"theory",children:(0,t.jsx)(n.strong,{children:"lexical grammar"})}),". In Lox, as in most\r\nprogramming languages, the rules of that grammar are simple enough for the\r\nlanguage to be classified a ",(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Regular_language",children:"regular language"})}),'. That\'s the same "regular"\r\nas in regular expressions.']}),"\n",(0,t.jsxs)(n.aside,{name:"theory",children:["\n",(0,t.jsxs)(n.p,{children:["It pains me to gloss over the theory so much, especially when it's as\r\ninteresting as I think the ",(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Chomsky_hierarchy",children:"Chomsky hierarchy"})," and ",(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Finite-state_machine",children:"finite-state machines"}),"\r\nare. But the honest truth is other books cover this better than I could.\r\n",(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools",children:(0,t.jsx)(n.em,{children:"Compilers: Principles, Techniques, and Tools"})}),' (universally known as\r\n"the dragon book") is the canonical reference.']}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["You very precisely ",(0,t.jsx)(n.em,{children:"can"})," recognize all of the different lexemes for Lox using\r\nregexes if you want to, and there's a pile of interesting theory underlying why\r\nthat is and what it means. Tools like ",(0,t.jsx)(n.a,{href:"http://dinosaur.compilertools.net/lex/",children:"Lex"})," or\r\n",(0,t.jsx)(n.a,{href:"https://github.com/westes/flex",children:"Flex"})," are designed expressly to let you do this -- throw a handful of regexes\r\nat them, and they give you a complete scanner ",(0,t.jsx)(n.span,{name:"lex",children:"back"}),"."]}),"\n",(0,t.jsxs)(n.aside,{name:"lex",children:["\n",(0,t.jsxs)(n.p,{children:["Lex was created by Mike Lesk and Eric Schmidt. Yes, the same Eric Schmidt who\r\nwas executive chairman of Google. I'm not saying programming languages are a\r\nsurefire path to wealth and fame, but we ",(0,t.jsx)(n.em,{children:"can"})," count at least one\r\nmega billionaire among us."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Since our goal is to understand how a scanner does what it does, we won't be\r\ndelegating that task. We're about handcrafted goods."}),"\n",(0,t.jsx)(n.h2,{id:"the-scanner-class",children:"The Scanner Class"}),"\n",(0,t.jsx)(n.p,{children:"Without further ado, let's make ourselves a scanner."}),"\n",(0,t.jsx)(n.p,{children:"^code scanner-class"}),"\n",(0,t.jsxs)(n.aside,{name:"static-import",children:["\n",(0,t.jsxs)(n.p,{children:["I know static imports are considered bad style by some, but they save me from\r\nhaving to sprinkle ",(0,t.jsx)(n.code,{children:"TokenType."})," all over the scanner and parser. Forgive me, but\r\nevery character counts in a book."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We store the raw source code as a simple string, and we have a list ready to\r\nfill with tokens we're going to generate. The aforementioned loop that does that\r\nlooks like this:"}),"\n",(0,t.jsx)(n.p,{children:"^code scan-tokens"}),"\n",(0,t.jsx)(n.p,{children:'The scanner works its way through the source code, adding tokens until it runs\r\nout of characters. Then it appends one final "end of file" token. That isn\'t\r\nstrictly needed, but it makes our parser a little cleaner.'}),"\n",(0,t.jsx)(n.p,{children:"This loop depends on a couple of fields to keep track of where the scanner is in\r\nthe source code."}),"\n",(0,t.jsx)(n.p,{children:"^code scan-state (1 before, 2 after)"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"start"})," and ",(0,t.jsx)(n.code,{children:"current"})," fields are offsets that index into the string. The\r\n",(0,t.jsx)(n.code,{children:"start"})," field points to the first character in the lexeme being scanned, and\r\n",(0,t.jsx)(n.code,{children:"current"})," points at the character currently being considered. The ",(0,t.jsx)(n.code,{children:"line"})," field\r\ntracks what source line ",(0,t.jsx)(n.code,{children:"current"})," is on so we can produce tokens that know their\r\nlocation."]}),"\n",(0,t.jsx)(n.p,{children:"Then we have one little helper function that tells us if we've consumed all the\r\ncharacters."}),"\n",(0,t.jsx)(n.p,{children:"^code is-at-end"}),"\n",(0,t.jsx)(n.h2,{id:"recognizing-lexemes",children:"Recognizing Lexemes"}),"\n",(0,t.jsxs)(n.p,{children:["In each turn of the loop, we scan a single token. This is the real heart of the\r\nscanner. We'll start simple. Imagine if every lexeme were only a single character\r\nlong. All you would need to do is consume the next character and pick a token type for\r\nit. Several lexemes ",(0,t.jsx)(n.em,{children:"are"})," only a single character in Lox, so let's start with\r\nthose."]}),"\n",(0,t.jsx)(n.p,{children:"^code scan-token"}),"\n",(0,t.jsxs)(n.aside,{name:"slash",children:["\n",(0,t.jsxs)(n.p,{children:["Wondering why ",(0,t.jsx)(n.code,{children:"/"})," isn't in here? Don't worry, we'll get to it."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Again, we need a couple of helper methods."}),"\n",(0,t.jsx)(n.p,{children:"^code advance-and-add-token"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"advance()"})," method consumes the next character in the source file and\r\nreturns it. Where ",(0,t.jsx)(n.code,{children:"advance()"})," is for input, ",(0,t.jsx)(n.code,{children:"addToken()"})," is for output. It grabs\r\nthe text of the current lexeme and creates a new token for it. We'll use the\r\nother overload to handle tokens with literal values soon."]}),"\n",(0,t.jsx)(n.h3,{id:"lexical-errors",children:"Lexical errors"}),"\n",(0,t.jsxs)(n.p,{children:["Before we get too far in, let's take a moment to think about errors at the\r\nlexical level. What happens if a user throws a source file containing some\r\ncharacters Lox doesn't use, like ",(0,t.jsx)(n.code,{children:"@#^"}),", at our interpreter? Right now, those\r\ncharacters get silently discarded. They aren't used by the Lox language, but\r\nthat doesn't mean the interpreter can pretend they aren't there. Instead, we\r\nreport an error."]}),"\n",(0,t.jsx)(n.p,{children:"^code char-error (1 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:["Note that the erroneous character is still ",(0,t.jsx)(n.em,{children:"consumed"})," by the earlier call to\r\n",(0,t.jsx)(n.code,{children:"advance()"}),". That's important so that we don't get stuck in an infinite loop."]}),"\n",(0,t.jsxs)(n.p,{children:["Note also that we ",(0,t.jsx)(n.span,{name:"shotgun",children:(0,t.jsx)(n.em,{children:"keep scanning"})}),". There may be\r\nother errors later in the program. It gives our users a better experience if we\r\ndetect as many of those as possible in one go. Otherwise, they see one tiny\r\nerror and fix it, only to have the next error appear, and so on. Syntax error\r\nWhac-A-Mole is no fun."]}),"\n",(0,t.jsxs)(n.p,{children:["(Don't worry. Since ",(0,t.jsx)(n.code,{children:"hadError"})," gets set, we'll never try to ",(0,t.jsx)(n.em,{children:"execute"})," any of the\r\ncode, even though we keep going and scan the rest of it.)"]}),"\n",(0,t.jsxs)(n.aside,{name:"shotgun",children:["\n",(0,t.jsx)(n.p,{children:"The code reports each invalid character separately, so this shotguns the user\r\nwith a blast of errors if they accidentally paste a big blob of weird text.\r\nCoalescing a run of invalid characters into a single error would give a nicer\r\nuser experience."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"operators",children:"Operators"}),"\n",(0,t.jsxs)(n.p,{children:["We have single-character lexemes working, but that doesn't cover all of Lox's\r\noperators. What about ",(0,t.jsx)(n.code,{children:"!"}),"? It's a single character, right? Sometimes, yes, but\r\nif the very next character is an equals sign, then we should instead create a\r\n",(0,t.jsx)(n.code,{children:"!="})," lexeme. Note that the ",(0,t.jsx)(n.code,{children:"!"})," and ",(0,t.jsx)(n.code,{children:"="})," are ",(0,t.jsx)(n.em,{children:"not"})," two independent operators. You\r\ncan't write ",(0,t.jsx)(n.code,{children:"!   ="})," in Lox and have it behave like an inequality operator.\r\nThat's why we need to scan ",(0,t.jsx)(n.code,{children:"!="})," as a single lexeme. Likewise, ",(0,t.jsx)(n.code,{children:"<"}),", ",(0,t.jsx)(n.code,{children:">"}),", and ",(0,t.jsx)(n.code,{children:"="}),"\r\ncan all be followed by ",(0,t.jsx)(n.code,{children:"="})," to create the other equality and comparison\r\noperators."]}),"\n",(0,t.jsx)(n.p,{children:"For all of these, we need to look at the second character."}),"\n",(0,t.jsx)(n.p,{children:"^code two-char-tokens (1 before, 2 after)"}),"\n",(0,t.jsx)(n.p,{children:"Those cases use this new method:"}),"\n",(0,t.jsx)(n.p,{children:"^code match"}),"\n",(0,t.jsxs)(n.p,{children:["It's like a conditional ",(0,t.jsx)(n.code,{children:"advance()"}),". We only consume the current character if\r\nit's what we're looking for."]}),"\n",(0,t.jsxs)(n.p,{children:["Using ",(0,t.jsx)(n.code,{children:"match()"}),", we recognize these lexemes in two stages. When we reach, for\r\nexample, ",(0,t.jsx)(n.code,{children:"!"}),", we jump to its switch case. That means we know the lexeme ",(0,t.jsx)(n.em,{children:"starts"}),"\r\nwith ",(0,t.jsx)(n.code,{children:"!"}),". Then we look at the next character to determine if we're on a ",(0,t.jsx)(n.code,{children:"!="})," or\r\nmerely a ",(0,t.jsx)(n.code,{children:"!"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"longer-lexemes",children:"Longer Lexemes"}),"\n",(0,t.jsxs)(n.p,{children:["We're still missing one operator: ",(0,t.jsx)(n.code,{children:"/"})," for division. That character needs a\r\nlittle special handling because comments begin with a slash too."]}),"\n",(0,t.jsx)(n.p,{children:"^code slash (1 before, 2 after)"}),"\n",(0,t.jsxs)(n.p,{children:["This is similar to the other two-character operators, except that when we find a\r\nsecond ",(0,t.jsx)(n.code,{children:"/"}),", we don't end the token yet. Instead, we keep consuming characters\r\nuntil we reach the end of the line."]}),"\n",(0,t.jsx)(n.p,{children:"This is our general strategy for handling longer lexemes. After we detect the\r\nbeginning of one, we shunt over to some lexeme-specific code that keeps eating\r\ncharacters until it sees the end."}),"\n",(0,t.jsx)(n.p,{children:"We've got another helper:"}),"\n",(0,t.jsx)(n.p,{children:"^code peek"}),"\n",(0,t.jsxs)(n.p,{children:["It's sort of like ",(0,t.jsx)(n.code,{children:"advance()"}),", but doesn't consume the character. This is called\r\n",(0,t.jsx)(n.span,{name:"match",children:(0,t.jsx)(n.strong,{children:"lookahead"})}),". Since it only looks at the current\r\nunconsumed character, we have ",(0,t.jsx)(n.em,{children:"one character of lookahead"}),". The smaller this\r\nnumber is, generally, the faster the scanner runs. The rules of the lexical\r\ngrammar dictate how much lookahead we need. Fortunately, most languages in wide\r\nuse peek only one or two characters ahead."]}),"\n",(0,t.jsxs)(n.aside,{name:"match",children:["\n",(0,t.jsxs)(n.p,{children:["Technically, ",(0,t.jsx)(n.code,{children:"match()"})," is doing lookahead too. ",(0,t.jsx)(n.code,{children:"advance()"})," and ",(0,t.jsx)(n.code,{children:"peek()"})," are the\r\nfundamental operators and ",(0,t.jsx)(n.code,{children:"match()"})," combines them."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Comments are lexemes, but they aren't meaningful, and the parser doesn't want\r\nto deal with them. So when we reach the end of the comment, we ",(0,t.jsx)(n.em,{children:"don't"})," call\r\n",(0,t.jsx)(n.code,{children:"addToken()"}),". When we loop back around to start the next lexeme, ",(0,t.jsx)(n.code,{children:"start"})," gets\r\nreset and the comment's lexeme disappears in a puff of smoke."]}),"\n",(0,t.jsx)(n.p,{children:"While we're at it, now's a good time to skip over those other meaningless\r\ncharacters: newlines and whitespace."}),"\n",(0,t.jsx)(n.p,{children:"^code whitespace (1 before, 3 after)"}),"\n",(0,t.jsxs)(n.p,{children:["When encountering whitespace, we simply go back to the beginning of the scan\r\nloop. That starts a new lexeme ",(0,t.jsx)(n.em,{children:"after"})," the whitespace character. For newlines,\r\nwe do the same thing, but we also increment the line counter. (This is why we\r\nused ",(0,t.jsx)(n.code,{children:"peek()"})," to find the newline ending a comment instead of ",(0,t.jsx)(n.code,{children:"match()"}),". We want\r\nthat newline to get us here so we can update ",(0,t.jsx)(n.code,{children:"line"}),".)"]}),"\n",(0,t.jsx)(n.p,{children:"Our scanner is getting smarter. It can handle fairly free-form code like:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"// this is a comment\r\n(( )){} // grouping stuff\r\n!*+-/=<> <= == // operators\n"})}),"\n",(0,t.jsx)(n.h3,{id:"string-literals",children:"String literals"}),"\n",(0,t.jsxs)(n.p,{children:["Now that we're comfortable with longer lexemes, we're ready to tackle literals.\r\nWe'll do strings first, since they always begin with a specific character, ",(0,t.jsx)(n.code,{children:'"'}),"."]}),"\n",(0,t.jsx)(n.p,{children:"^code string-start (1 before, 2 after)"}),"\n",(0,t.jsx)(n.p,{children:"That calls:"}),"\n",(0,t.jsx)(n.p,{children:"^code string"}),"\n",(0,t.jsxs)(n.p,{children:["Like with comments, we consume characters until we hit the ",(0,t.jsx)(n.code,{children:'"'})," that ends the\r\nstring. We also gracefully handle running out of input before the string is\r\nclosed and report an error for that."]}),"\n",(0,t.jsxs)(n.p,{children:["For no particular reason, Lox supports multi-line strings. There are pros and\r\ncons to that, but prohibiting them was a little more complex than allowing them,\r\nso I left them in. That does mean we also need to update ",(0,t.jsx)(n.code,{children:"line"})," when we hit a\r\nnewline inside a string."]}),"\n",(0,t.jsxs)(n.p,{children:["Finally, the last interesting bit is that when we create the token, we also\r\nproduce the actual string ",(0,t.jsx)(n.em,{children:"value"})," that will be used later by the interpreter.\r\nHere, that conversion only requires a ",(0,t.jsx)(n.code,{children:"substring()"})," to strip off the surrounding\r\nquotes. If Lox supported escape sequences like ",(0,t.jsx)(n.code,{children:"\\n"}),", we'd unescape those here."]}),"\n",(0,t.jsx)(n.h3,{id:"number-literals",children:"Number literals"}),"\n",(0,t.jsxs)(n.p,{children:["All numbers in Lox are floating point at runtime, but both integer and decimal\r\nliterals are supported. A number literal is a series of ",(0,t.jsx)(n.span,{name:"minus",children:"digits"})," optionally followed by a ",(0,t.jsx)(n.code,{children:"."})," and one or more trailing\r\ndigits."]}),"\n",(0,t.jsxs)(n.aside,{name:"minus",children:["\n",(0,t.jsxs)(n.p,{children:["Since we look only for a digit to start a number, that means ",(0,t.jsx)(n.code,{children:"-123"})," is not a\r\nnumber ",(0,t.jsx)(n.em,{children:"literal"}),". Instead, ",(0,t.jsx)(n.code,{children:"-123"}),", is an ",(0,t.jsx)(n.em,{children:"expression"})," that applies ",(0,t.jsx)(n.code,{children:"-"})," to the\r\nnumber literal ",(0,t.jsx)(n.code,{children:"123"}),". In practice, the result is the same, though it has one\r\ninteresting edge case if we were to add method calls on numbers. Consider:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"print -123.abs();\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This prints ",(0,t.jsx)(n.code,{children:"-123"})," because negation has lower precedence than method calls. We\r\ncould fix that by making ",(0,t.jsx)(n.code,{children:"-"})," part of the number literal. But then consider:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"var n = 123;\r\nprint -n.abs();\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This still produces ",(0,t.jsx)(n.code,{children:"-123"}),", so now the language seems inconsistent. No matter\r\nwhat you do, some case ends up weird."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"1234\r\n12.34\n"})}),"\n",(0,t.jsx)(n.p,{children:"We don't allow a leading or trailing decimal point, so these are both invalid:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:".1234\r\n1234.\n"})}),"\n",(0,t.jsxs)(n.p,{children:["We could easily support the former, but I left it out to keep things simple. The\r\nlatter gets weird if we ever want to allow methods on numbers like ",(0,t.jsx)(n.code,{children:"123.sqrt()"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"To recognize the beginning of a number lexeme, we look for any digit. It's kind\r\nof tedious to add cases for every decimal digit, so we'll stuff it in the\r\ndefault case instead."}),"\n",(0,t.jsx)(n.p,{children:"^code digit-start (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"This relies on this little utility:"}),"\n",(0,t.jsx)(n.p,{children:"^code is-digit"}),"\n",(0,t.jsxs)(n.aside,{name:"is-digit",children:["\n",(0,t.jsxs)(n.p,{children:["The Java standard library provides ",(0,t.jsx)(n.a,{href:"http://docs.oracle.com/javase/7/docs/api/java/lang/Character.html#isDigit(char)",children:(0,t.jsx)(n.code,{children:"Character.isDigit()"})}),", which seems\r\nlike a good fit. Alas, that method allows things like Devanagari digits,\r\nfull-width numbers, and other funny stuff we don't want."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Once we know we are in a number, we branch to a separate method to consume the\r\nrest of the literal, like we do with strings."}),"\n",(0,t.jsx)(n.p,{children:"^code number"}),"\n",(0,t.jsxs)(n.p,{children:["We consume as many digits as we find for the integer part of the literal. Then\r\nwe look for a fractional part, which is a decimal point (",(0,t.jsx)(n.code,{children:"."}),") followed by at\r\nleast one digit. If we do have a fractional part, again, we consume as many\r\ndigits as we can find."]}),"\n",(0,t.jsxs)(n.p,{children:["Looking past the decimal point requires a second character of lookahead since we\r\ndon't want to consume the ",(0,t.jsx)(n.code,{children:"."})," until we're sure there is a digit ",(0,t.jsx)(n.em,{children:"after"})," it. So\r\nwe add:"]}),"\n",(0,t.jsx)(n.p,{children:"^code peek-next"}),"\n",(0,t.jsxs)(n.aside,{name:"peek-next",children:["\n",(0,t.jsxs)(n.p,{children:["I could have made ",(0,t.jsx)(n.code,{children:"peek()"})," take a parameter for the number of characters ahead\r\nto look instead of defining two functions, but that would allow ",(0,t.jsx)(n.em,{children:"arbitrarily"}),"\r\nfar lookahead. Providing these two functions makes it clearer to a reader of the\r\ncode that our scanner looks ahead at most two characters."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Finally, we convert the lexeme to its numeric value. Our interpreter uses Java's\r\n",(0,t.jsx)(n.code,{children:"Double"})," type to represent numbers, so we produce a value of that type. We're\r\nusing Java's own parsing method to convert the lexeme to a real Java double. We\r\ncould implement that ourselves, but, honestly, unless you're trying to cram for\r\nan upcoming programming interview, it's not worth your time."]}),"\n",(0,t.jsxs)(n.p,{children:["The remaining literals are Booleans and ",(0,t.jsx)(n.code,{children:"nil"}),", but we handle those as keywords,\r\nwhich gets us to..."]}),"\n",(0,t.jsx)(n.h2,{id:"reserved-words-and-identifiers",children:"Reserved Words and Identifiers"}),"\n",(0,t.jsxs)(n.p,{children:["Our scanner is almost done. The only remaining pieces of the lexical grammar to\r\nimplement are identifiers and their close cousins, the reserved words. You might\r\nthink we could match keywords like ",(0,t.jsx)(n.code,{children:"or"})," in the same way we handle\r\nmultiple-character operators like ",(0,t.jsx)(n.code,{children:"<="}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-java",children:"case 'o':\r\n  if (match('r')) {\r\n    addToken(OR);\r\n  }\r\n  break;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Consider what would happen if a user named a variable ",(0,t.jsx)(n.code,{children:"orchid"}),". The scanner\r\nwould see the first two letters, ",(0,t.jsx)(n.code,{children:"or"}),", and immediately emit an ",(0,t.jsx)(n.code,{children:"or"})," keyword\r\ntoken. This gets us to an important principle called ",(0,t.jsx)(n.span,{name:"maximal",children:(0,t.jsx)(n.strong,{children:"maximal munch"})}),". When two lexical grammar rules can both\r\nmatch a chunk of code that the scanner is looking at, ",(0,t.jsx)(n.em,{children:"whichever one matches the\r\nmost characters wins"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["That rule states that if we can match ",(0,t.jsx)(n.code,{children:"orchid"})," as an identifier and ",(0,t.jsx)(n.code,{children:"or"})," as a\r\nkeyword, then the former wins. This is also why we tacitly assumed, previously,\r\nthat ",(0,t.jsx)(n.code,{children:"<="})," should be scanned as a single ",(0,t.jsx)(n.code,{children:"<="})," token and not ",(0,t.jsx)(n.code,{children:"<"})," followed by ",(0,t.jsx)(n.code,{children:"="}),"."]}),"\n",(0,t.jsxs)(n.aside,{name:"maximal",children:["\n",(0,t.jsx)(n.p,{children:"Consider this nasty bit of C code:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"---a;\n"})}),"\n",(0,t.jsx)(n.p,{children:"Is it valid? That depends on how the scanner splits the lexemes. What if the scanner\r\nsees it like this:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"- --a;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Then it could be parsed. But that would require the scanner to know about the\r\ngrammatical structure of the surrounding code, which entangles things more than\r\nwe want. Instead, the maximal munch rule says that it is ",(0,t.jsx)(n.em,{children:"always"})," scanned like:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"-- -a;\n"})}),"\n",(0,t.jsx)(n.p,{children:"It scans it that way even though doing so leads to a syntax error later in the\r\nparser."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Maximal munch means we can't easily detect a reserved word until we've reached\r\nthe end of what might instead be an identifier. After all, a reserved word ",(0,t.jsx)(n.em,{children:"is"}),"\r\nan identifier, it's just one that has been claimed by the language for its own\r\nuse. That's where the term ",(0,t.jsx)(n.strong,{children:"reserved word"})," comes from."]}),"\n",(0,t.jsx)(n.p,{children:"So we begin by assuming any lexeme starting with a letter or underscore is an\r\nidentifier."}),"\n",(0,t.jsx)(n.p,{children:"^code identifier-start (3 before, 3 after)"}),"\n",(0,t.jsx)(n.p,{children:"The rest of the code lives over here:"}),"\n",(0,t.jsx)(n.p,{children:"^code identifier"}),"\n",(0,t.jsx)(n.p,{children:"We define that in terms of these helpers:"}),"\n",(0,t.jsx)(n.p,{children:"^code is-alpha"}),"\n",(0,t.jsx)(n.p,{children:"That gets identifiers working. To handle keywords, we see if the identifier's\r\nlexeme is one of the reserved words. If so, we use a token type specific to that\r\nkeyword. We define the set of reserved words in a map."}),"\n",(0,t.jsx)(n.p,{children:"^code keyword-map"}),"\n",(0,t.jsx)(n.p,{children:"Then, after we scan an identifier, we check to see if it matches anything in the\r\nmap."}),"\n",(0,t.jsx)(n.p,{children:"^code keyword-type (2 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"If so, we use that keyword's token type. Otherwise, it's a regular user-defined\r\nidentifier."}),"\n",(0,t.jsx)(n.p,{children:"And with that, we now have a complete scanner for the entire Lox lexical\r\ngrammar. Fire up the REPL and type in some valid and invalid code. Does it\r\nproduce the tokens you expect? Try to come up with some interesting edge cases\r\nand see if it handles them as it should."}),"\n",(0,t.jsxs)(n.div,{className:"challenges",children:["\n",(0,t.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The lexical grammars of Python and Haskell are not ",(0,t.jsx)(n.em,{children:"regular"}),". What does that\r\nmean, and why aren't they?"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Aside from separating tokens -- distinguishing ",(0,t.jsx)(n.code,{children:"print foo"})," from ",(0,t.jsx)(n.code,{children:"printfoo"}),"\r\n-- spaces aren't used for much in most languages. However, in a couple of\r\ndark corners, a space ",(0,t.jsx)(n.em,{children:"does"})," affect how code is parsed in CoffeeScript,\r\nRuby, and the C preprocessor. Where and what effect does it have in each of\r\nthose languages?"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Our scanner here, like most, discards comments and whitespace since those\r\naren't needed by the parser. Why might you want to write a scanner that does\r\n",(0,t.jsx)(n.em,{children:"not"})," discard those? What would it be useful for?"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Add support to Lox's scanner for C-style ",(0,t.jsx)(n.code,{children:"/* ... */"})," block comments. Make\r\nsure to handle newlines in them. Consider allowing them to nest. Is adding\r\nsupport for nesting more work than you expected? Why?"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.div,{className:"design-note",children:["\n",(0,t.jsx)(n.h2,{id:"design-note-implicit-semicolons",children:"Design Note: Implicit Semicolons"}),"\n",(0,t.jsxs)(n.p,{children:["Programmers today are spoiled for choice in languages and have gotten picky\r\nabout syntax. They want their language to look clean and modern. One bit of\r\nsyntactic lichen that almost every new language scrapes off (and some ancient\r\nones like BASIC never had) is ",(0,t.jsx)(n.code,{children:";"})," as an explicit statement terminator."]}),"\n",(0,t.jsxs)(n.p,{children:['Instead, they treat a newline as a statement terminator where it makes sense to\r\ndo so. The "where it makes sense" part is the challenging bit. While ',(0,t.jsx)(n.em,{children:"most"}),"\r\nstatements are on their own line, sometimes you need to spread a single\r\nstatement across a couple of lines. Those intermingled newlines should not be\r\ntreated as terminators."]}),"\n",(0,t.jsx)(n.p,{children:"Most of the obvious cases where the newline should be ignored are easy to\r\ndetect, but there are a handful of nasty ones:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"A return value on the next line:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:'if (condition) return\r\n"value"\n'})}),"\n",(0,t.jsxs)(n.p,{children:['Is "value" the value being returned, or do we have a ',(0,t.jsx)(n.code,{children:"return"})," statement with\r\nno value followed by an expression statement containing a string literal?"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"A parenthesized expression on the next line:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"func\r\n(parenthesized)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Is this a call to ",(0,t.jsx)(n.code,{children:"func(parenthesized)"}),", or two expression statements, one\r\nfor ",(0,t.jsx)(n.code,{children:"func"})," and one for a parenthesized expression?"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["A ",(0,t.jsx)(n.code,{children:"-"})," on the next line:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"first\r\n-second\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Is this ",(0,t.jsx)(n.code,{children:"first - second"})," -- an infix subtraction -- or two expression\r\nstatements, one for ",(0,t.jsx)(n.code,{children:"first"})," and one to negate ",(0,t.jsx)(n.code,{children:"second"}),"?"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"In all of these, either treating the newline as a separator or not would both\r\nproduce valid code, but possibly not the code the user wants. Across languages,\r\nthere is an unsettling variety of rules used to decide which newlines are\r\nseparators. Here are a couple:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://www.lua.org/pil/1.1.html",children:"Lua"})," completely ignores newlines, but carefully controls its grammar such\r\nthat no separator between statements is needed at all in most cases. This is\r\nperfectly legit:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lua",children:"a = 1 b = 2\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Lua avoids the ",(0,t.jsx)(n.code,{children:"return"})," problem by requiring a ",(0,t.jsx)(n.code,{children:"return"})," statement to be the\r\nvery last statement in a block. If there is a value after ",(0,t.jsx)(n.code,{children:"return"})," before\r\nthe keyword ",(0,t.jsx)(n.code,{children:"end"}),", it ",(0,t.jsx)(n.em,{children:"must"})," be for the ",(0,t.jsx)(n.code,{children:"return"}),". For the other two cases,\r\nthey allow an explicit ",(0,t.jsx)(n.code,{children:";"})," and expect users to use that. In practice, that\r\nalmost never happens because there's no point in a parenthesized or unary\r\nnegation expression statement."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://golang.org/ref/spec#Semicolons",children:"Go"})," handles newlines in the scanner. If a newline appears following one\r\nof a handful of token types that are known to potentially end a statement,\r\nthe newline is treated like a semicolon. Otherwise it is ignored. The Go\r\nteam provides a canonical code formatter, ",(0,t.jsx)(n.a,{href:"https://golang.org/cmd/gofmt/",children:"gofmt"}),", and the ecosystem is\r\nfervent about its use, which ensures that idiomatic styled code works well\r\nwith this simple rule."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://docs.python.org/3.5/reference/lexical_analysis.html#implicit-line-joining",children:"Python"})," treats all newlines as significant unless an explicit backslash\r\nis used at the end of a line to continue it to the next line. However,\r\nnewlines anywhere inside a pair of brackets (",(0,t.jsx)(n.code,{children:"()"}),", ",(0,t.jsx)(n.code,{children:"[]"}),", or ",(0,t.jsx)(n.code,{children:"{}"}),") are\r\nignored. Idiomatic style strongly prefers the latter."]}),"\n",(0,t.jsx)(n.p,{children:'This rule works well for Python because it is a highly statement-oriented\r\nlanguage. In particular, Python\'s grammar ensures a statement never appears\r\ninside an expression. C does the same, but many other languages which have a\r\n"lambda" or function literal syntax do not.'}),"\n",(0,t.jsx)(n.p,{children:"An example in JavaScript:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"console.log(function() {\r\n  statement();\r\n});\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Here, the ",(0,t.jsx)(n.code,{children:"console.log()"})," ",(0,t.jsx)(n.em,{children:"expression"})," contains a function literal which\r\nin turn contains the ",(0,t.jsx)(n.em,{children:"statement"})," ",(0,t.jsx)(n.code,{children:"statement();"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["Python would need a different set of rules for implicitly joining lines if\r\nyou could get back ",(0,t.jsx)(n.em,{children:"into"})," a ",(0,t.jsx)(n.span,{name:"lambda",children:"statement"})," where\r\nnewlines should become meaningful while still nested inside brackets."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.aside,{name:"lambda",children:["\n",(0,t.jsxs)(n.p,{children:["And now you know why Python's ",(0,t.jsx)(n.code,{children:"lambda"})," allows only a single expression body."]}),"\n"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["JavaScript's \"",(0,t.jsx)(n.a,{href:"https://www.ecma-international.org/ecma-262/5.1/#sec-7.9",children:"automatic semicolon insertion"}),'" rule is the real odd\r\none. Where other languages assume most newlines ',(0,t.jsx)(n.em,{children:"are"})," meaningful and only a\r\nfew should be ignored in multi-line statements, JS assumes the opposite. It\r\ntreats all of your newlines as meaningless whitespace ",(0,t.jsx)(n.em,{children:"unless"})," it encounters\r\na parse error. If it does, it goes back and tries turning the previous\r\nnewline into a semicolon to get something grammatically valid."]}),"\n",(0,t.jsxs)(n.p,{children:["This design note would turn into a design diatribe if I went into complete\r\ndetail about how that even ",(0,t.jsx)(n.em,{children:"works"}),", much less all the various ways that\r\nJavaScript's \"solution\" is a bad idea. It's a mess. JavaScript is the only\r\nlanguage I know where many style guides demand explicit semicolons after\r\nevery statement even though the language theoretically lets you elide them."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["If you're designing a new language, you almost surely ",(0,t.jsx)(n.em,{children:"should"})," avoid an explicit\r\nstatement terminator. Programmers are creatures of fashion like other humans, and\r\nsemicolons are as pass\xe9 as ALL CAPS KEYWORDS. Just make sure you pick a set of\r\nrules that make sense for your language's particular grammar and idioms. And\r\ndon't do what JavaScript did."]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>o});var t=r(6540);const s={},a=t.createContext(s);function i(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);