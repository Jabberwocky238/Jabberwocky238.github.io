"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[1994],{4523:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>h,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var s=r(4848),t=r(8453);const a={},i=void 0,o={id:"Craftinginterpreters/not-translated-yet/parsing-expressions",title:"parsing-expressions",description:"Grammar, which knows how to control even kings.",source:"@site/docs/Craftinginterpreters/not-translated-yet/parsing-expressions.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/parsing-expressions",permalink:"/docs/Craftinginterpreters/not-translated-yet/parsing-expressions",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/parsing-expressions.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"optimization",permalink:"/docs/Craftinginterpreters/not-translated-yet/optimization"},next:{title:"representing-code",permalink:"/docs/Craftinginterpreters/not-translated-yet/representing-code"}},h={},c=[{value:"Ambiguity and the Parsing Game",id:"ambiguity-and-the-parsing-game",level:2},{value:"Recursive Descent Parsing",id:"recursive-descent-parsing",level:2},{value:"The parser class",id:"the-parser-class",level:3},{value:"Syntax Errors",id:"syntax-errors",level:2},{value:"Panic mode error recovery",id:"panic-mode-error-recovery",level:3},{value:"Entering panic mode",id:"entering-panic-mode",level:3},{value:"Synchronizing a recursive descent parser",id:"synchronizing-a-recursive-descent-parser",level:3},{value:"Wiring up the Parser",id:"wiring-up-the-parser",level:2},{value:"Challenges",id:"challenges",level:2},{value:"Design Note: Logic Versus History",id:"design-note-logic-versus-history",level:2}];function l(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["Grammar, which knows how to control even kings.\r\n",(0,s.jsx)(n.cite,{children:"Moli\xe8re"})]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.span,{name:"parse",children:"This"})," chapter marks the first major milestone of the\r\nbook. Many of us have cobbled together a mishmash of regular expressions and\r\nsubstring operations to extract some sense out of a pile of text. The code was\r\nprobably riddled with bugs and a beast to maintain. Writing a ",(0,s.jsx)(n.em,{children:"real"})," parser --\r\none with decent error handling, a coherent internal structure, and the ability\r\nto robustly chew through a sophisticated syntax -- is considered a rare,\r\nimpressive skill. In this chapter, you will ",(0,s.jsx)(n.span,{name:"attain",children:"attain"}),"\r\nit."]}),"\n",(0,s.jsxs)(n.aside,{name:"parse",children:["\n",(0,s.jsx)(n.p,{children:'"Parse" comes to English from the Old French "pars" for "part of speech". It\r\nmeans to take a text and map each word to the grammar of the language. We use it\r\nhere in the same sense, except that our language is a little more modern than\r\nOld French.'}),"\n"]}),"\n",(0,s.jsxs)(n.aside,{name:"attain",children:["\n",(0,s.jsx)(n.p,{children:"Like many rites of passage, you'll probably find it looks a little smaller, a\r\nlittle less daunting when it's behind you than when it loomed ahead."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["It's easier than you think, partially because we front-loaded a lot of the hard\r\nwork in the ",(0,s.jsx)(n.a,{href:"representing-code.html",children:"last chapter"}),". You already know your way around a formal grammar.\r\nYou're familiar with syntax trees, and we have some Java classes to represent\r\nthem. The only remaining piece is parsing -- transmogrifying a sequence of\r\ntokens into one of those syntax trees."]}),"\n",(0,s.jsxs)(n.p,{children:["Some CS textbooks make a big deal out of parsers. In the '60s, computer\r\nscientists -- understandably tired of programming in assembly language --\r\nstarted designing more sophisticated, ",(0,s.jsx)(n.span,{name:"human",children:"human"}),"-friendly\r\nlanguages like Fortran and ALGOL. Alas, they weren't very ",(0,s.jsx)(n.em,{children:"machine"}),"-friendly\r\nfor the primitive computers of the time."]}),"\n",(0,s.jsxs)(n.aside,{name:"human",children:["\n",(0,s.jsxs)(n.p,{children:["Imagine how harrowing assembly programming on those old machines must have been\r\nthat they considered ",(0,s.jsx)(n.em,{children:"Fortran"})," to be an improvement."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These pioneers designed languages that they honestly weren't even sure how to\r\nwrite compilers for, and then did groundbreaking work inventing parsing and\r\ncompiling techniques that could handle these new, big languages on those old, tiny\r\nmachines."}),"\n",(0,s.jsxs)(n.p,{children:["Classic compiler books read like fawning hagiographies of these heroes and their\r\ntools. The cover of ",(0,s.jsx)(n.em,{children:"Compilers: Principles, Techniques, and Tools"}),' literally has\r\na dragon labeled "complexity of compiler design" being slain by a knight bearing\r\na sword and shield branded "LALR parser generator" and "syntax directed\r\ntranslation". They laid it on thick.']}),"\n",(0,s.jsx)(n.p,{children:"A little self-congratulation is well-deserved, but the truth is you don't need\r\nto know most of that stuff to bang out a high quality parser for a modern\r\nmachine. As always, I encourage you to broaden your education and take it in\r\nlater, but this book omits the trophy case."}),"\n",(0,s.jsx)(n.h2,{id:"ambiguity-and-the-parsing-game",children:"Ambiguity and the Parsing Game"}),"\n",(0,s.jsxs)(n.p,{children:['In the last chapter, I said you can "play" a context-free grammar like a game in\r\norder to ',(0,s.jsx)(n.em,{children:"generate"})," strings. Parsers play that game in reverse. Given a string\r\n-- a series of tokens -- we map those tokens to terminals in the grammar to\r\nfigure out which rules could have generated that string."]}),"\n",(0,s.jsxs)(n.p,{children:['The "could have" part is interesting. It\'s entirely possible to create a grammar\r\nthat is ',(0,s.jsx)(n.em,{children:"ambiguous"}),", where different choices of productions can lead to the same\r\nstring. When you're using the grammar to ",(0,s.jsx)(n.em,{children:"generate"})," strings, that doesn't matter\r\nmuch. Once you have the string, who cares how you got to it?"]}),"\n",(0,s.jsx)(n.p,{children:"When parsing, ambiguity means the parser may misunderstand the user's code. As\r\nwe parse, we aren't just determining if the string is valid Lox code, we're\r\nalso tracking which rules match which parts of it so that we know what part of\r\nthe language each token belongs to. Here's the Lox expression grammar we put\r\ntogether in the last chapter:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'expression     \u2192 literal\r\n               | unary\r\n               | binary\r\n               | grouping ;\r\n\r\nliteral        \u2192 NUMBER | STRING | "true" | "false" | "nil" ;\r\ngrouping       \u2192 "(" expression ")" ;\r\nunary          \u2192 ( "-" | "!" ) expression ;\r\nbinary         \u2192 expression operator expression ;\r\noperator       \u2192 "==" | "!=" | "<" | "<=" | ">" | ">="\r\n               | "+"  | "-"  | "*" | "/" ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"This is a valid string in that grammar:"}),"\n",(0,s.jsx)(n.img,{src:"image/parsing-expressions/tokens.png",alt:"6 / 3 - 1"}),"\n",(0,s.jsx)(n.p,{children:"But there are two ways we could have generated it. One way is:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Starting at ",(0,s.jsx)(n.code,{children:"expression"}),", pick ",(0,s.jsx)(n.code,{children:"binary"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["For the left-hand ",(0,s.jsx)(n.code,{children:"expression"}),", pick ",(0,s.jsx)(n.code,{children:"NUMBER"}),", and use ",(0,s.jsx)(n.code,{children:"6"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["For the operator, pick ",(0,s.jsx)(n.code,{children:'"/"'}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["For the right-hand ",(0,s.jsx)(n.code,{children:"expression"}),", pick ",(0,s.jsx)(n.code,{children:"binary"})," again."]}),"\n",(0,s.jsxs)(n.li,{children:["In that nested ",(0,s.jsx)(n.code,{children:"binary"})," expression, pick ",(0,s.jsx)(n.code,{children:"3 - 1"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Another is:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Starting at ",(0,s.jsx)(n.code,{children:"expression"}),", pick ",(0,s.jsx)(n.code,{children:"binary"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["For the left-hand ",(0,s.jsx)(n.code,{children:"expression"}),", pick ",(0,s.jsx)(n.code,{children:"binary"})," again."]}),"\n",(0,s.jsxs)(n.li,{children:["In that nested ",(0,s.jsx)(n.code,{children:"binary"})," expression, pick ",(0,s.jsx)(n.code,{children:"6 / 3"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Back at the outer ",(0,s.jsx)(n.code,{children:"binary"}),", for the operator, pick ",(0,s.jsx)(n.code,{children:'"-"'}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["For the right-hand ",(0,s.jsx)(n.code,{children:"expression"}),", pick ",(0,s.jsx)(n.code,{children:"NUMBER"}),", and use ",(0,s.jsx)(n.code,{children:"1"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Those produce the same ",(0,s.jsx)(n.em,{children:"strings"}),", but not the same ",(0,s.jsx)(n.em,{children:"syntax trees"}),":"]}),"\n",(0,s.jsx)(n.img,{src:"image/parsing-expressions/syntax-trees.png",alt:"Two valid syntax trees: (6 / 3) - 1 and 6 / (3 - 1)"}),"\n",(0,s.jsxs)(n.p,{children:["In other words, the grammar allows seeing the expression as ",(0,s.jsx)(n.code,{children:"(6 / 3) - 1"})," or ",(0,s.jsx)(n.code,{children:"6 / (3 - 1)"}),". The ",(0,s.jsx)(n.code,{children:"binary"})," rule lets operands nest any which way you want. That in\r\nturn affects the result of evaluating the parsed tree. The way mathematicians\r\nhave addressed this ambiguity since blackboards were first invented is by\r\ndefining rules for precedence and associativity."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.span,{name:"nonassociative",children:(0,s.jsx)(n.strong,{children:"Precedence"})})," determines which operator\r\nis evaluated first in an expression containing a mixture of different\r\noperators. Precedence rules tell us that we evaluate the ",(0,s.jsx)(n.code,{children:"/"})," before the ",(0,s.jsx)(n.code,{children:"-"}),'\r\nin the above example. Operators with higher precedence are evaluated\r\nbefore operators with lower precedence. Equivalently, higher precedence\r\noperators are said to "bind tighter".']}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Associativity"})," determines which operator is evaluated first in a series\r\nof the ",(0,s.jsx)(n.em,{children:"same"})," operator. When an operator is ",(0,s.jsx)(n.strong,{children:"left-associative"}),' (think\r\n"left-to-right"), operators on the left evaluate before those on the right.\r\nSince ',(0,s.jsx)(n.code,{children:"-"})," is left-associative, this expression:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"5 - 3 - 1\n"})}),"\n",(0,s.jsx)(n.p,{children:"is equivalent to:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"(5 - 3) - 1\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Assignment, on the other hand, is ",(0,s.jsx)(n.strong,{children:"right-associative"}),". This:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"a = b = c\n"})}),"\n",(0,s.jsx)(n.p,{children:"is equivalent to:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"a = (b = c)\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.aside,{name:"nonassociative",children:["\n",(0,s.jsxs)(n.p,{children:["While not common these days, some languages specify that certain pairs of\r\noperators have ",(0,s.jsx)(n.em,{children:"no"})," relative precedence. That makes it a syntax error to mix\r\nthose operators in an expression without using explicit grouping."]}),"\n",(0,s.jsxs)(n.p,{children:["Likewise, some operators are ",(0,s.jsx)(n.strong,{children:"non-associative"}),". That means it's an error to\r\nuse that operator more than once in a sequence. For example, Perl's range\r\noperator isn't associative, so ",(0,s.jsx)(n.code,{children:"a .. b"})," is OK, but ",(0,s.jsx)(n.code,{children:"a .. b .. c"})," is an error."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Without well-defined precedence and associativity, an expression that uses\r\nmultiple operators is ambiguous -- it can be parsed into different syntax trees,\r\nwhich could in turn evaluate to different results. We'll fix that in Lox by\r\napplying the same precedence rules as C, going from lowest to highest."}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:["\n  ",(0,s.jsx)(n.td,{children:"Name"}),"\n  ",(0,s.jsx)(n.td,{children:"Operators"}),"\n  ",(0,s.jsx)(n.td,{children:"Associates"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:["\n  ",(0,s.jsx)(n.td,{children:"Equality"}),"\n  ",(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"=="})," ",(0,s.jsx)(n.code,{children:"!="})]}),"\n  ",(0,s.jsx)(n.td,{children:"Left"})]}),(0,s.jsxs)(n.tr,{children:["\n  ",(0,s.jsx)(n.td,{children:"Comparison"}),"\n  ",(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:">"})," ",(0,s.jsx)(n.code,{children:">="}),"\n      ",(0,s.jsx)(n.code,{children:"<"})," ",(0,s.jsx)(n.code,{children:"<="})]}),"\n  ",(0,s.jsx)(n.td,{children:"Left"})]}),(0,s.jsxs)(n.tr,{children:["\n  ",(0,s.jsx)(n.td,{children:"Term"}),"\n  ",(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"-"})," ",(0,s.jsx)(n.code,{children:"+"})]}),"\n  ",(0,s.jsx)(n.td,{children:"Left"})]}),(0,s.jsxs)(n.tr,{children:["\n  ",(0,s.jsx)(n.td,{children:"Factor"}),"\n  ",(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"/"})," ",(0,s.jsx)(n.code,{children:"*"})]}),"\n  ",(0,s.jsx)(n.td,{children:"Left"})]}),(0,s.jsxs)(n.tr,{children:["\n  ",(0,s.jsx)(n.td,{children:"Unary"}),"\n  ",(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"!"})," ",(0,s.jsx)(n.code,{children:"-"})]}),"\n  ",(0,s.jsx)(n.td,{children:"Right"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:["Right now, the grammar stuffs all expression types into a single ",(0,s.jsx)(n.code,{children:"expression"}),"\r\nrule. That same rule is used as the non-terminal for operands, which lets the\r\ngrammar accept any kind of expression as a subexpression, regardless of whether\r\nthe precedence rules allow it."]}),"\n",(0,s.jsxs)(n.p,{children:["We fix that by ",(0,s.jsx)(n.span,{name:"massage",children:"stratifying"})," the grammar. We define a\r\nseparate rule for each precedence level."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:"expression     \u2192 ...\r\nequality       \u2192 ...\r\ncomparison     \u2192 ...\r\nterm           \u2192 ...\r\nfactor         \u2192 ...\r\nunary          \u2192 ...\r\nprimary        \u2192 ...\n"})}),"\n",(0,s.jsxs)(n.aside,{name:"massage",children:["\n",(0,s.jsx)(n.p,{children:"Instead of baking precedence right into the grammar rules, some parser\r\ngenerators let you keep the same ambiguous-but-simple grammar and then add in a\r\nlittle explicit operator precedence metadata on the side in order to\r\ndisambiguate."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Each rule here only matches expressions at its precedence level or higher. For\r\nexample, ",(0,s.jsx)(n.code,{children:"unary"})," matches a unary expression like ",(0,s.jsx)(n.code,{children:"!negated"})," or a primary\r\nexpression like ",(0,s.jsx)(n.code,{children:"1234"}),". And ",(0,s.jsx)(n.code,{children:"term"})," can match ",(0,s.jsx)(n.code,{children:"1 + 2"})," but also ",(0,s.jsx)(n.code,{children:"3 * 4 / 5"}),". The\r\nfinal ",(0,s.jsx)(n.code,{children:"primary"})," rule covers the highest-precedence forms -- literals and\r\nparenthesized expressions."]}),"\n",(0,s.jsxs)(n.p,{children:["We just need to fill in the productions for each of those rules. We'll do the\r\neasy ones first. The top ",(0,s.jsx)(n.code,{children:"expression"})," rule matches any expression at any\r\nprecedence level. Since ",(0,s.jsx)(n.span,{name:"equality",children:(0,s.jsx)(n.code,{children:"equality"})})," has the lowest\r\nprecedence, if we match that, then it covers everything."]}),"\n",(0,s.jsxs)(n.aside,{name:"equality",children:["\n",(0,s.jsxs)(n.p,{children:["We could eliminate ",(0,s.jsx)(n.code,{children:"expression"})," and simply use ",(0,s.jsx)(n.code,{children:"equality"})," in the other rules\r\nthat contain expressions, but using ",(0,s.jsx)(n.code,{children:"expression"})," makes those other rules read a\r\nlittle better."]}),"\n",(0,s.jsxs)(n.p,{children:["Also, in later chapters when we expand the grammar to include assignment and\r\nlogical operators, we'll only need to change the production for ",(0,s.jsx)(n.code,{children:"expression"}),"\r\ninstead of touching every rule that contains an expression."]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:"expression     \u2192 equality\n"})}),"\n",(0,s.jsx)(n.p,{children:"Over at the other end of the precedence table, a primary expression contains\r\nall the literals and grouping expressions."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'primary        \u2192 NUMBER | STRING | "true" | "false" | "nil"\r\n               | "(" expression ")" ;\n'})}),"\n",(0,s.jsxs)(n.p,{children:["A unary expression starts with a unary operator followed by the operand. Since\r\nunary operators can nest -- ",(0,s.jsx)(n.code,{children:"!!true"})," is a valid if weird expression -- the\r\noperand can itself be a unary operator. A recursive rule handles that nicely."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'unary          \u2192 ( "!" | "-" ) unary ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"But this rule has a problem. It never terminates."}),"\n",(0,s.jsxs)(n.p,{children:["Remember, each rule needs to match expressions at that precedence level ",(0,s.jsx)(n.em,{children:"or\r\nhigher"}),", so we also need to let this match a primary expression."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'unary          \u2192 ( "!" | "-" ) unary\r\n               | primary ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"That works."}),"\n",(0,s.jsx)(n.p,{children:"The remaining rules are all binary operators. We'll start with the rule for\r\nmultiplication and division. Here's a first try:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'factor         \u2192 factor ( "/" | "*" ) unary\r\n               | unary ;\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The rule recurses to match the left operand. That enables the rule to match a\r\nseries of multiplication and division expressions like ",(0,s.jsx)(n.code,{children:"1 * 2 / 3"}),". Putting the\r\nrecursive production on the left side and ",(0,s.jsx)(n.code,{children:"unary"})," on the right makes the rule\r\n",(0,s.jsx)(n.span,{name:"mult",children:"left-associative"})," and unambiguous."]}),"\n",(0,s.jsxs)(n.aside,{name:"mult",children:["\n",(0,s.jsx)(n.p,{children:"In principle, it doesn't matter whether you treat multiplication as left- or\r\nright-associative -- you get the same result either way. Alas, in the real world\r\nwith limited precision, roundoff and overflow mean that associativity can affect\r\nthe result of a sequence of multiplications. Consider:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"print 0.1 * (0.2 * 0.3);\r\nprint (0.1 * 0.2) * 0.3;\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In languages like Lox that use ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Double-precision_floating-point_format",children:"IEEE 754"})," double-precision floating-point\r\nnumbers, the first evaluates to ",(0,s.jsx)(n.code,{children:"0.006"}),", while the second yields\r\n",(0,s.jsx)(n.code,{children:"0.006000000000000001"}),". Sometimes that tiny difference matters.\r\n",(0,s.jsx)(n.a,{href:"https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html",children:"This"})," is a good place to learn more."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["All of this is correct, but the fact that the first symbol in the body of the\r\nrule is the same as the head of the rule means this production is\r\n",(0,s.jsx)(n.strong,{children:"left-recursive"}),". Some parsing techniques, including the one we're going to\r\nuse, have trouble with left recursion. (Recursion elsewhere, like we have in\r\n",(0,s.jsx)(n.code,{children:"unary"})," and the indirect recursion for grouping in ",(0,s.jsx)(n.code,{children:"primary"})," are not a problem.)"]}),"\n",(0,s.jsx)(n.p,{children:"There are many grammars you can define that match the same language. The choice\r\nfor how to model a particular language is partially a matter of taste and\r\npartially a pragmatic one. This rule is correct, but not optimal for how we\r\nintend to parse it. Instead of a left recursive rule, we'll use a different one."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'factor         \u2192 unary ( ( "/" | "*" ) unary )* ;\n'})}),"\n",(0,s.jsxs)(n.p,{children:["We define a factor expression as a flat ",(0,s.jsx)(n.em,{children:"sequence"})," of multiplications\r\nand divisions. This matches the same syntax as the previous rule, but better\r\nmirrors the code we'll write to parse Lox. We use the same structure for all of\r\nthe other binary operator precedence levels, giving us this complete expression\r\ngrammar:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'expression     \u2192 equality ;\r\nequality       \u2192 comparison ( ( "!=" | "==" ) comparison )* ;\r\ncomparison     \u2192 term ( ( ">" | ">=" | "<" | "<=" ) term )* ;\r\nterm           \u2192 factor ( ( "-" | "+" ) factor )* ;\r\nfactor         \u2192 unary ( ( "/" | "*" ) unary )* ;\r\nunary          \u2192 ( "!" | "-" ) unary\r\n               | primary ;\r\nprimary        \u2192 NUMBER | STRING | "true" | "false" | "nil"\r\n               | "(" expression ")" ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"This grammar is more complex than the one we had before, but in return we have\r\neliminated the previous one's ambiguity. It's just what we need to make a\r\nparser."}),"\n",(0,s.jsx)(n.h2,{id:"recursive-descent-parsing",children:"Recursive Descent Parsing"}),"\n",(0,s.jsxs)(n.p,{children:['There is a whole pack of parsing techniques whose names are mostly combinations\r\nof "L" and "R" -- ',(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/LL_parser",children:"LL(k)"}),", ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/LR_parser",children:"LR(1)"}),", ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/LALR_parser",children:"LALR"})," -- along with more exotic\r\nbeasts like ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Parser_combinator",children:"parser combinators"}),", ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Earley_parser",children:"Earley parsers"}),", ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Shunting-yard_algorithm",children:"the shunting yard\r\nalgorithm"}),", and ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Parsing_expression_grammar",children:"packrat parsing"}),". For our first interpreter, one\r\ntechnique is more than sufficient: ",(0,s.jsx)(n.strong,{children:"recursive descent"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Recursive descent is the simplest way to build a parser, and doesn't require\r\nusing complex parser generator tools like Yacc, Bison or ANTLR. All you need is\r\nstraightforward handwritten code. Don't be fooled by its simplicity, though.\r\nRecursive descent parsers are fast, robust, and can support sophisticated\r\nerror handling. In fact, GCC, V8 (the JavaScript VM in Chrome), Roslyn (the C#\r\ncompiler written in C#) and many other heavyweight production language\r\nimplementations use recursive descent. It rocks."}),"\n",(0,s.jsxs)(n.p,{children:["Recursive descent is considered a ",(0,s.jsx)(n.strong,{children:"top-down parser"})," because it starts from the\r\ntop or outermost grammar rule (here ",(0,s.jsx)(n.code,{children:"expression"}),") and works its way ",(0,s.jsx)(n.span,{name:"descent",children:"down"})," into the nested subexpressions before finally\r\nreaching the leaves of the syntax tree. This is in contrast with bottom-up\r\nparsers like LR that start with primary expressions and compose them into larger\r\nand larger chunks of syntax."]}),"\n",(0,s.jsxs)(n.aside,{name:"descent",children:["\n",(0,s.jsxs)(n.p,{children:["It's called \"recursive ",(0,s.jsx)(n.em,{children:"descent"}),'" because it walks ',(0,s.jsx)(n.em,{children:"down"}),' the grammar.\r\nConfusingly, we also use direction metaphorically when talking about "high" and\r\n"low" precedence, but the orientation is reversed. In a top-down parser, you\r\nreach the lowest-precedence expressions first because they may in turn contain\r\nsubexpressions of higher precedence.']}),"\n",(0,s.jsx)(n.img,{src:"image/parsing-expressions/direction.png",alt:"Top-down grammar rules in order of increasing precedence."}),"\n",(0,s.jsx)(n.p,{children:"CS people really need to get together and straighten out their metaphors. Don't\r\neven get me started on which direction a stack grows or why trees have their\r\nroots on top."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"A recursive descent parser is a literal translation of the grammar's rules\r\nstraight into imperative code. Each rule becomes a function. The body of the\r\nrule translates to code roughly like:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:["\n  ",(0,s.jsx)(n.td,{children:"Grammar notation"}),"\n  ",(0,s.jsx)(n.td,{children:"Code representation"})]})}),(0,s.jsxs)(n.tbody,{children:["\n  ",(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Terminal"}),(0,s.jsx)(n.td,{children:"Code to match and consume a token"})]}),"\n  ",(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Nonterminal"}),(0,s.jsx)(n.td,{children:"Call to that rule\u2019s function"})]}),"\n  ",(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"|"})}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"if"})," or ",(0,s.jsx)(n.code,{children:"switch"})," statement"]})]}),"\n  ",(0,s.jsxs)(n.tr,{children:[(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"*"})," or ",(0,s.jsx)(n.code,{children:"+"})]}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"while"})," or ",(0,s.jsx)(n.code,{children:"for"})," loop"]})]}),"\n  ",(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"?"})}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"if"})," statement"]})]})]})]}),"\n",(0,s.jsx)(n.p,{children:'The descent is described as "recursive" because when a grammar rule refers to\r\nitself -- directly or indirectly -- that translates to a recursive function\r\ncall.'}),"\n",(0,s.jsx)(n.h3,{id:"the-parser-class",children:"The parser class"}),"\n",(0,s.jsx)(n.p,{children:"Each grammar rule becomes a method inside this new class:"}),"\n",(0,s.jsx)(n.p,{children:"^code parser"}),"\n",(0,s.jsxs)(n.p,{children:["Like the scanner, the parser consumes a flat input sequence, only now we're\r\nreading tokens instead of characters. We store the list of tokens and use\r\n",(0,s.jsx)(n.code,{children:"current"})," to point to the next token eagerly waiting to be parsed."]}),"\n",(0,s.jsxs)(n.p,{children:["We're going to run straight through the expression grammar now and translate\r\neach rule to Java code. The first rule, ",(0,s.jsx)(n.code,{children:"expression"}),", simply expands to the\r\n",(0,s.jsx)(n.code,{children:"equality"})," rule, so that's straightforward."]}),"\n",(0,s.jsx)(n.p,{children:"^code expression"}),"\n",(0,s.jsxs)(n.p,{children:["Each method for parsing a grammar rule produces a syntax tree for that rule and\r\nreturns it to the caller. When the body of the rule contains a nonterminal -- a\r\nreference to another rule -- we ",(0,s.jsx)(n.span,{name:"left",children:"call"})," that other rule's\r\nmethod."]}),"\n",(0,s.jsxs)(n.aside,{name:"left",children:["\n",(0,s.jsx)(n.p,{children:"This is why left recursion is problematic for recursive descent. The function\r\nfor a left-recursive rule immediately calls itself, which calls itself again,\r\nand so on, until the parser hits a stack overflow and dies."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The rule for equality is a little more complex."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'equality       \u2192 comparison ( ( "!=" | "==" ) comparison )* ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"In Java, that becomes:"}),"\n",(0,s.jsx)(n.p,{children:"^code equality"}),"\n",(0,s.jsxs)(n.p,{children:["Let's step through it. The first ",(0,s.jsx)(n.code,{children:"comparison"})," nonterminal in the body translates\r\nto the first call to ",(0,s.jsx)(n.code,{children:"comparison()"})," in the method. We take that result and store\r\nit in a local variable."]}),"\n",(0,s.jsxs)(n.p,{children:["Then, the ",(0,s.jsx)(n.code,{children:"( ... )*"})," loop in the rule maps to a ",(0,s.jsx)(n.code,{children:"while"})," loop. We need to know\r\nwhen to exit that loop. We can see that inside the rule, we must first find\r\neither a ",(0,s.jsx)(n.code,{children:"!="})," or ",(0,s.jsx)(n.code,{children:"=="})," token. So, if we ",(0,s.jsx)(n.em,{children:"don't"})," see one of those, we must be done\r\nwith the sequence of equality operators. We express that check using a handy\r\n",(0,s.jsx)(n.code,{children:"match()"})," method."]}),"\n",(0,s.jsx)(n.p,{children:"^code match"}),"\n",(0,s.jsxs)(n.p,{children:["This checks to see if the current token has any of the given types. If so, it\r\nconsumes the token and returns ",(0,s.jsx)(n.code,{children:"true"}),". Otherwise, it returns ",(0,s.jsx)(n.code,{children:"false"})," and leaves\r\nthe current token alone. The ",(0,s.jsx)(n.code,{children:"match()"})," method is defined in terms of two more\r\nfundamental operations."]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"check()"})," method returns ",(0,s.jsx)(n.code,{children:"true"})," if the current token is of the given type.\r\nUnlike ",(0,s.jsx)(n.code,{children:"match()"}),", it never consumes the token, it only looks at it."]}),"\n",(0,s.jsx)(n.p,{children:"^code check"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"advance()"})," method consumes the current token and returns it, similar to how\r\nour scanner's corresponding method crawled through characters."]}),"\n",(0,s.jsx)(n.p,{children:"^code advance"}),"\n",(0,s.jsx)(n.p,{children:"These methods bottom out on the last handful of primitive operations."}),"\n",(0,s.jsx)(n.p,{children:"^code utils"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"isAtEnd()"})," checks if we've run out of tokens to parse. ",(0,s.jsx)(n.code,{children:"peek()"})," returns the\r\ncurrent token we have yet to consume, and ",(0,s.jsx)(n.code,{children:"previous()"})," returns the most recently\r\nconsumed token. The latter makes it easier to use ",(0,s.jsx)(n.code,{children:"match()"})," and then access the\r\njust-matched token."]}),"\n",(0,s.jsxs)(n.p,{children:["That's most of the parsing infrastructure we need. Where were we? Right, so if\r\nwe are inside the ",(0,s.jsx)(n.code,{children:"while"})," loop in ",(0,s.jsx)(n.code,{children:"equality()"}),", then we know we have found a\r\n",(0,s.jsx)(n.code,{children:"!="})," or ",(0,s.jsx)(n.code,{children:"=="})," operator and must be parsing an equality expression."]}),"\n",(0,s.jsxs)(n.p,{children:["We grab the matched operator token so we can track which kind of equality\r\nexpression we have. Then we call ",(0,s.jsx)(n.code,{children:"comparison()"})," again to parse the right-hand\r\noperand. We combine the operator and its two operands into a new ",(0,s.jsx)(n.code,{children:"Expr.Binary"}),"\r\nsyntax tree node, and then loop around. For each iteration, we store the\r\nresulting expression back in the same ",(0,s.jsx)(n.code,{children:"expr"})," local variable. As we zip through a\r\nsequence of equality expressions, that creates a left-associative nested tree of\r\nbinary operator nodes."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.span,{name:"sequence"})}),"\n",(0,s.jsx)(n.img,{src:"image/parsing-expressions/sequence.png",alt:"The syntax tree created by parsing 'a == b == c == d == e'"}),"\n",(0,s.jsxs)(n.aside,{name:"sequence",children:["\n",(0,s.jsxs)(n.p,{children:["Parsing ",(0,s.jsx)(n.code,{children:"a == b == c == d == e"}),". For each iteration, we create a new binary\r\nexpression using the previous one as the left operand."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The parser falls out of the loop once it hits a token that's not an equality\r\noperator. Finally, it returns the expression. Note that if the parser never\r\nencounters an equality operator, then it never enters the loop. In that case,\r\nthe ",(0,s.jsx)(n.code,{children:"equality()"})," method effectively calls and returns ",(0,s.jsx)(n.code,{children:"comparison()"}),". In that\r\nway, this method matches an equality operator ",(0,s.jsx)(n.em,{children:"or anything of higher\r\nprecedence"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Moving on to the next rule..."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'comparison     \u2192 term ( ( ">" | ">=" | "<" | "<=" ) term )* ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"Translated to Java:"}),"\n",(0,s.jsx)(n.p,{children:"^code comparison"}),"\n",(0,s.jsxs)(n.p,{children:["The grammar rule is virtually ",(0,s.jsx)(n.span,{name:"handle",children:"identical"})," to ",(0,s.jsx)(n.code,{children:"equality"}),"\r\nand so is the corresponding code. The only differences are the token types for\r\nthe operators we match, and the method we call for the operands -- now\r\n",(0,s.jsx)(n.code,{children:"term()"})," instead of ",(0,s.jsx)(n.code,{children:"comparison()"}),". The remaining two binary operator rules\r\nfollow the same pattern."]}),"\n",(0,s.jsx)(n.p,{children:"In order of precedence, first addition and subtraction:"}),"\n",(0,s.jsxs)(n.aside,{name:"handle",children:["\n",(0,s.jsx)(n.p,{children:"If you wanted to do some clever Java 8, you could create a helper method for\r\nparsing a left-associative series of binary operators given a list of token\r\ntypes, and an operand method handle to simplify this redundant code."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"^code term"}),"\n",(0,s.jsx)(n.p,{children:"And finally, multiplication and division:"}),"\n",(0,s.jsx)(n.p,{children:"^code factor"}),"\n",(0,s.jsx)(n.p,{children:"That's all of the binary operators, parsed with the correct precedence and\r\nassociativity. We're crawling up the precedence hierarchy and now we've reached\r\nthe unary operators."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'unary          \u2192 ( "!" | "-" ) unary\r\n               | primary ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"The code for this is a little different."}),"\n",(0,s.jsx)(n.p,{children:"^code unary"}),"\n",(0,s.jsxs)(n.p,{children:["Again, we look at the ",(0,s.jsx)(n.span,{name:"current",children:"current"})," token to see how to\r\nparse. If it's a ",(0,s.jsx)(n.code,{children:"!"})," or ",(0,s.jsx)(n.code,{children:"-"}),", we must have a unary expression. In that case, we\r\ngrab the token and then recursively call ",(0,s.jsx)(n.code,{children:"unary()"})," again to parse the operand.\r\nWrap that all up in a unary expression syntax tree and we're done."]}),"\n",(0,s.jsxs)(n.aside,{name:"current",children:["\n",(0,s.jsxs)(n.p,{children:["The fact that the parser looks ahead at upcoming tokens to decide how to parse\r\nputs recursive descent into the category of ",(0,s.jsx)(n.strong,{children:"predictive parsers"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Otherwise, we must have reached the highest level of precedence, primary\r\nexpressions."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'primary        \u2192 NUMBER | STRING | "true" | "false" | "nil"\r\n               | "(" expression ")" ;\n'})}),"\n",(0,s.jsx)(n.p,{children:"Most of the cases for the rule are single terminals, so parsing is\r\nstraightforward."}),"\n",(0,s.jsx)(n.p,{children:"^code primary"}),"\n",(0,s.jsxs)(n.p,{children:["The interesting branch is the one for handling parentheses. After we match an\r\nopening ",(0,s.jsx)(n.code,{children:"("})," and parse the expression inside it, we ",(0,s.jsx)(n.em,{children:"must"})," find a ",(0,s.jsx)(n.code,{children:")"})," token. If\r\nwe don't, that's an error."]}),"\n",(0,s.jsx)(n.h2,{id:"syntax-errors",children:"Syntax Errors"}),"\n",(0,s.jsx)(n.p,{children:"A parser really has two jobs:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Given a valid sequence of tokens, produce a corresponding syntax tree."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Given an ",(0,s.jsx)(n.em,{children:"invalid"})," sequence of tokens, detect any errors and tell the\r\nuser about their mistakes."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Don't underestimate how important the second job is! In modern IDEs and editors,\r\nthe parser is constantly reparsing code -- often while the user is still editing\r\nit -- in order to syntax highlight and support things like auto-complete. That\r\nmeans it will encounter code in incomplete, half-wrong states ",(0,s.jsx)(n.em,{children:"all the time."})]}),"\n",(0,s.jsxs)(n.p,{children:["When the user doesn't realize the syntax is wrong, it is up to the parser to\r\nhelp guide them back onto the right path. The way it reports errors is a large\r\npart of your language's user interface. Good syntax error handling is hard. By\r\ndefinition, the code isn't in a well-defined state, so there's no infallible way\r\nto know what the user ",(0,s.jsx)(n.em,{children:"meant"})," to write. The parser can't read your ",(0,s.jsx)(n.span,{name:"telepathy",children:"mind"}),"."]}),"\n",(0,s.jsxs)(n.aside,{name:"telepathy",children:["\n",(0,s.jsx)(n.p,{children:"Not yet at least. With the way things are going in machine learning these days,\r\nwho knows what the future will bring?"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"There are a couple of hard requirements for when the parser runs into a syntax\r\nerror. A parser must:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Detect and report the error."})," If it doesn't detect the ",(0,s.jsx)(n.span,{name:"error",children:"error"})," and passes the resulting malformed syntax tree on\r\nto the interpreter, all manner of horrors may be summoned."]}),"\n",(0,s.jsxs)(n.aside,{name:"error",children:["\n",(0,s.jsxs)(n.p,{children:["Philosophically speaking, if an error isn't detected and the interpreter\r\nruns the code, is it ",(0,s.jsx)(n.em,{children:"really"})," an error?"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Avoid crashing or hanging."})," Syntax errors are a fact of life, and\r\nlanguage tools have to be robust in the face of them. Segfaulting or getting\r\nstuck in an infinite loop isn't allowed. While the source may not be valid\r\n",(0,s.jsx)(n.em,{children:"code"}),", it's still a valid ",(0,s.jsx)(n.em,{children:"input to the parser"})," because users use the\r\nparser to learn what syntax is allowed."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Those are the table stakes if you want to get in the parser game at all, but you\r\nreally want to raise the ante beyond that. A decent parser should:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Be fast."})," Computers are thousands of times faster than they were when\r\nparser technology was first invented. The days of needing to optimize your\r\nparser so that it could get through an entire source file during a coffee\r\nbreak are over. But programmer expectations have risen as quickly, if not\r\nfaster. They expect their editors to reparse files in milliseconds after\r\nevery keystroke."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Report as many distinct errors as there are."})," Aborting after the first\r\nerror is easy to implement, but it's annoying for users if every time they\r\nfix what they think is the one error in a file, a new one appears. They\r\nwant to see them all."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["Minimize ",(0,s.jsx)(n.em,{children:"cascaded"})," errors."]})," Once a single error is found, the parser no\r\nlonger really knows what's going on. It tries to get itself back on track\r\nand keep going, but if it gets confused, it may report a slew of ghost\r\nerrors that don't indicate other real problems in the code. When the first\r\nerror is fixed, those phantoms disappear, because they reflect only the\r\nparser's own confusion. Cascaded errors are annoying because they can scare\r\nthe user into thinking their code is in a worse state than it is."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The last two points are in tension. We want to report as many separate errors as\r\nwe can, but we don't want to report ones that are merely side effects of an\r\nearlier one."}),"\n",(0,s.jsxs)(n.p,{children:["The way a parser responds to an error and keeps going to look for later errors\r\nis called ",(0,s.jsx)(n.strong,{children:"error recovery"}),". This was a hot research topic in the '60s. Back\r\nthen, you'd hand a stack of punch cards to the secretary and come back the next\r\nday to see if the compiler succeeded. With an iteration loop that slow, you\r\n",(0,s.jsx)(n.em,{children:"really"})," wanted to find every single error in your code in one pass."]}),"\n",(0,s.jsx)(n.p,{children:"Today, when parsers complete before you've even finished typing, it's less of an\r\nissue. Simple, fast error recovery is fine."}),"\n",(0,s.jsx)(n.h3,{id:"panic-mode-error-recovery",children:"Panic mode error recovery"}),"\n",(0,s.jsxs)(n.aside,{name:"panic",children:["\n",(0,s.jsx)(n.p,{children:"You know you want to push it."}),"\n",(0,s.jsx)(n.img,{src:"image/parsing-expressions/panic.png",alt:"A big shiny 'PANIC' button."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Of all the recovery techniques devised in yesteryear, the one that best stood\r\nthe test of time is called -- somewhat alarmingly -- ",(0,s.jsx)(n.span,{name:"panic",children:(0,s.jsx)(n.strong,{children:"panic\r\nmode"})}),". As soon as the parser detects an error, it enters panic mode. It\r\nknows at least one token doesn't make sense given its current state in the\r\nmiddle of some stack of grammar productions."]}),"\n",(0,s.jsxs)(n.p,{children:["Before it can get back to parsing, it needs to get its state and the sequence of\r\nforthcoming tokens aligned such that the next token does match the rule being\r\nparsed. This process is called ",(0,s.jsx)(n.strong,{children:"synchronization"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"To do that, we select some rule in the grammar that will mark the\r\nsynchronization point. The parser fixes its parsing state by jumping out of any\r\nnested productions until it gets back to that rule. Then it synchronizes the\r\ntoken stream by discarding tokens until it reaches one that can appear at that\r\npoint in the rule."}),"\n",(0,s.jsxs)(n.p,{children:["Any additional real syntax errors hiding in those discarded tokens aren't\r\nreported, but it also means that any mistaken cascaded errors that are side\r\neffects of the initial error aren't ",(0,s.jsx)(n.em,{children:"falsely"})," reported either, which is a decent\r\ntrade-off."]}),"\n",(0,s.jsx)(n.p,{children:"The traditional place in the grammar to synchronize is between statements. We\r\ndon't have those yet, so we won't actually synchronize in this chapter, but\r\nwe'll get the machinery in place for later."}),"\n",(0,s.jsx)(n.h3,{id:"entering-panic-mode",children:"Entering panic mode"}),"\n",(0,s.jsxs)(n.p,{children:["Back before we went on this side trip around error recovery, we were writing the\r\ncode to parse a parenthesized expression. After parsing the expression, the\r\nparser looks for the closing ",(0,s.jsx)(n.code,{children:")"})," by calling ",(0,s.jsx)(n.code,{children:"consume()"}),". Here, finally, is that\r\nmethod:"]}),"\n",(0,s.jsx)(n.p,{children:"^code consume"}),"\n",(0,s.jsxs)(n.p,{children:["It's similar to ",(0,s.jsx)(n.code,{children:"match()"})," in that it checks to see if the next token is of the\r\nexpected type. If so, it consumes the token and everything is groovy. If some\r\nother token is there, then we've hit an error. We report it by calling this:"]}),"\n",(0,s.jsx)(n.p,{children:"^code error"}),"\n",(0,s.jsx)(n.p,{children:"First, that shows the error to the user by calling:"}),"\n",(0,s.jsx)(n.p,{children:"^code token-error"}),"\n",(0,s.jsx)(n.p,{children:"This reports an error at a given token. It shows the token's location and the\r\ntoken itself. This will come in handy later since we use tokens throughout the\r\ninterpreter to track locations in code."}),"\n",(0,s.jsxs)(n.p,{children:["After we report the error, the user knows about their mistake, but what does the\r\n",(0,s.jsx)(n.em,{children:"parser"})," do next? Back in ",(0,s.jsx)(n.code,{children:"error()"}),", we create and return a ParseError, an\r\ninstance of this new class:"]}),"\n",(0,s.jsx)(n.p,{children:"^code parse-error (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["This is a simple sentinel class we use to unwind the parser. The ",(0,s.jsx)(n.code,{children:"error()"}),"\r\nmethod ",(0,s.jsx)(n.em,{children:"returns"})," the error instead of ",(0,s.jsx)(n.em,{children:"throwing"})," it because we want to let the\r\ncalling method inside the parser decide whether to unwind or not. Some parse\r\nerrors occur in places where the parser isn't likely to get into a weird state\r\nand we don't need to ",(0,s.jsx)(n.span,{name:"production",children:"synchronize"}),". In those\r\nplaces, we simply report the error and keep on truckin'."]}),"\n",(0,s.jsx)(n.p,{children:"For example, Lox limits the number of arguments you can pass to a function. If\r\nyou pass too many, the parser needs to report that error, but it can and should\r\nsimply keep on parsing the extra arguments instead of freaking out and going\r\ninto panic mode."}),"\n",(0,s.jsxs)(n.aside,{name:"production",children:["\n",(0,s.jsxs)(n.p,{children:["Another way to handle common syntax errors is with ",(0,s.jsx)(n.strong,{children:"error productions"}),". You\r\naugment the grammar with a rule that ",(0,s.jsx)(n.em,{children:"successfully"})," matches the ",(0,s.jsx)(n.em,{children:"erroneous"}),"\r\nsyntax. The parser safely parses it but then reports it as an error instead of\r\nproducing a syntax tree."]}),"\n",(0,s.jsxs)(n.p,{children:["For example, some languages have a unary ",(0,s.jsx)(n.code,{children:"+"})," operator, like ",(0,s.jsx)(n.code,{children:"+123"}),", but Lox does\r\nnot. Instead of getting confused when the parser stumbles onto a ",(0,s.jsx)(n.code,{children:"+"})," at the\r\nbeginning of an expression, we could extend the unary rule to allow it."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ebnf",children:'unary \u2192 ( "!" | "-" | "+" ) unary\r\n      | primary ;\n'})}),"\n",(0,s.jsxs)(n.p,{children:["This lets the parser consume ",(0,s.jsx)(n.code,{children:"+"})," without going into panic mode or leaving the\r\nparser in a weird state."]}),"\n",(0,s.jsxs)(n.p,{children:["Error productions work well because you, the parser author, know ",(0,s.jsx)(n.em,{children:"how"})," the code\r\nis wrong and what the user was likely trying to do. That means you can give a\r\nmore helpful message to get the user back on track, like, \"Unary '+' expressions\r\nare not supported.\" Mature parsers tend to accumulate error productions like\r\nbarnacles since they help users fix common mistakes."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"In our case, though, the syntax error is nasty enough that we want to panic and\r\nsynchronize. Discarding tokens is pretty easy, but how do we synchronize the\r\nparser's own state?"}),"\n",(0,s.jsx)(n.h3,{id:"synchronizing-a-recursive-descent-parser",children:"Synchronizing a recursive descent parser"}),"\n",(0,s.jsx)(n.p,{children:"With recursive descent, the parser's state -- which rules it is in the middle of\r\nrecognizing -- is not stored explicitly in fields. Instead, we use Java's\r\nown call stack to track what the parser is doing. Each rule in the middle of\r\nbeing parsed is a call frame on the stack. In order to reset that state, we need\r\nto clear out those call frames."}),"\n",(0,s.jsxs)(n.p,{children:["The natural way to do that in Java is exceptions. When we want to synchronize,\r\nwe ",(0,s.jsx)(n.em,{children:"throw"})," that ParseError object. Higher up in the method for the grammar rule\r\nwe are synchronizing to, we'll catch it. Since we synchronize on statement\r\nboundaries, we'll catch the exception there. After the exception is caught, the\r\nparser is in the right state. All that's left is to synchronize the tokens."]}),"\n",(0,s.jsxs)(n.p,{children:["We want to discard tokens until we're right at the beginning of the next\r\nstatement. That boundary is pretty easy to spot -- it's one of the main reasons\r\nwe picked it. ",(0,s.jsx)(n.em,{children:"After"})," a semicolon, we're ",(0,s.jsx)(n.span,{name:"semicolon",children:"probably"}),"\r\nfinished with a statement. Most statements start with a keyword -- ",(0,s.jsx)(n.code,{children:"for"}),", ",(0,s.jsx)(n.code,{children:"if"}),",\r\n",(0,s.jsx)(n.code,{children:"return"}),", ",(0,s.jsx)(n.code,{children:"var"}),", etc. When the ",(0,s.jsx)(n.em,{children:"next"})," token is any of those, we're probably\r\nabout to start a statement."]}),"\n",(0,s.jsxs)(n.aside,{name:"semicolon",children:["\n",(0,s.jsxs)(n.p,{children:['I say "probably" because we could hit a semicolon separating clauses in a ',(0,s.jsx)(n.code,{children:"for"}),"\r\nloop. Our synchronization isn't perfect, but that's OK. We've already reported\r\nthe first error precisely, so everything after that is kind of \"best effort\"."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This method encapsulates that logic:"}),"\n",(0,s.jsx)(n.p,{children:"^code synchronize"}),"\n",(0,s.jsx)(n.p,{children:"It discards tokens until it thinks it has found a statement boundary. After\r\ncatching a ParseError, we'll call this and then we are hopefully back in sync.\r\nWhen it works well, we have discarded tokens that would have likely caused\r\ncascaded errors anyway, and now we can parse the rest of the file starting at\r\nthe next statement."}),"\n",(0,s.jsxs)(n.p,{children:["Alas, we don't get to see this method in action, since we don't have statements\r\nyet. We'll get to that ",(0,s.jsx)(n.a,{href:"statements-and-state.html",children:"in a couple of chapters"}),". For now, if an\r\nerror occurs, we'll panic and unwind all the way to the top and stop parsing.\r\nSince we can parse only a single expression anyway, that's no big loss."]}),"\n",(0,s.jsx)(n.h2,{id:"wiring-up-the-parser",children:"Wiring up the Parser"}),"\n",(0,s.jsxs)(n.p,{children:["We are mostly done parsing expressions now. There is one other place where we\r\nneed to add a little error handling. As the parser descends through the parsing\r\nmethods for each grammar rule, it eventually hits ",(0,s.jsx)(n.code,{children:"primary()"}),". If none of the\r\ncases in there match, it means we are sitting on a token that can't start an\r\nexpression. We need to handle that error too."]}),"\n",(0,s.jsx)(n.p,{children:"^code primary-error (5 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["With that, all that remains in the parser is to define an initial method to kick\r\nit off. That method is called, naturally enough, ",(0,s.jsx)(n.code,{children:"parse()"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"^code parse"}),"\n",(0,s.jsx)(n.p,{children:"We'll revisit this method later when we add statements to the language. For now,\r\nit parses a single expression and returns it. We also have some temporary code\r\nto exit out of panic mode. Syntax error recovery is the parser's job, so we\r\ndon't want the ParseError exception to escape into the rest of the interpreter."}),"\n",(0,s.jsxs)(n.p,{children:["When a syntax error does occur, this method returns ",(0,s.jsx)(n.code,{children:"null"}),". That's OK. The\r\nparser promises not to crash or hang on invalid syntax, but it doesn't promise\r\nto return a ",(0,s.jsx)(n.em,{children:"usable syntax tree"})," if an error is found. As soon as the parser\r\nreports an error, ",(0,s.jsx)(n.code,{children:"hadError"})," gets set, and subsequent phases are skipped."]}),"\n",(0,s.jsxs)(n.p,{children:["Finally, we can hook up our brand new parser to the main Lox class and try it\r\nout. We still don't have an interpreter, so for now, we'll parse to a syntax\r\ntree and then use the AstPrinter class from the ",(0,s.jsx)(n.a,{href:"representing-code.html#a-not-very-pretty-printer",children:"last chapter"})," to\r\ndisplay it."]}),"\n",(0,s.jsx)(n.p,{children:"Delete the old code to print the scanned tokens and replace it with this:"}),"\n",(0,s.jsx)(n.p,{children:"^code print-ast (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["Congratulations, you have crossed the ",(0,s.jsx)(n.span,{name:"harder",children:"threshold"}),"! That\r\nreally is all there is to handwriting a parser. We'll extend the grammar in\r\nlater chapters with assignment, statements, and other stuff, but none of that is\r\nany more complex than the binary operators we tackled here."]}),"\n",(0,s.jsxs)(n.aside,{name:"harder",children:["\n",(0,s.jsx)(n.p,{children:"It is possible to define a more complex grammar than Lox's that's difficult to\r\nparse using recursive descent. Predictive parsing gets tricky when you may need\r\nto look ahead a large number of tokens to figure out what you're sitting on."}),"\n",(0,s.jsx)(n.p,{children:"In practice, most languages are designed to avoid that. Even in cases where they\r\naren't, you can usually hack around it without too much pain. If you can parse\r\nC++ using recursive descent -- which many C++ compilers do -- you can parse\r\nanything."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Fire up the interpreter and type in some expressions. See how it handles\r\nprecedence and associativity correctly? Not bad for less than 200 lines of code."}),"\n",(0,s.jsxs)(n.div,{className:"challenges",children:["\n",(0,s.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["In C, a block is a statement form that allows you to pack a series of\r\nstatements where a single one is expected. The ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Comma_operator",children:"comma operator"})," is an\r\nanalogous syntax for expressions. A comma-separated series of expressions\r\ncan be given where a single expression is expected (except inside a function\r\ncall's argument list). At runtime, the comma operator evaluates the left\r\noperand and discards the result. Then it evaluates and returns the right\r\noperand."]}),"\n",(0,s.jsx)(n.p,{children:"Add support for comma expressions. Give them the same precedence and\r\nassociativity as in C. Write the grammar, and then implement the necessary\r\nparsing code."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:['Likewise, add support for the C-style conditional or "ternary" operator\r\n',(0,s.jsx)(n.code,{children:"?:"}),". What precedence level is allowed between the ",(0,s.jsx)(n.code,{children:"?"})," and ",(0,s.jsx)(n.code,{children:":"}),"? Is the whole\r\noperator left-associative or right-associative?"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Add error productions to handle each binary operator appearing without a\r\nleft-hand operand. In other words, detect a binary operator appearing at the\r\nbeginning of an expression. Report that as an error, but also parse and\r\ndiscard a right-hand operand with the appropriate precedence."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.div,{className:"design-note",children:["\n",(0,s.jsx)(n.h2,{id:"design-note-logic-versus-history",children:"Design Note: Logic Versus History"}),"\n",(0,s.jsxs)(n.p,{children:["Let's say we decide to add bitwise ",(0,s.jsx)(n.code,{children:"&"})," and ",(0,s.jsx)(n.code,{children:"|"})," operators to Lox. Where should we\r\nput them in the precedence hierarchy? C -- and most languages that follow in C's\r\nfootsteps -- place them below ",(0,s.jsx)(n.code,{children:"=="}),". This is widely considered a mistake because\r\nit means common operations like testing a flag require parentheses."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"if (flags & FLAG_MASK == SOME_FLAG) { ... } // Wrong.\r\nif ((flags & FLAG_MASK) == SOME_FLAG) { ... } // Right.\n"})}),"\n",(0,s.jsx)(n.p,{children:"Should we fix this for Lox and put bitwise operators higher up the precedence\r\ntable than C does? There are two strategies we can take."}),"\n",(0,s.jsxs)(n.p,{children:["You almost never want to use the result of an ",(0,s.jsx)(n.code,{children:"=="})," expression as the operand to\r\na bitwise operator. By making bitwise bind tighter, users don't need to\r\nparenthesize as often. So if we do that, and users assume the precedence is\r\nchosen logically to minimize parentheses, they're likely to infer it correctly."]}),"\n",(0,s.jsxs)(n.p,{children:["This kind of internal consistency makes the language easier to learn because\r\nthere are fewer edge cases and exceptions users have to stumble into and then\r\ncorrect. That's good, because before users can use our language, they have to\r\nload all of that syntax and semantics into their heads. A simpler, more rational\r\nlanguage ",(0,s.jsx)(n.em,{children:"makes sense"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["But, for many users there is an even faster shortcut to getting our language's\r\nideas into their wetware -- ",(0,s.jsx)(n.em,{children:"use concepts they already know"}),". Many newcomers to\r\nour language will be coming from some other language or languages. If our\r\nlanguage uses some of the same syntax or semantics as those, there is much less\r\nfor the user to learn (and ",(0,s.jsx)(n.em,{children:"unlearn"}),")."]}),"\n",(0,s.jsx)(n.p,{children:"This is particularly helpful with syntax. You may not remember it well today,\r\nbut way back when you learned your very first programming language, code\r\nprobably looked alien and unapproachable. Only through painstaking effort did\r\nyou learn to read and accept it. If you design a novel syntax for your new\r\nlanguage, you force users to start that process all over again."}),"\n",(0,s.jsxs)(n.p,{children:["Taking advantage of what users already know is one of the most powerful tools\r\nyou can use to ease adoption of your language. It's almost impossible to\r\noverestimate how valuable this is. But it faces you with a nasty problem: What\r\nhappens when the thing the users all know ",(0,s.jsx)(n.em,{children:"kind of sucks"}),"? C's bitwise operator\r\nprecedence is a mistake that doesn't make sense. But it's a ",(0,s.jsx)(n.em,{children:"familiar"})," mistake\r\nthat millions have already gotten used to and learned to live with."]}),"\n",(0,s.jsx)(n.p,{children:"Do you stay true to your language's own internal logic and ignore history? Do\r\nyou start from a blank slate and first principles? Or do you weave your language\r\ninto the rich tapestry of programming history and give your users a leg up by\r\nstarting from something they already know?"}),"\n",(0,s.jsx)(n.p,{children:"There is no perfect answer here, only trade-offs. You and I are obviously biased\r\ntowards liking novel languages, so our natural inclination is to burn the\r\nhistory books and start our own story."}),"\n",(0,s.jsxs)(n.p,{children:["In practice, it's often better to make the most of what users already know.\r\nGetting them to come to your language requires a big leap. The smaller you can\r\nmake that chasm, the more people will be willing to cross it. But you can't\r\n",(0,s.jsx)(n.em,{children:"always"})," stick to history, or your language won't have anything new and\r\ncompelling to give people a ",(0,s.jsx)(n.em,{children:"reason"})," to jump over."]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>o});var s=r(6540);const t={},a=s.createContext(t);function i(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);