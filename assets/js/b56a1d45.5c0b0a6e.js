"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[3517],{5693:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>o,toc:()=>h});var r=t(4848),a=t(8453);const i={sidebar_position:2},s=void 0,o={id:"Craftinginterpreters/Welcome/A Map of the Territory",title:"A Map of the Territory",description:"You must have a map, no matter how rough. Otherwise you wander all over the",source:"@site/docs/Craftinginterpreters/Welcome/A Map of the Territory.md",sourceDirName:"Craftinginterpreters/Welcome",slug:"/Craftinginterpreters/Welcome/A Map of the Territory",permalink:"/docs/Craftinginterpreters/Welcome/A Map of the Territory",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/Welcome/A Map of the Territory.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/docs/Craftinginterpreters/Welcome/Introduction"},next:{title:"not-translated-yet",permalink:"/docs/category/not-translated-yet"}},l={},h=[{value:"The Parts of a Language",id:"the-parts-of-a-language",level:2},{value:"Scanning",id:"scanning",level:3},{value:"Parsing",id:"parsing",level:3},{value:"Static analysis",id:"static-analysis",level:3},{value:"Intermediate representations",id:"intermediate-representations",level:3},{value:"Optimization",id:"optimization",level:3},{value:"Code generation",id:"code-generation",level:3},{value:"Virtual machine",id:"virtual-machine",level:3},{value:"Runtime",id:"runtime",level:3},{value:"Shortcuts and Alternate Routes",id:"shortcuts-and-alternate-routes",level:2},{value:"Single-pass compilers",id:"single-pass-compilers",level:3},{value:"Tree-walk interpreters",id:"tree-walk-interpreters",level:3},{value:"Transpilers",id:"transpilers",level:3},{value:"Just-in-time compilation",id:"just-in-time-compilation",level:3},{value:"Compilers and Interpreters",id:"compilers-and-interpreters",level:2},{value:"Our Journey",id:"our-journey",level:2},{value:"Challenges",id:"challenges",level:2}];function c(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["You must have a map, no matter how rough. Otherwise you wander all over the\r\nplace. In ",(0,r.jsx)(n.em,{children:"The Lord of the Rings"})," I never made anyone go farther than he could\r\non a given day."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.cite,{children:"J. R. R. Tolkien"})}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"We don't want to wander all over the place, so before we set off, let's scan\r\nthe territory charted by previous language implementers. It will help us\r\nunderstand where we are going and the alternate routes others have taken."}),"\n",(0,r.jsxs)(n.p,{children:["First, let me establish a shorthand. Much of this book is about a language's\r\n",(0,r.jsx)(n.em,{children:"implementation"}),", which is distinct from the ",(0,r.jsx)(n.em,{children:"language itself"}),' in some sort of\r\nPlatonic ideal form. Things like "stack", "bytecode", and "recursive descent",\r\nare nuts and bolts one particular implementation might use. From the user\'s\r\nperspective, as long as the resulting contraption faithfully follows the\r\nlanguage\'s specification, it\'s all implementation detail.']}),"\n",(0,r.jsxs)(n.p,{children:["We're going to spend a lot of time on those details, so if I have to write\r\n\"language ",(0,r.jsx)(n.em,{children:"implementation"}),'" every single time I mention them, I\'ll wear my\r\nfingers off. Instead, I\'ll use "language" to refer to either a language or an\r\nimplementation of it, or both, unless the distinction matters.']}),"\n",(0,r.jsx)(n.h2,{id:"the-parts-of-a-language",children:"The Parts of a Language"}),"\n",(0,r.jsx)(n.p,{children:"Engineers have been building programming languages since the Dark Ages of\r\ncomputing. As soon as we could talk to computers, we discovered doing so was too\r\nhard, and we enlisted their help. I find it fascinating that even though today's\r\nmachines are literally a million times faster and have orders of magnitude more\r\nstorage, the way we build programming languages is virtually unchanged."}),"\n",(0,r.jsxs)(n.p,{children:["Though the area explored by language designers is vast, the trails they've\r\ncarved through it are ",(0,r.jsx)(n.span,{name:"dead",children:"few"}),'. Not every language takes the\r\nexact same path -- some take a shortcut or two -- but otherwise they are\r\nreassuringly similar, from Rear Admiral Grace Hopper\'s first COBOL compiler all\r\nthe way to some hot, new, transpile-to-JavaScript language whose "documentation"\r\nconsists entirely of a single, poorly edited README in a Git repository\r\nsomewhere.']}),"\n",(0,r.jsxs)(n.aside,{name:"dead",children:["\n",(0,r.jsx)(n.p,{children:"There are certainly dead ends, sad little cul-de-sacs of CS papers with zero\r\ncitations and now-forgotten optimizations that only made sense when memory was\r\nmeasured in individual bytes."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"I visualize the network of paths an implementation may choose as climbing a\r\nmountain. You start off at the bottom with the program as raw source text,\r\nliterally just a string of characters. Each phase analyzes the program and\r\ntransforms it to some higher-level representation where the semantics -- what\r\nthe author wants the computer to do -- become more apparent."}),"\n",(0,r.jsxs)(n.p,{children:["Eventually we reach the peak. We have a bird's-eye view of the user's program\r\nand can see what their code ",(0,r.jsx)(n.em,{children:"means"}),". We begin our descent down the other side of\r\nthe mountain. We transform this highest-level representation down to\r\nsuccessively lower-level forms to get closer and closer to something we know how\r\nto make the CPU actually execute."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"The branching paths a language may take over the mountain.",src:t(6434).A+"",width:"1824",height:"833"})}),"\n",(0,r.jsx)(n.p,{children:"Let's trace through each of those trails and points of interest. Our journey\r\nbegins on the left with the bare text of the user's source code:"}),"\n",(0,r.jsx)(n.img,{src:"image/a-map-of-the-territory/string.png",alt:"var average = (min + max) / 2;"}),"\n",(0,r.jsx)(n.h3,{id:"scanning",children:"Scanning"}),"\n",(0,r.jsxs)(n.p,{children:["The first step is ",(0,r.jsx)(n.strong,{children:"scanning"}),", also known as ",(0,r.jsx)(n.strong,{children:"lexing"}),", or (if you're trying\r\nto impress someone) ",(0,r.jsx)(n.strong,{children:"lexical analysis"}),'. They all mean pretty much the same\r\nthing. I like "lexing" because it sounds like something an evil supervillain\r\nwould do, but I\'ll use "scanning" because it seems to be marginally more\r\ncommonplace.']}),"\n",(0,r.jsx)(n.p,{children:"\u7b2c\u4e00\u6b65\u662f\u626b\u63cf\uff0c\u4e5f\u88ab\u53eb\u505a\u5206\u8bcd\uff0c\u6216\u8005(\u5982\u679c\u4f60\u60f3\u8981\u9707\u60ca\u67d0\u4e9b\u4eba)\u4e5f\u53ef\u4ee5\u53eb\u505a\u8bcd\u6cd5\u5206\u6790\u3002\r\n\u4ed6\u4eec\u5176\u5b9e\u90fd\u4e00\u4e2a\u610f\u601d\u3002\u6211\u559c\u6b22\u5206\u8bcd\uff0c\u662f\u56e0\u4e3a\u542c\u8d77\u6765\u50cf\u662f\u8d85\u7ea7\u53cd\u6d3e\u4f1a\u505a\u7684\u4e8b\uff0c\u4f46\u6211\u4f1a\u7528\u626b\u63cf\uff0c\u56e0\u4e3a\u5b83\u770b\u4e0a\u53bb\u7a0d\u663e\u5e73\u51e1\u3002"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"scanner"})," (or ",(0,r.jsx)(n.strong,{children:"lexer"}),") takes in the linear stream of characters and chunks\r\nthem together into a series of something more akin to ",(0,r.jsx)(n.span,{name:"word",children:'"words"'}),". In programming languages, each of these words is\r\ncalled a ",(0,r.jsx)(n.strong,{children:"token"}),". Some tokens are single characters, like ",(0,r.jsx)(n.code,{children:"("})," and ",(0,r.jsx)(n.code,{children:","}),". Others\r\nmay be several characters long, like numbers (",(0,r.jsx)(n.code,{children:"123"}),"), string literals (",(0,r.jsx)(n.code,{children:'"hi!"'}),"),\r\nand identifiers (",(0,r.jsx)(n.code,{children:"min"}),")."]}),"\n",(0,r.jsx)(n.p,{children:"\u4e00\u4e2a\u626b\u63cf\u5668(\u5206\u8bcd\u5668)\u63a5\u53d7\u7ebf\u6027\u5b57\u7b26\u6d41\uff0c\u7136\u540e\u628a\u4ed6\u4eec\u5206\u7ec4\u6210\u4e00\u7cfb\u5217\u66f4\u50cf\u5355\u8bcd\u7684\u4e1c\u897f\u3002\u5728\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u8fd9\u4e9b\u8bcd\u88ab\u53eb\u505atoken\u3002\u4e00\u4e9btoken\u662f\u5355\u72ec\u7684\u5b57\u7b26\uff0c\u50cf&\uff0c\u5176\u4ed6\u7684\u53ef\u80fd\u51e0\u4e2a\u5b57\u7b26\u957f\uff0c\u50cf\u6570\u5b57\uff0c\u5b57\u7b26\u4e32\u5b57\u9762\u91cf\uff0c\u6807\u5fd7\u7b26\u3002"}),"\n",(0,r.jsxs)(n.aside,{name:"word",children:["\n",(0,r.jsx)(n.p,{children:'"Lexical" comes from the Greek root "lex", meaning "word".'}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Some characters in a source file don't actually mean anything. Whitespace is\r\noften insignificant, and comments, by definition, are ignored by the language.\r\nThe scanner usually discards these, leaving a clean sequence of meaningful\r\ntokens."}),"\n",(0,r.jsx)(n.p,{children:"\u4e00\u4e9b\u6e90\u7801\u4e2d\u7684\u5b57\u7b26\u5e76\u6ca1\u6709\u4efb\u4f55\u610f\u4e49\u3002\u7a7a\u683c\u7ecf\u5e38\u662f\u4e0d\u91cd\u8981\u7684\uff0c\u8fd8\u6709\u5728\u5b9a\u4e49\u4e0a\u6ce8\u91ca\u4e5f\u4f1a\u88ab\u8bed\u8a00\u6240\u5ffd\u7565\u3002\u626b\u63cf\u5668\u4f1a\u629b\u5f03\u8fd9\u4e9b\u7559\u4e0b\u4e86\u5e72\u51c0\u7684\uff0c\u6709\u610f\u4e49\u7684token\u5e8f\u5217\u3002"}),"\n",(0,r.jsx)(n.img,{src:"image/a-map-of-the-territory/tokens.png",alt:"[var] [average] [=] [(] [min] [+] [max] [)] [/] [2] [;]"}),"\n",(0,r.jsx)(n.h3,{id:"parsing",children:"Parsing"}),"\n",(0,r.jsxs)(n.p,{children:["The next step is ",(0,r.jsx)(n.strong,{children:"parsing"}),". This is where our syntax gets a ",(0,r.jsx)(n.strong,{children:"grammar"}),' -- the\r\nability to compose larger expressions and statements out of smaller parts. Did\r\nyou ever diagram sentences in English class? If so, you\'ve done what a parser\r\ndoes, except that English has thousands and thousands of "keywords" and an\r\noverflowing cornucopia of ambiguity. Programming languages are much simpler.']}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"parser"})," takes the flat sequence of tokens and builds a tree structure that\r\nmirrors the nested nature of the grammar. These trees have a couple of different\r\nnames -- ",(0,r.jsx)(n.strong,{children:"parse tree"})," or ",(0,r.jsx)(n.strong,{children:"abstract syntax tree"})," -- depending on how\r\nclose to the bare syntactic structure of the source language they are. In\r\npractice, language hackers usually call them ",(0,r.jsx)(n.strong,{children:"syntax trees"}),", ",(0,r.jsx)(n.strong,{children:"ASTs"}),", or\r\noften just ",(0,r.jsx)(n.strong,{children:"trees"}),"."]}),"\n",(0,r.jsx)(n.img,{src:"image/a-map-of-the-territory/ast.png",alt:"An abstract syntax tree."}),"\n",(0,r.jsxs)(n.p,{children:["Parsing has a long, rich history in computer science that is closely tied to the\r\nartificial intelligence community. Many of the techniques used today to parse\r\nprogramming languages were originally conceived to parse ",(0,r.jsx)(n.em,{children:"human"})," languages by AI\r\nresearchers who were trying to get computers to talk to us."]}),"\n",(0,r.jsxs)(n.p,{children:["It turns out human languages were too messy for the rigid grammars those parsers\r\ncould handle, but they were a perfect fit for the simpler artificial grammars of\r\nprogramming languages. Alas, we flawed humans still manage to use those simple\r\ngrammars incorrectly, so the parser's job also includes letting us know when we\r\ndo by reporting ",(0,r.jsx)(n.strong,{children:"syntax errors"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"static-analysis",children:"Static analysis"}),"\n",(0,r.jsx)(n.p,{children:"The first two stages are pretty similar across all implementations. Now, the\r\nindividual characteristics of each language start coming into play. At this\r\npoint, we know the syntactic structure of the code -- things like which\r\nexpressions are nested in which -- but we don't know much more than that."}),"\n",(0,r.jsxs)(n.p,{children:["In an expression like ",(0,r.jsx)(n.code,{children:"a + b"}),", we know we are adding ",(0,r.jsx)(n.code,{children:"a"})," and ",(0,r.jsx)(n.code,{children:"b"}),", but we don't\r\nknow what those names refer to. Are they local variables? Global? Where are they\r\ndefined?"]}),"\n",(0,r.jsxs)(n.p,{children:["The first bit of analysis that most languages do is called ",(0,r.jsx)(n.strong,{children:"binding"})," or\r\n",(0,r.jsx)(n.strong,{children:"resolution"}),". For each ",(0,r.jsx)(n.strong,{children:"identifier"}),", we find out where that name is defined\r\nand wire the two together. This is where ",(0,r.jsx)(n.strong,{children:"scope"})," comes into play -- the region\r\nof source code where a certain name can be used to refer to a certain\r\ndeclaration."]}),"\n",(0,r.jsxs)(n.p,{children:["If the language is ",(0,r.jsx)(n.span,{name:"type",children:"statically typed"}),", this is when we\r\ntype check. Once we know where ",(0,r.jsx)(n.code,{children:"a"})," and ",(0,r.jsx)(n.code,{children:"b"})," are declared, we can also figure out\r\ntheir types. Then if those types don't support being added to each other, we\r\nreport a ",(0,r.jsx)(n.strong,{children:"type error"}),"."]}),"\n",(0,r.jsxs)(n.aside,{name:"type",children:["\n",(0,r.jsx)(n.p,{children:"The language we'll build in this book is dynamically typed, so it will do its\r\ntype checking later, at runtime."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Take a deep breath. We have attained the summit of the mountain and a sweeping\r\nview of the user's program. All this semantic insight that is visible to us from\r\nanalysis needs to be stored somewhere. There are a few places we can squirrel it\r\naway:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Often, it gets stored right back as ",(0,r.jsx)(n.strong,{children:"attributes"})," on the syntax tree\r\nitself -- extra fields in the nodes that aren't initialized during parsing\r\nbut get filled in later."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Other times, we may store data in a lookup table off to the side. Typically,\r\nthe keys to this table are identifiers -- names of variables and declarations.\r\nIn that case, we call it a ",(0,r.jsx)(n.strong,{children:"symbol table"})," and the values it associates with\r\neach key tell us what that identifier refers to."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The most powerful bookkeeping tool is to transform the tree into an entirely\r\nnew data structure that more directly expresses the semantics of the code.\r\nThat's the next section."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Everything up to this point is considered the ",(0,r.jsx)(n.strong,{children:"front end"})," of the\r\nimplementation. You might guess everything after this is the ",(0,r.jsx)(n.strong,{children:"back end"}),', but\r\nno. Back in the days of yore when "front end" and "back end" were coined,\r\ncompilers were much simpler. Later researchers invented new phases to stuff\r\nbetween the two halves. Rather than discard the old terms, William Wulf and\r\ncompany lumped those new phases into the charming but spatially paradoxical name\r\n',(0,r.jsx)(n.strong,{children:"middle end"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"intermediate-representations",children:"Intermediate representations"}),"\n",(0,r.jsx)(n.p,{children:"You can think of the compiler as a pipeline where each stage's job is to\r\norganize the data representing the user's code in a way that makes the next\r\nstage simpler to implement. The front end of the pipeline is specific to the\r\nsource language the program is written in. The back end is concerned with the\r\nfinal architecture where the program will run."}),"\n",(0,r.jsxs)(n.p,{children:["In the middle, the code may be stored in some ",(0,r.jsx)(n.span,{name:"ir",children:(0,r.jsx)(n.strong,{children:"intermediate\r\nrepresentation"})})," (",(0,r.jsx)(n.strong,{children:"IR"}),') that isn\'t tightly tied to either the source or\r\ndestination forms (hence "intermediate"). Instead, the IR acts as an interface\r\nbetween these two languages.']}),"\n",(0,r.jsxs)(n.aside,{name:"ir",children:["\n",(0,r.jsx)(n.p,{children:'There are a few well-established styles of IRs out there. Hit your search engine\r\nof choice and look for "control flow graph", "static single-assignment",\r\n"continuation-passing style", and "three-address code".'}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This lets you support multiple source languages and target platforms with less\r\neffort. Say you want to implement Pascal, C, and Fortran compilers, and you want\r\nto target x86, ARM, and, I dunno, SPARC. Normally, that means you're signing up\r\nto write ",(0,r.jsx)(n.em,{children:"nine"})," full compilers: Pascal\u2192x86, C\u2192ARM, and every other\r\ncombination."]}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.span,{name:"gcc",children:"shared"})," intermediate representation reduces that\r\ndramatically. You write ",(0,r.jsx)(n.em,{children:"one"})," front end for each source language that produces\r\nthe IR. Then ",(0,r.jsx)(n.em,{children:"one"})," back end for each target architecture. Now you can mix and\r\nmatch those to get every combination."]}),"\n",(0,r.jsxs)(n.aside,{name:"gcc",children:["\n",(0,r.jsxs)(n.p,{children:["If you've ever wondered how ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/GNU_Compiler_Collection",children:"GCC"})," supports so many crazy languages and\r\narchitectures, like Modula-3 on Motorola 68k, now you know. Language front ends\r\ntarget one of a handful of IRs, mainly ",(0,r.jsx)(n.a,{href:"https://gcc.gnu.org/onlinedocs/gccint/GIMPLE.html",children:"GIMPLE"})," and ",(0,r.jsx)(n.a,{href:"https://gcc.gnu.org/onlinedocs/gccint/RTL.html",children:"RTL"}),". Target back ends\r\nlike the one for 68k then take those IRs and produce native code."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"There's another big reason we might want to transform the code into a form that\r\nmakes the semantics more apparent..."}),"\n",(0,r.jsx)(n.h3,{id:"optimization",children:"Optimization"}),"\n",(0,r.jsxs)(n.p,{children:["Once we understand what the user's program means, we are free to swap it out\r\nwith a different program that has the ",(0,r.jsx)(n.em,{children:"same semantics"})," but implements them more\r\nefficiently -- we can ",(0,r.jsx)(n.strong,{children:"optimize"})," it."]}),"\n",(0,r.jsxs)(n.p,{children:["A simple example is ",(0,r.jsx)(n.strong,{children:"constant folding"}),": if some expression always evaluates to\r\nthe exact same value, we can do the evaluation at compile time and replace the\r\ncode for the expression with its result. If the user typed in this:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"pennyArea = 3.14159 * (0.75 / 2) * (0.75 / 2);\n"})}),"\n",(0,r.jsx)(n.p,{children:"we could do all of that arithmetic in the compiler and change the code to:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:"pennyArea = 0.4417860938;\n"})}),"\n",(0,r.jsx)(n.p,{children:"Optimization is a huge part of the programming language business. Many language\r\nhackers spend their entire careers here, squeezing every drop of performance\r\nthey can out of their compilers to get their benchmarks a fraction of a percent\r\nfaster. It can become a sort of obsession."}),"\n",(0,r.jsxs)(n.p,{children:["We're mostly going to ",(0,r.jsx)(n.span,{name:"rathole",children:"hop over that rathole"})," in this\r\nbook. Many successful languages have surprisingly few compile-time\r\noptimizations. For example, Lua and CPython generate relatively unoptimized\r\ncode, and focus most of their performance effort on the runtime."]}),"\n",(0,r.jsxs)(n.aside,{name:"rathole",children:["\n",(0,r.jsx)(n.p,{children:'If you can\'t resist poking your foot into that hole, some keywords to get you\r\nstarted are "constant propagation", "common subexpression elimination", "loop\r\ninvariant code motion", "global value numbering", "strength reduction", "scalar\r\nreplacement of aggregates", "dead code elimination", and "loop unrolling".'}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"code-generation",children:"Code generation"}),"\n",(0,r.jsxs)(n.p,{children:["We have applied all of the optimizations we can think of to the user's program.\r\nThe last step is converting it to a form the machine can actually run. In other\r\nwords, ",(0,r.jsx)(n.strong,{children:"generating code"})," (or ",(0,r.jsx)(n.strong,{children:"code gen"}),'), where "code" here usually refers to\r\nthe kind of primitive assembly-like instructions a CPU runs and not the kind of\r\n"source code" a human might want to read.']}),"\n",(0,r.jsxs)(n.p,{children:["Finally, we are in the ",(0,r.jsx)(n.strong,{children:"back end"}),", descending the other side of the mountain.\r\nFrom here on out, our representation of the code becomes more and more\r\nprimitive, like evolution run in reverse, as we get closer to something our\r\nsimple-minded machine can understand."]}),"\n",(0,r.jsxs)(n.p,{children:["We have a decision to make. Do we generate instructions for a real CPU or a\r\nvirtual one? If we generate real machine code, we get an executable that the OS\r\ncan load directly onto the chip. Native code is lightning fast, but generating\r\nit is a lot of work. Today's architectures have piles of instructions, complex\r\npipelines, and enough ",(0,r.jsx)(n.span,{name:"aad",children:"historical baggage"})," to fill a 747's\r\nluggage bay."]}),"\n",(0,r.jsxs)(n.p,{children:["Speaking the chip's language also means your compiler is tied to a specific\r\narchitecture. If your compiler targets ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/X86",children:"x86"})," machine code, it's not going to\r\nrun on an ",(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/ARM_architecture",children:"ARM"})," device. All the way back in the '60s, during the\r\nCambrian explosion of computer architectures, that lack of portability was a\r\nreal obstacle."]}),"\n",(0,r.jsxs)(n.aside,{name:"aad",children:["\n",(0,r.jsxs)(n.p,{children:["For example, the ",(0,r.jsx)(n.a,{href:"http://www.felixcloutier.com/x86/AAD.html",children:"AAD"}),' ("ASCII Adjust AX Before Division") instruction lets\r\nyou perform division, which sounds useful. Except that instruction takes, as\r\noperands, two binary-coded decimal digits packed into a single 16-bit register.\r\nWhen was the last time ',(0,r.jsx)(n.em,{children:"you"})," needed BCD on a 16-bit machine?"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["To get around that, hackers like Martin Richards and Niklaus Wirth, of BCPL and\r\nPascal fame, respectively, made their compilers produce ",(0,r.jsx)(n.em,{children:"virtual"})," machine code.\r\nInstead of instructions for some real chip, they produced code for a\r\nhypothetical, idealized machine. Wirth called this ",(0,r.jsx)(n.strong,{children:"p-code"})," for ",(0,r.jsx)(n.em,{children:"portable"}),",\r\nbut today, we generally call it ",(0,r.jsx)(n.strong,{children:"bytecode"})," because each instruction is often a\r\nsingle byte long."]}),"\n",(0,r.jsx)(n.p,{children:"These synthetic instructions are designed to map a little more closely to the\r\nlanguage's semantics, and not be so tied to the peculiarities of any one\r\ncomputer architecture and its accumulated historical cruft. You can think of it\r\nlike a dense, binary encoding of the language's low-level operations."}),"\n",(0,r.jsx)(n.h3,{id:"virtual-machine",children:"Virtual machine"}),"\n",(0,r.jsxs)(n.p,{children:["If your compiler produces bytecode, your work isn't over once that's done. Since\r\nthere is no chip that speaks that bytecode, it's your job to translate. Again,\r\nyou have two options. You can write a little mini-compiler for each target\r\narchitecture that converts the bytecode to native code for that machine. You\r\nstill have to do work for ",(0,r.jsx)(n.span,{name:"shared",children:"each"})," chip you support, but\r\nthis last stage is pretty simple and you get to reuse the rest of the compiler\r\npipeline across all of the machines you support. You're basically using your\r\nbytecode as an intermediate representation."]}),"\n",(0,r.jsxs)(n.aside,{name:"shared",className:"bottom",children:["\n",(0,r.jsx)(n.p,{children:"The basic principle here is that the farther down the pipeline you push the\r\narchitecture-specific work, the more of the earlier phases you can share across\r\narchitectures."}),"\n",(0,r.jsx)(n.p,{children:"There is a tension, though. Many optimizations, like register allocation and\r\ninstruction selection, work best when they know the strengths and capabilities\r\nof a specific chip. Figuring out which parts of your compiler can be shared and\r\nwhich should be target-specific is an art."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Or you can write a ",(0,r.jsx)(n.span,{name:"vm",children:(0,r.jsx)(n.strong,{children:"virtual machine"})})," (",(0,r.jsx)(n.strong,{children:"VM"}),"), a\r\nprogram that emulates a hypothetical chip supporting your virtual architecture\r\nat runtime. Running bytecode in a VM is slower than translating it to native\r\ncode ahead of time because every instruction must be simulated at runtime each\r\ntime it executes. In return, you get simplicity and portability. Implement your\r\nVM in, say, C, and you can run your language on any platform that has a C\r\ncompiler. This is how the second interpreter we build in this book works."]}),"\n",(0,r.jsxs)(n.aside,{name:"vm",children:["\n",(0,r.jsxs)(n.p,{children:['The term "virtual machine" also refers to a different kind of abstraction. A\r\n',(0,r.jsx)(n.strong,{children:"system virtual machine"}),' emulates an entire hardware platform and operating\r\nsystem in software. This is how you can play Windows games on your Linux\r\nmachine, and how cloud providers give customers the user experience of\r\ncontrolling their own "server" without needing to physically allocate separate\r\ncomputers for each user.']}),"\n",(0,r.jsxs)(n.p,{children:["The kind of VMs we'll talk about in this book are ",(0,r.jsx)(n.strong,{children:"language virtual machines"}),"\r\nor ",(0,r.jsx)(n.strong,{children:"process virtual machines"})," if you want to be unambiguous."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"runtime",children:"Runtime"}),"\n",(0,r.jsx)(n.p,{children:"We have finally hammered the user's program into a form that we can execute. The\r\nlast step is running it. If we compiled it to machine code, we simply tell the\r\noperating system to load the executable and off it goes. If we compiled it to\r\nbytecode, we need to start up the VM and load the program into that."}),"\n",(0,r.jsx)(n.p,{children:'In both cases, for all but the basest of low-level languages, we usually need\r\nsome services that our language provides while the program is running. For\r\nexample, if the language automatically manages memory, we need a garbage\r\ncollector going in order to reclaim unused bits. If our language supports\r\n"instance of" tests so you can see what kind of object you have, then we need\r\nsome representation to keep track of the type of each object during execution.'}),"\n",(0,r.jsxs)(n.p,{children:["All of this stuff is going at runtime, so it's called, appropriately, the\r\n",(0,r.jsx)(n.strong,{children:"runtime"}),". In a fully compiled language, the code implementing the runtime\r\ngets inserted directly into the resulting executable. In, say, ",(0,r.jsx)(n.a,{href:"https://golang.org/",children:"Go"}),", each\r\ncompiled application has its own copy of Go's runtime directly embedded in it.\r\nIf the language is run inside an interpreter or VM, then the runtime lives\r\nthere. This is how most implementations of languages like Java, Python, and\r\nJavaScript work."]}),"\n",(0,r.jsx)(n.h2,{id:"shortcuts-and-alternate-routes",children:"Shortcuts and Alternate Routes"}),"\n",(0,r.jsx)(n.p,{children:"That's the long path covering every possible phase you might implement. Many\r\nlanguages do walk the entire route, but there are a few shortcuts and alternate\r\npaths."}),"\n",(0,r.jsx)(n.h3,{id:"single-pass-compilers",children:"Single-pass compilers"}),"\n",(0,r.jsxs)(n.p,{children:["Some simple compilers interleave parsing, analysis, and code generation so that\r\nthey produce output code directly in the parser, without ever allocating any\r\nsyntax trees or other IRs. These ",(0,r.jsx)(n.span,{name:"sdt",children:(0,r.jsx)(n.strong,{children:"single-pass\r\ncompilers"})})," restrict the design of the language. You have no intermediate\r\ndata structures to store global information about the program, and you don't\r\nrevisit any previously parsed part of the code. That means as soon as you see\r\nsome expression, you need to know enough to correctly compile it."]}),"\n",(0,r.jsxs)(n.aside,{name:"sdt",children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Syntax-directed_translation",children:(0,r.jsx)(n.strong,{children:"Syntax-directed translation"})})," is a structured technique for building\r\nthese all-at-once compilers. You associate an ",(0,r.jsx)(n.em,{children:"action"})," with each piece of the\r\ngrammar, usually one that generates output code. Then, whenever the parser\r\nmatches that chunk of syntax, it executes the action, building up the target\r\ncode one rule at a time."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Pascal and C were designed around this limitation. At the time, memory was so\r\nprecious that a compiler might not even be able to hold an entire ",(0,r.jsx)(n.em,{children:"source file"}),"\r\nin memory, much less the whole program. This is why Pascal's grammar requires\r\ntype declarations to appear first in a block. It's why in C you can't call a\r\nfunction above the code that defines it unless you have an explicit forward\r\ndeclaration that tells the compiler what it needs to know to generate code for a\r\ncall to the later function."]}),"\n",(0,r.jsx)(n.h3,{id:"tree-walk-interpreters",children:"Tree-walk interpreters"}),"\n",(0,r.jsx)(n.p,{children:"Some programming languages begin executing code right after parsing it to an AST\r\n(with maybe a bit of static analysis applied). To run the program, the\r\ninterpreter traverses the syntax tree one branch and leaf at a time, evaluating\r\neach node as it goes."}),"\n",(0,r.jsxs)(n.p,{children:["This implementation style is common for student projects and little languages,\r\nbut is not widely used for ",(0,r.jsx)(n.span,{name:"ruby",children:"general-purpose"}),' languages\r\nsince it tends to be slow. Some people use "interpreter" to mean only these\r\nkinds of implementations, but others define that word more generally, so I\'ll\r\nuse the inarguably explicit ',(0,r.jsx)(n.strong,{children:"tree-walk interpreter"})," to refer to these. Our\r\nfirst interpreter rolls this way."]}),"\n",(0,r.jsxs)(n.aside,{name:"ruby",children:["\n",(0,r.jsx)(n.p,{children:"A notable exception is early versions of Ruby, which were tree walkers. At 1.9,\r\nthe canonical implementation of Ruby switched from the original MRI (Matz's Ruby\r\nInterpreter) to Koichi Sasada's YARV (Yet Another Ruby VM). YARV is a\r\nbytecode virtual machine."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"transpilers",children:"Transpilers"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.span,{name:"gary",children:"Writing"})," a complete back end for a language can be a lot\r\nof work. If you have some existing generic IR to target, you could bolt your\r\nfront end onto that. Otherwise, it seems like you're stuck. But what if you\r\ntreated some other ",(0,r.jsx)(n.em,{children:"source language"})," as if it were an intermediate\r\nrepresentation?"]}),"\n",(0,r.jsxs)(n.p,{children:["You write a front end for your language. Then, in the back end, instead of doing\r\nall the work to ",(0,r.jsx)(n.em,{children:"lower"})," the semantics to some primitive target language, you\r\nproduce a string of valid source code for some other language that's about as\r\nhigh level as yours. Then, you use the existing compilation tools for ",(0,r.jsx)(n.em,{children:"that"}),"\r\nlanguage as your escape route off the mountain and down to something you can\r\nexecute."]}),"\n",(0,r.jsxs)(n.p,{children:["They used to call this a ",(0,r.jsx)(n.strong,{children:"source-to-source compiler"})," or a ",(0,r.jsx)(n.strong,{children:"transcompiler"}),".\r\nAfter the rise of languages that compile to JavaScript in order to run in the\r\nbrowser, they've affected the hipster sobriquet ",(0,r.jsx)(n.strong,{children:"transpiler"}),"."]}),"\n",(0,r.jsxs)(n.aside,{name:"gary",children:["\n",(0,r.jsx)(n.p,{children:"The first transcompiler, XLT86, translated 8080 assembly into 8086 assembly.\r\nThat might seem straightforward, but keep in mind the 8080 was an 8-bit chip and\r\nthe 8086 a 16-bit chip that could use each register as a pair of 8-bit ones.\r\nXLT86 did data flow analysis to track register usage in the source program and\r\nthen efficiently map it to the register set of the 8086."}),"\n",(0,r.jsx)(n.p,{children:"It was written by Gary Kildall, a tragic hero of computer science if there\r\never was one. One of the first people to recognize the promise of\r\nmicrocomputers, he created PL/M and CP/M, the first high-level language and OS\r\nfor them."}),"\n",(0,r.jsx)(n.p,{children:"He was a sea captain, business owner, licensed pilot, and motorcyclist. A TV\r\nhost with the Kris Kristofferson-esque look sported by dashing bearded dudes in\r\nthe '80s. He took on Bill Gates and, like many, lost, before meeting his end in\r\na biker bar under mysterious circumstances. He died too young, but sure as hell\r\nlived before he did."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"While the first transcompiler translated one assembly language to another,\r\ntoday, most transpilers work on higher-level languages. After the viral spread\r\nof UNIX to machines various and sundry, there began a long tradition of\r\ncompilers that produced C as their output language. C compilers were available\r\neverywhere UNIX was and produced efficient code, so targeting C was a good way\r\nto get your language running on a lot of architectures."}),"\n",(0,r.jsxs)(n.p,{children:['Web browsers are the "machines" of today, and their "machine code" is\r\nJavaScript, so these days it seems ',(0,r.jsx)(n.a,{href:"https://github.com/jashkenas/coffeescript/wiki/list-of-languages-that-compile-to-js",children:"almost every language out there"})," has a\r\ncompiler that targets JS since that's the ",(0,r.jsx)(n.span,{name:"js",children:"main"})," way to get\r\nyour code running in a browser."]}),"\n",(0,r.jsxs)(n.aside,{name:"js",children:["\n",(0,r.jsxs)(n.p,{children:["JS used to be the ",(0,r.jsx)(n.em,{children:"only"})," way to execute code in a browser. Thanks to\r\n",(0,r.jsx)(n.a,{href:"https://github.com/webassembly/",children:"WebAssembly"}),", compilers now have a second, lower-level language they can\r\ntarget that runs on the web."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The front end -- scanner and parser -- of a transpiler looks like other\r\ncompilers. Then, if the source language is only a simple syntactic skin over the\r\ntarget language, it may skip analysis entirely and go straight to outputting the\r\nanalogous syntax in the destination language."}),"\n",(0,r.jsx)(n.p,{children:"If the two languages are more semantically different, you'll see more of the\r\ntypical phases of a full compiler including analysis and possibly even\r\noptimization. Then, when it comes to code generation, instead of outputting some\r\nbinary language like machine code, you produce a string of grammatically correct\r\nsource (well, destination) code in the target language."}),"\n",(0,r.jsx)(n.p,{children:"Either way, you then run that resulting code through the output language's\r\nexisting compilation pipeline, and you're good to go."}),"\n",(0,r.jsx)(n.h3,{id:"just-in-time-compilation",children:"Just-in-time compilation"}),"\n",(0,r.jsx)(n.p,{children:"This last one is less a shortcut and more a dangerous alpine scramble best\r\nreserved for experts. The fastest way to execute code is by compiling it to\r\nmachine code, but you might not know what architecture your end user's machine\r\nsupports. What to do?"}),"\n",(0,r.jsxs)(n.p,{children:["You can do the same thing that the HotSpot Java Virtual Machine (JVM),\r\nMicrosoft's Common Language Runtime (CLR), and most JavaScript interpreters do.\r\nOn the end user's machine, when the program is loaded -- either from source in\r\nthe case of JS, or platform-independent bytecode for the JVM and CLR -- you\r\ncompile it to native code for the architecture their computer supports.\r\nNaturally enough, this is called ",(0,r.jsx)(n.strong,{children:"just-in-time compilation"}),'. Most hackers just\r\nsay "JIT", pronounced like it rhymes with "fit".']}),"\n",(0,r.jsxs)(n.p,{children:["The most sophisticated JITs insert profiling hooks into the generated code to\r\nsee which regions are most performance critical and what kind of data is flowing\r\nthrough them. Then, over time, they will automatically recompile those ",(0,r.jsx)(n.span,{name:"hot",children:"hot spots"})," with more advanced optimizations."]}),"\n",(0,r.jsxs)(n.aside,{name:"hot",children:["\n",(0,r.jsx)(n.p,{children:"This is, of course, exactly where the HotSpot JVM gets its name."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"compilers-and-interpreters",children:"Compilers and Interpreters"}),"\n",(0,r.jsx)(n.p,{children:"Now that I've stuffed your head with a dictionary's worth of programming\r\nlanguage jargon, we can finally address a question that's plagued coders since\r\ntime immemorial: What's the difference between a compiler and an interpreter?"}),"\n",(0,r.jsxs)(n.p,{children:['It turns out this is like asking the difference between a fruit and a vegetable.\r\nThat seems like a binary either-or choice, but actually "fruit" is a ',(0,r.jsx)(n.em,{children:"botanical"}),'\r\nterm and "vegetable" is ',(0,r.jsx)(n.em,{children:"culinary"}),". One does not strictly imply the negation of\r\nthe other. There are fruits that aren't vegetables (apples) and vegetables that\r\naren't fruits (carrots), but also edible plants that are both fruits ",(0,r.jsx)(n.em,{children:"and"}),"\r\nvegetables, like tomatoes."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.span,{name:"veg"})}),"\n",(0,r.jsx)(n.img,{src:"image/a-map-of-the-territory/plants.png",alt:"A Venn diagram of edible plants"}),"\n",(0,r.jsxs)(n.aside,{name:"veg",children:["\n",(0,r.jsx)(n.p,{children:"Peanuts (which are not even nuts) and cereals like wheat are actually fruit, but\r\nI got this drawing wrong. What can I say, I'm a software engineer, not a\r\nbotanist. I should probably erase the little peanut guy, but he's so cute that I\r\ncan't bear to."}),"\n",(0,r.jsxs)(n.p,{children:["Now ",(0,r.jsx)(n.em,{children:"pine nuts"}),", on the other hand, are plant-based foods that are neither\r\nfruits nor vegetables. At least as far as I can tell."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"So, back to languages:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Compiling"})," is an ",(0,r.jsx)(n.em,{children:"implementation technique"})," that involves translating a\r\nsource language to some other -- usually lower-level -- form. When you\r\ngenerate bytecode or machine code, you are compiling. When you transpile to\r\nanother high-level language, you are compiling too."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:['When we say a language implementation "is a ',(0,r.jsx)(n.strong,{children:"compiler"}),"\", we mean it\r\ntranslates source code to some other form but doesn't execute it. The user has\r\nto take the resulting output and run it themselves."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:['Conversely, when we say an implementation "is an ',(0,r.jsx)(n.strong,{children:"interpreter"}),'", we mean it\r\ntakes in source code and executes it immediately. It runs programs "from\r\nsource".']}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Like apples and oranges, some implementations are clearly compilers and ",(0,r.jsx)(n.em,{children:"not"}),"\r\ninterpreters. GCC and Clang take your C code and compile it to machine code. An\r\nend user runs that executable directly and may never even know which tool was\r\nused to compile it. So those are ",(0,r.jsx)(n.em,{children:"compilers"})," for C."]}),"\n",(0,r.jsxs)(n.p,{children:["In older versions of Matz's canonical implementation of Ruby, the user ran Ruby\r\nfrom source. The implementation parsed it and executed it directly by traversing\r\nthe syntax tree. No other translation occurred, either internally or in any\r\nuser-visible form. So this was definitely an ",(0,r.jsx)(n.em,{children:"interpreter"})," for Ruby."]}),"\n",(0,r.jsx)(n.p,{children:"But what of CPython? When you run your Python program using it, the code is\r\nparsed and converted to an internal bytecode format, which is then executed\r\ninside the VM. From the user's perspective, this is clearly an interpreter --\r\nthey run their program from source. But if you look under CPython's scaly skin,\r\nyou'll see that there is definitely some compiling going on."}),"\n",(0,r.jsxs)(n.p,{children:["The answer is that it is ",(0,r.jsx)(n.span,{name:"go",children:"both"}),". CPython ",(0,r.jsx)(n.em,{children:"is"})," an\r\ninterpreter, and it ",(0,r.jsx)(n.em,{children:"has"})," a compiler. In practice, most scripting languages work\r\nthis way, as you can see:"]}),"\n",(0,r.jsxs)(n.aside,{name:"go",children:["\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.a,{href:"https://golang.org/",children:"Go tool"})," is even more of a horticultural curiosity. If you run ",(0,r.jsx)(n.code,{children:"go build"}),", it compiles your Go source code to machine code and stops. If you type\r\n",(0,r.jsx)(n.code,{children:"go run"}),", it does that, then immediately executes the generated executable."]}),"\n",(0,r.jsxs)(n.p,{children:["So ",(0,r.jsx)(n.code,{children:"go"})," ",(0,r.jsx)(n.em,{children:"is"})," a compiler (you can use it as a tool to compile code without\r\nrunning it), ",(0,r.jsx)(n.em,{children:"is"})," an interpreter (you can invoke it to immediately run a program\r\nfrom source), and also ",(0,r.jsx)(n.em,{children:"has"})," a compiler (when you use it as an interpreter, it\r\nis still compiling internally)."]}),"\n"]}),"\n",(0,r.jsx)(n.img,{src:"image/a-map-of-the-territory/venn.png",alt:"A Venn diagram of compilers and interpreters"}),"\n",(0,r.jsx)(n.p,{children:"That overlapping region in the center is where our second interpreter lives too,\r\nsince it internally compiles to bytecode. So while this book is nominally about\r\ninterpreters, we'll cover some compilation too."}),"\n",(0,r.jsx)(n.h2,{id:"our-journey",children:"Our Journey"}),"\n",(0,r.jsxs)(n.p,{children:["That's a lot to take in all at once. Don't worry. This isn't the chapter where\r\nyou're expected to ",(0,r.jsx)(n.em,{children:"understand"})," all of these pieces and parts. I just want you\r\nto know that they are out there and roughly how they fit together."]}),"\n",(0,r.jsx)(n.p,{children:"This map should serve you well as you explore the territory beyond the guided\r\npath we take in this book. I want to leave you yearning to strike out on your\r\nown and wander all over that mountain."}),"\n",(0,r.jsxs)(n.p,{children:["But, for now, it's time for our own journey to begin. Tighten your bootlaces,\r\ncinch up your pack, and come along. From ",(0,r.jsx)(n.span,{name:"here",children:"here"})," on out,\r\nall you need to focus on is the path in front of you."]}),"\n",(0,r.jsxs)(n.aside,{name:"here",children:["\n",(0,r.jsx)(n.p,{children:"Henceforth, I promise to tone down the whole mountain metaphor thing."}),"\n"]}),"\n",(0,r.jsxs)(n.div,{className:"challenges",children:["\n",(0,r.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Pick an open source implementation of a language you like. Download the\r\nsource code and poke around in it. Try to find the code that implements the\r\nscanner and parser. Are they handwritten, or generated using tools like\r\nLex and Yacc? (",(0,r.jsx)(n.code,{children:".l"})," or ",(0,r.jsx)(n.code,{children:".y"})," files usually imply the latter.)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Just-in-time compilation tends to be the fastest way to implement dynamically\r\ntyped languages, but not all of them use it. What reasons are there to ",(0,r.jsx)(n.em,{children:"not"}),"\r\nJIT?"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Most Lisp implementations that compile to C also contain an interpreter that\r\nlets them execute Lisp code on the fly as well. Why?"}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},6434:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/mountain-fb8894c489ca034a5178297e3681c993.png"},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var r=t(6540);const a={},i=r.createContext(a);function s(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);