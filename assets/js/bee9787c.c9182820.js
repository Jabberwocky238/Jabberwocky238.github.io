"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[765],{5709:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>h,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var t=r(4848),s=r(8453);const i={},o=void 0,a={id:"Craftinginterpreters/not-translated-yet/compiling-expressions",title:"compiling-expressions",description:"In the middle of the journey of our life I found myself within a dark woods",source:"@site/docs/Craftinginterpreters/not-translated-yet/compiling-expressions.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/compiling-expressions",permalink:"/docs/Craftinginterpreters/not-translated-yet/compiling-expressions",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/compiling-expressions.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"closures",permalink:"/docs/Craftinginterpreters/not-translated-yet/closures"},next:{title:"contents",permalink:"/docs/Craftinginterpreters/not-translated-yet/contents"}},h={},l=[{value:"Single-Pass Compilation",id:"single-pass-compilation",level:2},{value:"Parsing Tokens",id:"parsing-tokens",level:2},{value:"Handling syntax errors",id:"handling-syntax-errors",level:3},{value:"Emitting Bytecode",id:"emitting-bytecode",level:2},{value:"Parsing Prefix Expressions",id:"parsing-prefix-expressions",level:2},{value:"Parsers for tokens",id:"parsers-for-tokens",level:3},{value:"Parentheses for grouping",id:"parentheses-for-grouping",level:3},{value:"Unary negation",id:"unary-negation",level:3},{value:"Parsing Infix Expressions",id:"parsing-infix-expressions",level:2},{value:"A Pratt Parser",id:"a-pratt-parser",level:2},{value:"Parsing with precedence",id:"parsing-with-precedence",level:3},{value:"Dumping Chunks",id:"dumping-chunks",level:2},{value:"Challenges",id:"challenges",level:2},{value:"Design Note: It&#39;s Just Parsing",id:"design-note-its-just-parsing",level:2}];function c(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"In the middle of the journey of our life I found myself within a dark woods\r\nwhere the straight way was lost."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.cite,{children:["Dante Alighieri, ",(0,t.jsx)(n.em,{children:"Inferno"})]})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This chapter is exciting for not one, not two, but ",(0,t.jsx)(n.em,{children:"three"})," reasons. First, it\r\nprovides the final segment of our VM's execution pipeline. Once in place, we can\r\nplumb the user's source code from scanning all the way through to executing it."]}),"\n",(0,t.jsx)(n.img,{src:"image/compiling-expressions/pipeline.png",alt:"Lowering the 'compiler' section of pipe between 'scanner' and 'VM'."}),"\n",(0,t.jsxs)(n.p,{children:["Second, we get to write an actual, honest-to-God ",(0,t.jsx)(n.em,{children:"compiler"}),". It parses source\r\ncode and outputs a low-level series of binary instructions. Sure, it's ",(0,t.jsx)(n.span,{name:"wirth",children:"bytecode"})," and not some chip's native instruction set, but\r\nit's way closer to the metal than jlox was. We're about to be real language\r\nhackers."]}),"\n",(0,t.jsxs)(n.aside,{name:"wirth",children:["\n",(0,t.jsx)(n.p,{children:"Bytecode was good enough for Niklaus Wirth, and no one questions his street\r\ncred."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.span,{name:"pratt",children:"Third"})," and finally, I get to show you one of my\r\nabsolute favorite algorithms: Vaughan Pratt's \"top-down operator precedence\r\nparsing\". It's the most elegant way I know to parse expressions. It gracefully\r\nhandles prefix operators, postfix, infix, ",(0,t.jsx)(n.em,{children:"mixfix"}),", any kind of ",(0,t.jsx)(n.em,{children:"-fix"})," you got.\r\nIt deals with precedence and associativity without breaking a sweat. I love it."]}),"\n",(0,t.jsxs)(n.aside,{name:"pratt",children:["\n",(0,t.jsx)(n.p,{children:"Pratt parsers are a sort of oral tradition in industry. No compiler or language\r\nbook I've read teaches them. Academia is very focused on generated parsers, and\r\nPratt's technique is for handwritten ones, so it gets overlooked."}),"\n",(0,t.jsx)(n.p,{children:"But in production compilers, where hand-rolled parsers are common, you'd be\r\nsurprised how many people know it. Ask where they learned it, and it's always,\r\n\"Oh, I worked on this compiler years ago and my coworker said they took it from\r\nthis old front end...\""}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"As usual, before we get to the fun stuff, we've got some preliminaries to work\r\nthrough. You have to eat your vegetables before you get dessert. First, let's\r\nditch that temporary scaffolding we wrote for testing the scanner and replace it\r\nwith something more useful."}),"\n",(0,t.jsx)(n.p,{children:"^code interpret-chunk (1 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:["We create a new empty chunk and pass it over to the compiler. The compiler will\r\ntake the user's program and fill up the chunk with bytecode. At least, that's\r\nwhat it will do if the program doesn't have any compile errors. If it does\r\nencounter an error, ",(0,t.jsx)(n.code,{children:"compile()"})," returns ",(0,t.jsx)(n.code,{children:"false"})," and we discard the unusable\r\nchunk."]}),"\n",(0,t.jsxs)(n.p,{children:["Otherwise, we send the completed chunk over to the VM to be executed. When the\r\nVM finishes, we free the chunk and we're done. As you can see, the signature to\r\n",(0,t.jsx)(n.code,{children:"compile()"})," is different now."]}),"\n",(0,t.jsx)(n.p,{children:"^code compile-h (2 before, 2 after)"}),"\n",(0,t.jsxs)(n.p,{children:["We pass in the chunk where the compiler will write the code, and then\r\n",(0,t.jsx)(n.code,{children:"compile()"})," returns whether or not compilation succeeded. We make the same\r\nchange to the signature in the implementation."]}),"\n",(0,t.jsx)(n.p,{children:"^code compile-signature (2 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:["That call to ",(0,t.jsx)(n.code,{children:"initScanner()"})," is the only line that survives this chapter. Rip\r\nout the temporary code we wrote to test the scanner and replace it with these\r\nthree lines:"]}),"\n",(0,t.jsx)(n.p,{children:"^code compile-chunk (1 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:["The call to ",(0,t.jsx)(n.code,{children:"advance()"})," \"primes the pump\" on the scanner. We'll see what it does\r\nsoon. Then we parse a single expression. We aren't going to do statements yet,\r\nso that's the only subset of the grammar we support. We'll revisit this when we\r\n",(0,t.jsx)(n.a,{href:"global-variables.html",children:"add statements in a few chapters"}),". After we compile the expression, we\r\nshould be at the end of the source code, so we check for the sentinel EOF token."]}),"\n",(0,t.jsxs)(n.p,{children:["We're going to spend the rest of the chapter making this function work,\r\nespecially that little ",(0,t.jsx)(n.code,{children:"expression()"})," call. Normally, we'd dive right into that\r\nfunction definition and work our way through the implementation from top to\r\nbottom."]}),"\n",(0,t.jsxs)(n.p,{children:["This chapter is ",(0,t.jsx)(n.span,{name:"blog",children:"different"}),". Pratt's parsing technique is\r\nremarkably simple once you have it all loaded in your head, but it's a little\r\ntricky to break into bite-sized pieces. It's recursive, of course, which is part\r\nof the problem. But it also relies on a big table of data. As we build up the\r\nalgorithm, that table grows additional columns."]}),"\n",(0,t.jsxs)(n.aside,{name:"blog",children:["\n",(0,t.jsxs)(n.p,{children:["If this chapter isn't clicking with you and you'd like another take on the\r\nconcepts, I wrote an article that teaches the same algorithm but using Java and\r\nan object-oriented style: ",(0,t.jsx)(n.a,{href:"http://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/",children:'"Pratt Parsing: Expression Parsing Made Easy"'}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"I don't want to revisit 40-something lines of code each time we extend the\r\ntable. So we're going to work our way into the core of the parser from the\r\noutside and cover all of the surrounding bits before we get to the juicy center.\r\nThis will require a little more patience and mental scratch space than most\r\nchapters, but it's the best I could do."}),"\n",(0,t.jsx)(n.h2,{id:"single-pass-compilation",children:"Single-Pass Compilation"}),"\n",(0,t.jsxs)(n.p,{children:["A compiler has roughly two jobs. It parses the user's source code to understand\r\nwhat it means. Then it takes that knowledge and outputs low-level instructions\r\nthat produce the same semantics. Many languages split those two roles into two\r\nseparate ",(0,t.jsx)(n.span,{name:"passes",children:"passes"})," in the implementation. A parser\r\nproduces an AST -- just like jlox does -- and then a code generator traverses\r\nthe AST and outputs target code."]}),"\n",(0,t.jsxs)(n.aside,{name:"passes",children:["\n",(0,t.jsxs)(n.p,{children:["In fact, most sophisticated optimizing compilers have a heck of a lot more than\r\ntwo passes. Determining not just ",(0,t.jsx)(n.em,{children:"what"}),' optimization passes to have, but how to\r\norder them to squeeze the most performance out of the compiler -- since the\r\noptimizations often interact in complex ways -- is somewhere between an "open\r\narea of research" and a "dark art".']}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"In clox, we're taking an old-school approach and merging these two passes into\r\none. Back in the day, language hackers did this because computers literally\r\ndidn't have enough memory to store an entire source file's AST. We're doing it\r\nbecause it keeps our compiler simpler, which is a real asset when programming in\r\nC."}),"\n",(0,t.jsxs)(n.p,{children:["Single-pass compilers like we're going to build don't work well for all\r\nlanguages. Since the compiler has only a peephole view into the user's program\r\nwhile generating code, the language must be designed such that you don't need\r\nmuch surrounding context to understand a piece of syntax. Fortunately, tiny,\r\ndynamically typed Lox is ",(0,t.jsx)(n.span,{name:"lox",children:"well-suited"})," to that."]}),"\n",(0,t.jsxs)(n.aside,{name:"lox",children:["\n",(0,t.jsx)(n.p,{children:"Not that this should come as much of a surprise. I did design the language\r\nspecifically for this book after all."}),"\n",(0,t.jsx)(n.img,{src:"image/compiling-expressions/keyhole.png",alt:"Peering through a keyhole at 'var x;'"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:'What this means in practical terms is that our "compiler" C module has\r\nfunctionality you\'ll recognize from jlox for parsing -- consuming tokens,\r\nmatching expected token types, etc. And it also has functions for code gen --\r\nemitting bytecode and adding constants to the destination chunk. (And it means\r\nI\'ll use "parsing" and "compiling" interchangeably throughout this and later\r\nchapters.)'}),"\n",(0,t.jsx)(n.p,{children:"We'll build the parsing and code generation halves first. Then we'll stitch them\r\ntogether with the code in the middle that uses Pratt's technique to parse Lox's\r\nparticular grammar and output the right bytecode."}),"\n",(0,t.jsx)(n.h2,{id:"parsing-tokens",children:"Parsing Tokens"}),"\n",(0,t.jsx)(n.p,{children:"First up, the front half of the compiler. This function's name should sound\r\nfamiliar."}),"\n",(0,t.jsx)(n.p,{children:"^code advance (1 before)"}),"\n",(0,t.jsxs)(n.p,{children:["Just like in jlox, it steps forward through the token stream. It asks the\r\nscanner for the next token and stores it for later use. Before doing that, it\r\ntakes the old ",(0,t.jsx)(n.code,{children:"current"})," token and stashes that in a ",(0,t.jsx)(n.code,{children:"previous"})," field. That will\r\ncome in handy later so that we can get at the lexeme after we match a token."]}),"\n",(0,t.jsxs)(n.p,{children:["The code to read the next token is wrapped in a loop. Remember, clox's scanner\r\ndoesn't report lexical errors. Instead, it creates special ",(0,t.jsx)(n.em,{children:"error tokens"})," and\r\nleaves it up to the parser to report them. We do that here."]}),"\n",(0,t.jsx)(n.p,{children:"We keep looping, reading tokens and reporting the errors, until we hit a\r\nnon-error one or reach the end. That way, the rest of the parser sees only valid\r\ntokens. The current and previous token are stored in this struct:"}),"\n",(0,t.jsx)(n.p,{children:"^code parser (1 before, 2 after)"}),"\n",(0,t.jsx)(n.p,{children:"Like we did in other modules, we have a single global variable of this struct\r\ntype so we don't need to pass the state around from function to function in the\r\ncompiler."}),"\n",(0,t.jsx)(n.h3,{id:"handling-syntax-errors",children:"Handling syntax errors"}),"\n",(0,t.jsx)(n.p,{children:"If the scanner hands us an error token, we need to actually tell the user. That\r\nhappens using this:"}),"\n",(0,t.jsx)(n.p,{children:"^code error-at-current"}),"\n",(0,t.jsxs)(n.p,{children:["We pull the location out of the current token in order to tell the user where\r\nthe error occurred and forward it to ",(0,t.jsx)(n.code,{children:"errorAt()"}),". More often, we'll report an\r\nerror at the location of the token we just consumed, so we give the shorter name\r\nto this other function:"]}),"\n",(0,t.jsx)(n.p,{children:"^code error"}),"\n",(0,t.jsx)(n.p,{children:"The actual work happens here:"}),"\n",(0,t.jsx)(n.p,{children:"^code error-at"}),"\n",(0,t.jsxs)(n.p,{children:["First, we print where the error occurred. We try to show the lexeme if it's\r\nhuman-readable. Then we print the error message itself. After that, we set this\r\n",(0,t.jsx)(n.code,{children:"hadError"})," flag. That records whether any errors occurred during compilation.\r\nThis field also lives in the parser struct."]}),"\n",(0,t.jsx)(n.p,{children:"^code had-error-field (1 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:["Earlier I said that ",(0,t.jsx)(n.code,{children:"compile()"})," should return ",(0,t.jsx)(n.code,{children:"false"})," if an error occurred. Now\r\nwe can make it do that."]}),"\n",(0,t.jsx)(n.p,{children:"^code return-had-error (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"I've got another flag to introduce for error handling. We want to avoid error\r\ncascades. If the user has a mistake in their code and the parser gets confused\r\nabout where it is in the grammar, we don't want it to spew out a whole pile of\r\nmeaningless knock-on errors after the first one."}),"\n",(0,t.jsxs)(n.p,{children:["We fixed that in jlox using panic mode error recovery. In the Java interpreter,\r\nwe threw an exception to unwind out of all of the parser code to a point where\r\nwe could skip tokens and resynchronize. We don't have ",(0,t.jsx)(n.span,{name:"setjmp",children:"exceptions"})," in C. Instead, we'll do a little smoke and\r\nmirrors. We add a flag to track whether we're currently in panic mode."]}),"\n",(0,t.jsxs)(n.aside,{name:"setjmp",children:["\n",(0,t.jsxs)(n.p,{children:["There is ",(0,t.jsx)(n.code,{children:"setjmp()"})," and ",(0,t.jsx)(n.code,{children:"longjmp()"}),", but I'd rather not go there. Those make it\r\ntoo easy to leak memory, forget to maintain invariants, or otherwise have a Very\r\nBad Day."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"^code panic-mode-field (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"When an error occurs, we set it."}),"\n",(0,t.jsx)(n.p,{children:"^code set-panic-mode (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"After that, we go ahead and keep compiling as normal as if the error never\r\noccurred. The bytecode will never get executed, so it's harmless to keep on\r\ntrucking. The trick is that while the panic mode flag is set, we simply suppress\r\nany other errors that get detected."}),"\n",(0,t.jsx)(n.p,{children:"^code check-panic-mode (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"There's a good chance the parser will go off in the weeds, but the user won't\r\nknow because the errors all get swallowed. Panic mode ends when the parser\r\nreaches a synchronization point. For Lox, we chose statement boundaries, so when\r\nwe later add those to our compiler, we'll clear the flag there."}),"\n",(0,t.jsx)(n.p,{children:"These new fields need to be initialized."}),"\n",(0,t.jsx)(n.p,{children:"^code init-parser-error (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"And to display the errors, we need a standard header."}),"\n",(0,t.jsx)(n.p,{children:"^code compiler-include-stdlib (1 before, 2 after)"}),"\n",(0,t.jsx)(n.p,{children:"There's one last parsing function, another old friend from jlox."}),"\n",(0,t.jsx)(n.p,{children:"^code consume"}),"\n",(0,t.jsxs)(n.p,{children:["It's similar to ",(0,t.jsx)(n.code,{children:"advance()"})," in that it reads the next token. But it also\r\nvalidates that the token has an expected type. If not, it reports an error. This\r\nfunction is the foundation of most syntax errors in the compiler."]}),"\n",(0,t.jsx)(n.p,{children:"OK, that's enough on the front end for now."}),"\n",(0,t.jsx)(n.h2,{id:"emitting-bytecode",children:"Emitting Bytecode"}),"\n",(0,t.jsx)(n.p,{children:"After we parse and understand a piece of the user's program, the next step is to\r\ntranslate that to a series of bytecode instructions. It starts with the easiest\r\npossible step: appending a single byte to the chunk."}),"\n",(0,t.jsx)(n.p,{children:"^code emit-byte"}),"\n",(0,t.jsx)(n.p,{children:"It's hard to believe great things will flow through such a simple function. It\r\nwrites the given byte, which may be an opcode or an operand to an instruction.\r\nIt sends in the previous token's line information so that runtime errors are\r\nassociated with that line."}),"\n",(0,t.jsxs)(n.p,{children:["The chunk that we're writing gets passed into ",(0,t.jsx)(n.code,{children:"compile()"}),", but it needs to make\r\nits way to ",(0,t.jsx)(n.code,{children:"emitByte()"}),". To do that, we rely on this intermediary function:"]}),"\n",(0,t.jsx)(n.p,{children:"^code compiling-chunk (1 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:['Right now, the chunk pointer is stored in a module-level variable like we store\r\nother global state. Later, when we start compiling user-defined functions, the\r\nnotion of "current chunk" gets more complicated. To avoid having to go back and\r\nchange a lot of code, I encapsulate that logic in the ',(0,t.jsx)(n.code,{children:"currentChunk()"})," function."]}),"\n",(0,t.jsx)(n.p,{children:"We initialize this new module variable before we write any bytecode:"}),"\n",(0,t.jsx)(n.p,{children:"^code init-compile-chunk (2 before, 2 after)"}),"\n",(0,t.jsx)(n.p,{children:"Then, at the very end, when we're done compiling the chunk, we wrap things up."}),"\n",(0,t.jsx)(n.p,{children:"^code finish-compile (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"That calls this:"}),"\n",(0,t.jsx)(n.p,{children:"^code end-compiler"}),"\n",(0,t.jsxs)(n.p,{children:["In this chapter, our VM deals only with expressions. When you run clox, it will\r\nparse, compile, and execute a single expression, then print the result. To print\r\nthat value, we are temporarily using the ",(0,t.jsx)(n.code,{children:"OP_RETURN"})," instruction. So we have the\r\ncompiler add one of those to the end of the chunk."]}),"\n",(0,t.jsx)(n.p,{children:"^code emit-return"}),"\n",(0,t.jsx)(n.p,{children:"While we're here in the back end we may as well make our lives easier."}),"\n",(0,t.jsx)(n.p,{children:"^code emit-bytes"}),"\n",(0,t.jsx)(n.p,{children:"Over time, we'll have enough cases where we need to write an opcode followed by\r\na one-byte operand that it's worth defining this convenience function."}),"\n",(0,t.jsx)(n.h2,{id:"parsing-prefix-expressions",children:"Parsing Prefix Expressions"}),"\n",(0,t.jsx)(n.p,{children:"We've assembled our parsing and code generation utility functions. The missing\r\npiece is the code in the middle that connects those together."}),"\n",(0,t.jsx)(n.img,{src:"image/compiling-expressions/mystery.png",alt:"Parsing functions on the left, bytecode emitting functions on the right. What goes in the middle?"}),"\n",(0,t.jsxs)(n.p,{children:["The only step in ",(0,t.jsx)(n.code,{children:"compile()"})," that we have left to implement is this function:"]}),"\n",(0,t.jsx)(n.p,{children:"^code expression"}),"\n",(0,t.jsx)(n.p,{children:"We aren't ready to implement every kind of expression in Lox yet. Heck, we don't\r\neven have Booleans. For this chapter, we're only going to worry about four:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Number literals: ",(0,t.jsx)(n.code,{children:"123"})]}),"\n",(0,t.jsxs)(n.li,{children:["Parentheses for grouping: ",(0,t.jsx)(n.code,{children:"(123)"})]}),"\n",(0,t.jsxs)(n.li,{children:["Unary negation: ",(0,t.jsx)(n.code,{children:"-123"})]}),"\n",(0,t.jsxs)(n.li,{children:["The Four Horsemen of the Arithmetic: ",(0,t.jsx)(n.code,{children:"+"}),", ",(0,t.jsx)(n.code,{children:"-"}),", ",(0,t.jsx)(n.code,{children:"*"}),", ",(0,t.jsx)(n.code,{children:"/"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"As we work through the functions to compile each of those kinds of expressions,\r\nwe'll also assemble the requirements for the table-driven parser that calls\r\nthem."}),"\n",(0,t.jsx)(n.h3,{id:"parsers-for-tokens",children:"Parsers for tokens"}),"\n",(0,t.jsx)(n.p,{children:"For now, let's focus on the Lox expressions that are each only a single token.\r\nIn this chapter, that's just number literals, but there will be more later. Here's\r\nhow we can compile them:"}),"\n",(0,t.jsxs)(n.p,{children:["We map each token type to a different kind of expression. We define a function\r\nfor each expression that outputs the appropriate bytecode. Then we build an\r\narray of function pointers. The indexes in the array correspond to the\r\n",(0,t.jsx)(n.code,{children:"TokenType"})," enum values, and the function at each index is the code to compile\r\nan expression of that token type."]}),"\n",(0,t.jsxs)(n.p,{children:["To compile number literals, we store a pointer to the following function at the\r\n",(0,t.jsx)(n.code,{children:"TOKEN_NUMBER"})," index in the array."]}),"\n",(0,t.jsx)(n.p,{children:"^code number"}),"\n",(0,t.jsxs)(n.p,{children:["We assume the token for the number literal has already been consumed and is\r\nstored in ",(0,t.jsx)(n.code,{children:"previous"}),". We take that lexeme and use the C standard library to\r\nconvert it to a double value. Then we generate the code to load that value using\r\nthis function:"]}),"\n",(0,t.jsx)(n.p,{children:"^code emit-constant"}),"\n",(0,t.jsxs)(n.p,{children:["First, we add the value to the constant table, then we emit an ",(0,t.jsx)(n.code,{children:"OP_CONSTANT"}),"\r\ninstruction that pushes it onto the stack at runtime. To insert an entry in the\r\nconstant table, we rely on:"]}),"\n",(0,t.jsx)(n.p,{children:"^code make-constant"}),"\n",(0,t.jsxs)(n.p,{children:["Most of the work happens in ",(0,t.jsx)(n.code,{children:"addConstant()"}),", which we defined back in an\r\n",(0,t.jsx)(n.a,{href:"chunks-of-bytecode.html",children:"earlier chapter"}),". That adds the given value to the end of the chunk's\r\nconstant table and returns its index. The new function's job is mostly to make\r\nsure we don't have too many constants. Since the ",(0,t.jsx)(n.code,{children:"OP_CONSTANT"})," instruction uses\r\na single byte for the index operand, we can store and load only up to ",(0,t.jsx)(n.span,{name:"256",children:"256"})," constants in a chunk."]}),"\n",(0,t.jsxs)(n.aside,{name:"256",children:["\n",(0,t.jsxs)(n.p,{children:["Yes, that limit is pretty low. If this were a full-sized language\r\nimplementation, we'd want to add another instruction like ",(0,t.jsx)(n.code,{children:"OP_CONSTANT_16"})," that\r\nstores the index as a two-byte operand so we could handle more constants when\r\nneeded."]}),"\n",(0,t.jsx)(n.p,{children:"The code to support that isn't particularly illuminating, so I omitted it from\r\nclox, but you'll want your VMs to scale to larger programs."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["That's basically all it takes. Provided there is some suitable code that\r\nconsumes a ",(0,t.jsx)(n.code,{children:"TOKEN_NUMBER"})," token, looks up ",(0,t.jsx)(n.code,{children:"number()"})," in the function pointer\r\narray, and then calls it, we can now compile number literals to bytecode."]}),"\n",(0,t.jsx)(n.h3,{id:"parentheses-for-grouping",children:"Parentheses for grouping"}),"\n",(0,t.jsxs)(n.p,{children:["Our as-yet-imaginary array of parsing function pointers would be great if every\r\nexpression was only a single token long. Alas, most are longer. However, many\r\nexpressions ",(0,t.jsx)(n.em,{children:"start"})," with a particular token. We call these ",(0,t.jsx)(n.em,{children:"prefix"})," expressions.\r\nFor example, when we're parsing an expression and the current token is ",(0,t.jsx)(n.code,{children:"("}),", we\r\nknow we must be looking at a parenthesized grouping expression."]}),"\n",(0,t.jsx)(n.p,{children:"It turns out our function pointer array handles those too. The parsing function\r\nfor an expression type can consume any additional tokens that it wants to, just\r\nlike in a regular recursive descent parser. Here's how parentheses work:"}),"\n",(0,t.jsx)(n.p,{children:"^code grouping"}),"\n",(0,t.jsxs)(n.p,{children:["Again, we assume the initial ",(0,t.jsx)(n.code,{children:"("})," has already been consumed. We ",(0,t.jsx)(n.span,{name:"recursive",children:"recursively"})," call back into ",(0,t.jsx)(n.code,{children:"expression()"})," to compile the\r\nexpression between the parentheses, then parse the closing ",(0,t.jsx)(n.code,{children:")"})," at the end."]}),"\n",(0,t.jsxs)(n.aside,{name:"recursive",children:["\n",(0,t.jsxs)(n.p,{children:["A Pratt parser isn't a recursive ",(0,t.jsx)(n.em,{children:"descent"})," parser, but it's still recursive.\r\nThat's to be expected since the grammar itself is recursive."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["As far as the back end is concerned, there's literally nothing to a grouping\r\nexpression. Its sole function is syntactic -- it lets you insert a\r\nlower-precedence expression where a higher precedence is expected. Thus, it has\r\nno runtime semantics on its own and therefore doesn't emit any bytecode. The\r\ninner call to ",(0,t.jsx)(n.code,{children:"expression()"})," takes care of generating bytecode for the\r\nexpression inside the parentheses."]}),"\n",(0,t.jsx)(n.h3,{id:"unary-negation",children:"Unary negation"}),"\n",(0,t.jsx)(n.p,{children:"Unary minus is also a prefix expression, so it works with our model too."}),"\n",(0,t.jsx)(n.p,{children:"^code unary"}),"\n",(0,t.jsxs)(n.p,{children:["The leading ",(0,t.jsx)(n.code,{children:"-"})," token has been consumed and is sitting in ",(0,t.jsx)(n.code,{children:"parser.previous"}),". We\r\ngrab the token type from that to note which unary operator we're dealing with.\r\nIt's unnecessary right now, but this will make more sense when we use this same\r\nfunction to compile the ",(0,t.jsx)(n.code,{children:"!"})," operator in ",(0,t.jsx)(n.a,{href:"types-of-values.html",children:"the next chapter"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["As in ",(0,t.jsx)(n.code,{children:"grouping()"}),", we recursively call ",(0,t.jsx)(n.code,{children:"expression()"})," to compile the operand.\r\nAfter that, we emit the bytecode to perform the negation. It might seem a little\r\nweird to write the negate instruction ",(0,t.jsx)(n.em,{children:"after"})," its operand's bytecode since the\r\n",(0,t.jsx)(n.code,{children:"-"})," appears on the left, but think about it in terms of order of execution:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"We evaluate the operand first which leaves its value on the stack."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Then we pop that value, negate it, and push the result."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["So the ",(0,t.jsx)(n.code,{children:"OP_NEGATE"})," instruction should be emitted ",(0,t.jsx)(n.span,{name:"line",children:"last"}),".\r\nThis is part of the compiler's job -- parsing the program in the order it\r\nappears in the source code and rearranging it into the order that execution\r\nhappens."]}),"\n",(0,t.jsxs)(n.aside,{name:"line",children:["\n",(0,t.jsxs)(n.p,{children:["Emitting the ",(0,t.jsx)(n.code,{children:"OP_NEGATE"})," instruction after the operands does mean that the\r\ncurrent token when the bytecode is written is ",(0,t.jsx)(n.em,{children:"not"})," the ",(0,t.jsx)(n.code,{children:"-"})," token. That mostly\r\ndoesn't matter, except that we use that token for the line number to associate\r\nwith that instruction."]}),"\n",(0,t.jsx)(n.p,{children:"This means if you have a multi-line negation expression, like:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"print -\r\n  true;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Then the runtime error will be reported on the wrong line. Here, it would show\r\nthe error on line 2, even though the ",(0,t.jsx)(n.code,{children:"-"})," is on line 1. A more robust approach\r\nwould be to store the token's line before compiling the operand and then pass\r\nthat into ",(0,t.jsx)(n.code,{children:"emitByte()"}),", but I wanted to keep things simple for the book."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["There is one problem with this code, though. The ",(0,t.jsx)(n.code,{children:"expression()"})," function it\r\ncalls will parse any expression for the operand, regardless of precedence. Once\r\nwe add binary operators and other syntax, that will do the wrong thing.\r\nConsider:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"-a.b + c;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Here, the operand to ",(0,t.jsx)(n.code,{children:"-"})," should be just the ",(0,t.jsx)(n.code,{children:"a.b"})," expression, not the entire\r\n",(0,t.jsx)(n.code,{children:"a.b + c"}),". But if ",(0,t.jsx)(n.code,{children:"unary()"})," calls ",(0,t.jsx)(n.code,{children:"expression()"}),", the latter will happily chew\r\nthrough all of the remaining code including the ",(0,t.jsx)(n.code,{children:"+"}),". It will erroneously treat\r\nthe ",(0,t.jsx)(n.code,{children:"-"})," as lower precedence than the ",(0,t.jsx)(n.code,{children:"+"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["When parsing the operand to unary ",(0,t.jsx)(n.code,{children:"-"}),", we need to compile only expressions at a\r\ncertain precedence level or higher. In jlox's recursive descent parser we\r\naccomplished that by calling into the parsing method for the lowest-precedence\r\nexpression we wanted to allow (in this case, ",(0,t.jsx)(n.code,{children:"call()"}),"). Each method for parsing\r\na specific expression also parsed any expressions of higher precedence too, so\r\nthat included the rest of the precedence table."]}),"\n",(0,t.jsxs)(n.p,{children:["The parsing functions like ",(0,t.jsx)(n.code,{children:"number()"})," and ",(0,t.jsx)(n.code,{children:"unary()"})," here in clox are different.\r\nEach only parses exactly one type of expression. They don't cascade to include\r\nhigher-precedence expression types too. We need a different solution, and it\r\nlooks like this:"]}),"\n",(0,t.jsx)(n.p,{children:"^code parse-precedence"}),"\n",(0,t.jsx)(n.p,{children:"This function -- once we implement it -- starts at the current token and parses\r\nany expression at the given precedence level or higher. We have some other setup\r\nto get through before we can write the body of this function, but you can\r\nprobably guess that it will use that table of parsing function pointers I've\r\nbeen talking about. For now, don't worry too much about how it works. In order\r\nto take the \"precedence\" as a parameter, we define it numerically."}),"\n",(0,t.jsx)(n.p,{children:"^code precedence (1 before, 2 after)"}),"\n",(0,t.jsxs)(n.p,{children:["These are all of Lox's precedence levels in order from lowest to highest. Since\r\nC implicitly gives successively larger numbers for enums, this means that\r\n",(0,t.jsx)(n.code,{children:"PREC_CALL"})," is numerically larger than ",(0,t.jsx)(n.code,{children:"PREC_UNARY"}),". For example, say the\r\ncompiler is sitting on a chunk of code like:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"-a.b + c\n"})}),"\n",(0,t.jsxs)(n.p,{children:["If we call ",(0,t.jsx)(n.code,{children:"parsePrecedence(PREC_ASSIGNMENT)"}),", then it will parse the entire\r\nexpression because ",(0,t.jsx)(n.code,{children:"+"})," has higher precedence than assignment. If instead we\r\ncall ",(0,t.jsx)(n.code,{children:"parsePrecedence(PREC_UNARY)"}),", it will compile the ",(0,t.jsx)(n.code,{children:"-a.b"})," and stop there.\r\nIt doesn't keep going through the ",(0,t.jsx)(n.code,{children:"+"})," because the addition has lower precedence\r\nthan unary operators."]}),"\n",(0,t.jsxs)(n.p,{children:["With this function in hand, it's a snap to fill in the missing body for\r\n",(0,t.jsx)(n.code,{children:"expression()"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"^code expression-body (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"We simply parse the lowest precedence level, which subsumes all of the\r\nhigher-precedence expressions too. Now, to compile the operand for a unary\r\nexpression, we call this new function and limit it to the appropriate level:"}),"\n",(0,t.jsx)(n.p,{children:"^code unary-operand (1 before, 2 after)"}),"\n",(0,t.jsxs)(n.p,{children:["We use the unary operator's own ",(0,t.jsx)(n.code,{children:"PREC_UNARY"})," precedence to permit ",(0,t.jsx)(n.span,{name:"useful",children:"nested"})," unary expressions like ",(0,t.jsx)(n.code,{children:"!!doubleNegative"}),". Since\r\nunary operators have pretty high precedence, that correctly excludes things like\r\nbinary operators. Speaking of which..."]}),"\n",(0,t.jsxs)(n.aside,{name:"useful",children:["\n",(0,t.jsx)(n.p,{children:"Not that nesting unary expressions is particularly useful in Lox. But other\r\nlanguages let you do it, so we do too."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"parsing-infix-expressions",children:"Parsing Infix Expressions"}),"\n",(0,t.jsxs)(n.p,{children:["Binary operators are different from the previous expressions because they are\r\n",(0,t.jsx)(n.em,{children:"infix"}),". With the other expressions, we know what we are parsing from the very\r\nfirst token. With infix expressions, we don't know we're in the middle of a\r\nbinary operator until ",(0,t.jsx)(n.em,{children:"after"})," we've parsed its left operand and then stumbled\r\nonto the operator token in the middle."]}),"\n",(0,t.jsx)(n.p,{children:"Here's an example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"1 + 2\n"})}),"\n",(0,t.jsx)(n.p,{children:"Let's walk through trying to compile it with what we know so far:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["We call ",(0,t.jsx)(n.code,{children:"expression()"}),". That in turn calls\r\n",(0,t.jsx)(n.code,{children:"parsePrecedence(PREC_ASSIGNMENT)"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["That function (once we implement it) sees the leading number token and\r\nrecognizes it is parsing a number literal. It hands off control to\r\n",(0,t.jsx)(n.code,{children:"number()"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"number()"})," creates a constant, emits an ",(0,t.jsx)(n.code,{children:"OP_CONSTANT"}),", and returns back to\r\n",(0,t.jsx)(n.code,{children:"parsePrecedence()"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Now what? The call to ",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," should consume the entire addition\r\nexpression, so it needs to keep going somehow. Fortunately, the parser is right\r\nwhere we need it to be. Now that we've compiled the leading number expression,\r\nthe next token is ",(0,t.jsx)(n.code,{children:"+"}),". That's the exact token that ",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," needs to\r\ndetect that we're in the middle of an infix expression and to realize that the\r\nexpression we already compiled is actually an operand to that."]}),"\n",(0,t.jsxs)(n.p,{children:["So this hypothetical array of function pointers doesn't just list functions to\r\nparse expressions that start with a given token. Instead, it's a ",(0,t.jsx)(n.em,{children:"table"})," of\r\nfunction pointers. One column associates prefix parser functions with token\r\ntypes. The second column associates infix parser functions with token types."]}),"\n",(0,t.jsxs)(n.p,{children:["The function we will use as the infix parser for ",(0,t.jsx)(n.code,{children:"TOKEN_PLUS"}),", ",(0,t.jsx)(n.code,{children:"TOKEN_MINUS"}),",\r\n",(0,t.jsx)(n.code,{children:"TOKEN_STAR"}),", and ",(0,t.jsx)(n.code,{children:"TOKEN_SLASH"})," is this:"]}),"\n",(0,t.jsx)(n.p,{children:"^code binary"}),"\n",(0,t.jsxs)(n.p,{children:["When a prefix parser function is called, the leading token has already been\r\nconsumed. An infix parser function is even more ",(0,t.jsx)(n.em,{children:"in medias res"})," -- the entire\r\nleft-hand operand expression has already been compiled and the subsequent infix\r\noperator consumed."]}),"\n",(0,t.jsx)(n.p,{children:"The fact that the left operand gets compiled first works out fine. It means at\r\nruntime, that code gets executed first. When it runs, the value it produces will\r\nend up on the stack. That's right where the infix operator is going to need it."}),"\n",(0,t.jsxs)(n.p,{children:["Then we come here to ",(0,t.jsx)(n.code,{children:"binary()"})," to handle the rest of the arithmetic operators.\r\nThis function compiles the right operand, much like how ",(0,t.jsx)(n.code,{children:"unary()"})," compiles its\r\nown trailing operand. Finally, it emits the bytecode instruction that performs\r\nthe binary operation."]}),"\n",(0,t.jsx)(n.p,{children:"When run, the VM will execute the left and right operand code, in that order,\r\nleaving their values on the stack. Then it executes the instruction for the\r\noperator. That pops the two values, computes the operation, and pushes the\r\nresult."}),"\n",(0,t.jsxs)(n.p,{children:["The code that probably caught your eye here is that ",(0,t.jsx)(n.code,{children:"getRule()"})," line. When we\r\nparse the right-hand operand, we again need to worry about precedence. Take an\r\nexpression like:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"2 * 3 + 4\n"})}),"\n",(0,t.jsxs)(n.p,{children:["When we parse the right operand of the ",(0,t.jsx)(n.code,{children:"*"})," expression, we need to just capture\r\n",(0,t.jsx)(n.code,{children:"3"}),", and not ",(0,t.jsx)(n.code,{children:"3 + 4"}),", because ",(0,t.jsx)(n.code,{children:"+"})," is lower precedence than ",(0,t.jsx)(n.code,{children:"*"}),". We could define\r\na separate function for each binary operator. Each would call\r\n",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," and pass in the correct precedence level for its operand."]}),"\n",(0,t.jsxs)(n.p,{children:["But that's kind of tedious. Each binary operator's right-hand operand precedence\r\nis one level ",(0,t.jsx)(n.span,{name:"higher",children:"higher"})," than its own. We can look that up\r\ndynamically with this ",(0,t.jsx)(n.code,{children:"getRule()"})," thing we'll get to soon. Using that, we call\r\n",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," with one level higher than this operator's level."]}),"\n",(0,t.jsxs)(n.aside,{name:"higher",children:["\n",(0,t.jsxs)(n.p,{children:["We use one ",(0,t.jsx)(n.em,{children:"higher"})," level of precedence for the right operand because the binary\r\noperators are left-associative. Given a series of the ",(0,t.jsx)(n.em,{children:"same"})," operator, like:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"1 + 2 + 3 + 4\n"})}),"\n",(0,t.jsx)(n.p,{children:"We want to parse it like:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"((1 + 2) + 3) + 4\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Thus, when parsing the right-hand operand to the first ",(0,t.jsx)(n.code,{children:"+"}),", we want to consume\r\nthe ",(0,t.jsx)(n.code,{children:"2"}),", but not the rest, so we use one level above ",(0,t.jsx)(n.code,{children:"+"}),"'s precedence. But if\r\nour operator was ",(0,t.jsx)(n.em,{children:"right"}),"-associative, this would be wrong. Given:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"a = b = c = d\n"})}),"\n",(0,t.jsx)(n.p,{children:"Since assignment is right-associative, we want to parse it as:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"a = (b = (c = d))\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To enable that, we would call ",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," with the ",(0,t.jsx)(n.em,{children:"same"})," precedence as\r\nthe current operator."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This way, we can use a single ",(0,t.jsx)(n.code,{children:"binary()"})," function for all binary operators even\r\nthough they have different precedences."]}),"\n",(0,t.jsx)(n.h2,{id:"a-pratt-parser",children:"A Pratt Parser"}),"\n",(0,t.jsxs)(n.p,{children:["We now have all of the pieces and parts of the compiler laid out. We have a\r\nfunction for each grammar production: ",(0,t.jsx)(n.code,{children:"number()"}),", ",(0,t.jsx)(n.code,{children:"grouping()"}),", ",(0,t.jsx)(n.code,{children:"unary()"}),", and\r\n",(0,t.jsx)(n.code,{children:"binary()"}),". We still need to implement ",(0,t.jsx)(n.code,{children:"parsePrecedence()"}),", and ",(0,t.jsx)(n.code,{children:"getRule()"}),". We\r\nalso know we need a table that, given a token type, lets us find"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"the function to compile a prefix expression starting with a token of that\r\ntype,"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"the function to compile an infix expression whose left operand is followed\r\nby a token of that type, and"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["the precedence of an ",(0,t.jsx)(n.span,{name:"prefix",children:"infix"})," expression that uses\r\nthat token as an operator."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.aside,{name:"prefix",children:["\n",(0,t.jsxs)(n.p,{children:["We don't need to track the precedence of the ",(0,t.jsx)(n.em,{children:"prefix"})," expression starting with a\r\ngiven token because all prefix operators in Lox have the same precedence."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We wrap these three properties in a little struct which represents a single row\r\nin the parser table."}),"\n",(0,t.jsx)(n.p,{children:"^code parse-rule (1 before, 2 after)"}),"\n",(0,t.jsxs)(n.p,{children:["That ParseFn type is a simple ",(0,t.jsx)(n.span,{name:"typedef",children:"typedef"})," for a function\r\ntype that takes no arguments and returns nothing."]}),"\n",(0,t.jsxs)(n.aside,{name:"typedef",className:"bottom",children:["\n",(0,t.jsx)(n.p,{children:'C\'s syntax for function pointer types is so bad that I always hide it behind a\r\ntypedef. I understand the intent behind the syntax -- the whole "declaration\r\nreflects use" thing -- but I think it was a failed syntactic experiment.'}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"^code parse-fn-type (1 before, 2 after)"}),"\n",(0,t.jsx)(n.p,{children:"The table that drives our whole parser is an array of ParseRules. We've been\r\ntalking about it forever, and finally you get to see it."}),"\n",(0,t.jsx)(n.p,{children:"^code rules"}),"\n",(0,t.jsxs)(n.aside,{name:"big",children:["\n",(0,t.jsx)(n.p,{children:"See what I mean about not wanting to revisit the table each time we needed a new\r\ncolumn? It's a beast."}),"\n",(0,t.jsxs)(n.p,{children:["If you haven't seen the ",(0,t.jsx)(n.code,{children:"[TOKEN_DOT] = "})," syntax in a C array literal, that is\r\nC99's designated initializer syntax. It's clearer than having to count array\r\nindexes by hand."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["You can see how ",(0,t.jsx)(n.code,{children:"grouping"})," and ",(0,t.jsx)(n.code,{children:"unary"})," are slotted into the prefix parser column\r\nfor their respective token types. In the next column, ",(0,t.jsx)(n.code,{children:"binary"})," is wired up to\r\nthe four arithmetic infix operators. Those infix operators also have their\r\nprecedences set in the last column."]}),"\n",(0,t.jsxs)(n.p,{children:["Aside from those, the rest of the table is full of ",(0,t.jsx)(n.code,{children:"NULL"})," and ",(0,t.jsx)(n.code,{children:"PREC_NONE"}),". Most\r\nof those empty cells are because there is no expression associated with those\r\ntokens. You can't start an expression with, say, ",(0,t.jsx)(n.code,{children:"else"}),", and ",(0,t.jsx)(n.code,{children:"}"})," would make for\r\na pretty confusing infix operator."]}),"\n",(0,t.jsx)(n.p,{children:"But, also, we haven't filled in the entire grammar yet. In later chapters, as we\r\nadd new expression types, some of these slots will get functions in them. One of\r\nthe things I like about this approach to parsing is that it makes it very easy\r\nto see which tokens are in use by the grammar and which are available."}),"\n",(0,t.jsxs)(n.p,{children:["Now that we have the table, we are finally ready to write the code that uses it.\r\nThis is where our Pratt parser comes to life. The easiest function to define is\r\n",(0,t.jsx)(n.code,{children:"getRule()"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"^code get-rule"}),"\n",(0,t.jsxs)(n.p,{children:["It simply returns the rule at the given index. It's called by ",(0,t.jsx)(n.code,{children:"binary()"})," to look\r\nup the precedence of the current operator. This function exists solely to handle\r\na declaration cycle in the C code. ",(0,t.jsx)(n.code,{children:"binary()"})," is defined ",(0,t.jsx)(n.em,{children:"before"})," the rules\r\ntable so that the table can store a pointer to it. That means the body of\r\n",(0,t.jsx)(n.code,{children:"binary()"})," cannot access the table directly."]}),"\n",(0,t.jsxs)(n.p,{children:["Instead, we wrap the lookup in a function. That lets us forward declare\r\n",(0,t.jsx)(n.code,{children:"getRule()"})," before the definition of ",(0,t.jsx)(n.code,{children:"binary()"}),", and ",(0,t.jsx)(n.span,{name:"forward",children:"then"})," ",(0,t.jsx)(n.em,{children:"define"})," ",(0,t.jsx)(n.code,{children:"getRule()"})," after the table. We'll need a\r\ncouple of other forward declarations to handle the fact that our grammar is\r\nrecursive, so let's get them all out of the way."]}),"\n",(0,t.jsxs)(n.aside,{name:"forward",children:["\n",(0,t.jsx)(n.p,{children:"This is what happens when you write your VM in a language that was designed to\r\nbe compiled on a PDP-11."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"^code forward-declarations (2 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"If you're following along and implementing clox yourself, pay close attention to\r\nthe little annotations that tell you where to put these code snippets. Don't\r\nworry, though, if you get it wrong, the C compiler will be happy to tell you."}),"\n",(0,t.jsx)(n.h3,{id:"parsing-with-precedence",children:"Parsing with precedence"}),"\n",(0,t.jsxs)(n.p,{children:["Now we're getting to the fun stuff. The maestro that orchestrates all of the\r\nparsing functions we've defined is ",(0,t.jsx)(n.code,{children:"parsePrecedence()"}),". Let's start with parsing\r\nprefix expressions."]}),"\n",(0,t.jsx)(n.p,{children:"^code precedence-body (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"We read the next token and look up the corresponding ParseRule. If there is no\r\nprefix parser, then the token must be a syntax error. We report that and return\r\nto the caller."}),"\n",(0,t.jsx)(n.p,{children:"Otherwise, we call that prefix parse function and let it do its thing. That\r\nprefix parser compiles the rest of the prefix expression, consuming any other\r\ntokens it needs, and returns back here. Infix expressions are where it gets\r\ninteresting since precedence comes into play. The implementation is remarkably\r\nsimple."}),"\n",(0,t.jsx)(n.p,{children:"^code infix (1 before, 1 after)"}),"\n",(0,t.jsxs)(n.p,{children:["That's the whole thing. Really. Here's how the entire function works: At the\r\nbeginning of ",(0,t.jsx)(n.code,{children:"parsePrecedence()"}),", we look up a prefix parser for the current\r\ntoken. The first token is ",(0,t.jsx)(n.em,{children:"always"})," going to belong to some kind of prefix\r\nexpression, by definition. It may turn out to be nested as an operand inside one\r\nor more infix expressions, but as you read the code from left to right, the\r\nfirst token you hit always belongs to a prefix expression."]}),"\n",(0,t.jsxs)(n.p,{children:["After parsing that, which may consume more tokens, the prefix expression is\r\ndone. Now we look for an infix parser for the next token. If we find one, it\r\nmeans the prefix expression we already compiled might be an operand for it. But\r\nonly if the call to ",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," has a ",(0,t.jsx)(n.code,{children:"precedence"})," that is low enough to\r\npermit that infix operator."]}),"\n",(0,t.jsxs)(n.p,{children:["If the next token is too low precedence, or isn't an infix operator at all,\r\nwe're done. We've parsed as much expression as we can. Otherwise, we consume the\r\noperator and hand off control to the infix parser we found. It consumes whatever\r\nother tokens it needs (usually the right operand) and returns back to\r\n",(0,t.jsx)(n.code,{children:"parsePrecedence()"}),". Then we loop back around and see if the ",(0,t.jsx)(n.em,{children:"next"})," token is\r\nalso a valid infix operator that can take the entire preceding expression as its\r\noperand. We keep looping like that, crunching through infix operators and their\r\noperands until we hit a token that isn't an infix operator or is too low\r\nprecedence and stop."]}),"\n",(0,t.jsx)(n.p,{children:"That's a lot of prose, but if you really want to mind meld with Vaughan Pratt\r\nand fully understand the algorithm, step through the parser in your debugger as\r\nit works through some expressions. Maybe a picture will help. There's only a\r\nhandful of functions, but they are marvelously intertwined:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.span,{name:"connections"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:"image/compiling-expressions/connections.png",alt:"The various parsing\nfunctions and how they call each other."})}),"\n",(0,t.jsxs)(n.aside,{name:"connections",children:["\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.img,{src:"image/compiling-expressions/calls.png",alt:"A solid arrow.",className:"arrow"})," arrow connects a function to another function it directly\r\ncalls. The ",(0,t.jsx)(n.img,{src:"image/compiling-expressions/points-to.png",alt:"An open\narrow.",className:"arrow"})," arrow shows the table's pointers to the parsing\r\nfunctions."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Later, we'll need to tweak the code in this chapter to handle assignment. But,\r\notherwise, what we wrote covers all of our expression compiling needs for the\r\nrest of the book. We'll plug additional parsing functions into the table when we\r\nadd new kinds of expressions, but ",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," is complete."]}),"\n",(0,t.jsx)(n.h2,{id:"dumping-chunks",children:"Dumping Chunks"}),"\n",(0,t.jsx)(n.p,{children:"While we're here in the core of our compiler, we should put in some\r\ninstrumentation. To help debug the generated bytecode, we'll add support for\r\ndumping the chunk once the compiler finishes. We had some temporary logging\r\nearlier when we hand-authored the chunk. Now we'll put in some real code so that\r\nwe can enable it whenever we want."}),"\n",(0,t.jsx)(n.p,{children:"Since this isn't for end users, we hide it behind a flag."}),"\n",(0,t.jsx)(n.p,{children:"^code define-debug-print-code (2 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:'When that flag is defined, we use our existing "debug" module to print out the\r\nchunk\'s bytecode.'}),"\n",(0,t.jsx)(n.p,{children:"^code dump-chunk (1 before, 1 after)"}),"\n",(0,t.jsx)(n.p,{children:"We do this only if the code was free of errors. After a syntax error, the\r\ncompiler keeps on going but it's in kind of a weird state and might produce\r\nbroken code. That's harmless because it won't get executed, but we'll just\r\nconfuse ourselves if we try to read it."}),"\n",(0,t.jsxs)(n.p,{children:["Finally, to access ",(0,t.jsx)(n.code,{children:"disassembleChunk()"}),", we need to include its header."]}),"\n",(0,t.jsx)(n.p,{children:"^code include-debug (1 before, 2 after)"}),"\n",(0,t.jsxs)(n.p,{children:["We made it! This was the last major section to install in our VM's compilation\r\nand execution pipeline. Our interpreter doesn't ",(0,t.jsx)(n.em,{children:"look"})," like much, but inside it\r\nis scanning, parsing, compiling to bytecode, and executing."]}),"\n",(0,t.jsx)(n.p,{children:"Fire up the VM and type in an expression. If we did everything right, it should\r\ncalculate and print the result. We now have a very over-engineered arithmetic\r\ncalculator. We have a lot of language features to add in the coming chapters,\r\nbut the foundation is in place."}),"\n",(0,t.jsxs)(n.div,{className:"challenges",children:["\n",(0,t.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["To really understand the parser, you need to see how execution threads\r\nthrough the interesting parsing functions -- ",(0,t.jsx)(n.code,{children:"parsePrecedence()"})," and the\r\nparser functions stored in the table. Take this (strange) expression:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-lox",children:"(-1 + 2) * 3 - -4\n"})}),"\n",(0,t.jsx)(n.p,{children:"Write a trace of how those functions are called. Show the order they are\r\ncalled, which calls which, and the arguments passed to them."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The ParseRule row for ",(0,t.jsx)(n.code,{children:"TOKEN_MINUS"})," has both prefix and infix function\r\npointers. That's because ",(0,t.jsx)(n.code,{children:"-"})," is both a prefix operator (unary negation) and\r\nan infix one (subtraction)."]}),"\n",(0,t.jsx)(n.p,{children:"In the full Lox language, what other tokens can be used in both prefix and\r\ninfix positions? What about in C or in another language of your choice?"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:['You might be wondering about complex "mixfix" expressions that have more\r\nthan two operands separated by tokens. C\'s conditional or "ternary"\r\noperator, ',(0,t.jsx)(n.code,{children:"?:"}),", is a widely known one."]}),"\n",(0,t.jsx)(n.p,{children:"Add support for that operator to the compiler. You don't have to generate\r\nany bytecode, just show how you would hook it up to the parser and handle\r\nthe operands."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.div,{className:"design-note",children:["\n",(0,t.jsx)(n.h2,{id:"design-note-its-just-parsing",children:"Design Note: It's Just Parsing"}),"\n",(0,t.jsxs)(n.p,{children:["I'm going to make a claim here that will be unpopular with some compiler and\r\nlanguage people. It's OK if you don't agree. Personally, I learn more from\r\nstrongly stated opinions that I disagree with than I do from several pages of\r\nqualifiers and equivocation. My claim is that ",(0,t.jsx)(n.em,{children:"parsing doesn't matter"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["Over the years, many programming language people, especially in academia, have\r\ngotten ",(0,t.jsx)(n.em,{children:"really"})," into parsers and taken them very seriously. Initially, it was\r\nthe compiler folks who got into ",(0,t.jsx)(n.span,{name:"yacc",children:"compiler-compilers"}),",\r\nLALR, and other stuff like that. The first half of the dragon book is a long\r\nlove letter to the wonders of parser generators."]}),"\n",(0,t.jsxs)(n.aside,{name:"yacc",children:["\n",(0,t.jsx)(n.p,{children:'All of us suffer from the vice of "when all you have is a hammer, everything\r\nlooks like a nail", but perhaps none so visibly as compiler people. You wouldn\'t\r\nbelieve the breadth of software problems that miraculously seem to require a new\r\nlittle language in their solution as soon as you ask a compiler hacker for help.'}),"\n",(0,t.jsx)(n.p,{children:'Yacc and other compiler-compilers are the most delightfully recursive example.\r\n"Wow, writing compilers is a chore. I know, let\'s write a compiler to write our\r\ncompiler for us."'}),"\n",(0,t.jsx)(n.p,{children:"For the record, I don't claim immunity to this affliction."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Later, the functional programming folks got into parser combinators, packrat\r\nparsers, and other sorts of things. Because, obviously, if you give a functional\r\nprogrammer a problem, the first thing they'll do is whip out a pocketful of\r\nhigher-order functions."}),"\n",(0,t.jsx)(n.p,{children:"Over in math and algorithm analysis land, there is a long legacy of research\r\ninto proving time and memory usage for various parsing techniques, transforming\r\nparsing problems into other problems and back, and assigning complexity classes\r\nto different grammars."}),"\n",(0,t.jsx)(n.p,{children:"At one level, this stuff is important. If you're implementing a language, you\r\nwant some assurance that your parser won't go exponential and take 7,000 years\r\nto parse a weird edge case in the grammar. Parser theory gives you that bound.\r\nAs an intellectual exercise, learning about parsing techniques is also fun and\r\nrewarding."}),"\n",(0,t.jsxs)(n.p,{children:["But if your goal is just to implement a language and get it in front of users,\r\nalmost all of that stuff doesn't matter. It's really easy to get worked up by\r\nthe enthusiasm of the people who ",(0,t.jsx)(n.em,{children:"are"})," into it and think that your front end\r\n",(0,t.jsx)(n.em,{children:"needs"})," some whiz-bang generated combinator-parser-factory thing. I've seen\r\npeople burn tons of time writing and rewriting their parser using whatever\r\ntoday's hot library or technique is."]}),"\n",(0,t.jsx)(n.p,{children:"That's time that doesn't add any value to your user's life. If you're just\r\ntrying to get your parser done, pick one of the bog-standard techniques, use it,\r\nand move on. Recursive descent, Pratt parsing, and the popular parser generators\r\nlike ANTLR or Bison are all fine."}),"\n",(0,t.jsx)(n.p,{children:"Take the extra time you saved not rewriting your parsing code and spend it\r\nimproving the compile error messages your compiler shows users. Good error\r\nhandling and reporting is more valuable to users than almost anything else you\r\ncan put time into in the front end."}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var t=r(6540);const s={},i=t.createContext(s);function o(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);