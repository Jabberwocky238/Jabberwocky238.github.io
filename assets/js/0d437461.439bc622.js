"use strict";(self.webpackChunkmybooks=self.webpackChunkmybooks||[]).push([[8514],{3641:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var s=t(4848),r=t(8453);const i={},a=void 0,o={id:"Craftinginterpreters/not-translated-yet/methods-and-initializers",title:"methods-and-initializers",description:"When you are on the dancefloor, there is nothing to do but dance.",source:"@site/docs/Craftinginterpreters/not-translated-yet/methods-and-initializers.md",sourceDirName:"Craftinginterpreters/not-translated-yet",slug:"/Craftinginterpreters/not-translated-yet/methods-and-initializers",permalink:"/docs/Craftinginterpreters/not-translated-yet/methods-and-initializers",draft:!1,unlisted:!1,editUrl:"https://github.com/jabberwocky238/jabberwocky238.github.io/docs/Craftinginterpreters/not-translated-yet/methods-and-initializers.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"local-variables",permalink:"/docs/Craftinginterpreters/not-translated-yet/local-variables"},next:{title:"optimization",permalink:"/docs/Craftinginterpreters/not-translated-yet/optimization"}},h={},l=[{value:"Method Declarations",id:"method-declarations",level:2},{value:"Representing methods",id:"representing-methods",level:3},{value:"Compiling method declarations",id:"compiling-method-declarations",level:3},{value:"Executing method declarations",id:"executing-method-declarations",level:3},{value:"Method References",id:"method-references",level:2},{value:"Bound methods",id:"bound-methods",level:3},{value:"Accessing methods",id:"accessing-methods",level:3},{value:"Calling methods",id:"calling-methods",level:3},{value:"This",id:"this",level:2},{value:"Misusing this",id:"misusing-this",level:3},{value:"Instance Initializers",id:"instance-initializers",level:2},{value:"Invoking initializers",id:"invoking-initializers",level:3},{value:"Initializer return values",id:"initializer-return-values",level:3},{value:"Incorrect returns in initializers",id:"incorrect-returns-in-initializers",level:3},{value:"Optimized Invocations",id:"optimized-invocations",level:2},{value:"Invoking fields",id:"invoking-fields",level:3},{value:"Challenges",id:"challenges",level:2},{value:"Design Note: Novelty Budget",id:"design-note-novelty-budget",level:2}];function c(e){const n={a:"a",aside:"aside",blockquote:"blockquote",cite:"cite",code:"code",div:"div",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"When you are on the dancefloor, there is nothing to do but dance."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.cite,{children:["Umberto Eco, ",(0,s.jsx)(n.em,{children:"The Mysterious Flame of Queen Loana"})]})}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"It is time for our virtual machine to bring its nascent objects to life with\r\nbehavior. That means methods and method calls. And, since they are a special\r\nkind of method, initializers too."}),"\n",(0,s.jsx)(n.p,{children:"All of this is familiar territory from our previous jlox interpreter. What's new\r\nin this second trip is an important optimization we'll implement to make method\r\ncalls over seven times faster than our baseline performance. But before we get\r\nto that fun, we gotta get the basic stuff working."}),"\n",(0,s.jsx)(n.h2,{id:"method-declarations",children:"Method Declarations"}),"\n",(0,s.jsx)(n.p,{children:"We can't optimize method calls before we have method calls, and we can't call\r\nmethods without having methods to call, so we'll start with declarations."}),"\n",(0,s.jsx)(n.h3,{id:"representing-methods",children:"Representing methods"}),"\n",(0,s.jsx)(n.p,{children:"We usually start in the compiler, but let's knock the object model out first\r\nthis time. The runtime representation for methods in clox is similar to that of\r\njlox. Each class stores a hash table of methods. Keys are method names, and each\r\nvalue is an ObjClosure for the body of the method."}),"\n",(0,s.jsx)(n.p,{children:"^code class-methods (3 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"A brand new class begins with an empty method table."}),"\n",(0,s.jsx)(n.p,{children:"^code init-methods (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"The ObjClass struct owns the memory for this table, so when the memory manager\r\ndeallocates a class, the table should be freed too."}),"\n",(0,s.jsx)(n.p,{children:"^code free-methods (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"Speaking of memory managers, the GC needs to trace through classes into the\r\nmethod table. If a class is still reachable (likely through some instance),\r\nthen all of its methods certainly need to stick around too."}),"\n",(0,s.jsx)(n.p,{children:"^code mark-methods (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["We use the existing ",(0,s.jsx)(n.code,{children:"markTable()"})," function, which traces through the key string\r\nand value in each table entry."]}),"\n",(0,s.jsx)(n.p,{children:"Storing a class's methods is pretty familiar coming from jlox. The different\r\npart is how that table gets populated. Our previous interpreter had access to\r\nthe entire AST node for the class declaration and all of the methods it\r\ncontained. At runtime, the interpreter simply walked that list of declarations."}),"\n",(0,s.jsx)(n.p,{children:"Now every piece of information the compiler wants to shunt over to the runtime\r\nhas to squeeze through the interface of a flat series of bytecode instructions.\r\nHow do we take a class declaration, which can contain an arbitrarily large set\r\nof methods, and represent it as bytecode? Let's hop over to the compiler and\r\nfind out."}),"\n",(0,s.jsx)(n.h3,{id:"compiling-method-declarations",children:"Compiling method declarations"}),"\n",(0,s.jsx)(n.p,{children:"The last chapter left us with a compiler that parses classes but allows only an\r\nempty body. Now we insert a little code to compile a series of method\r\ndeclarations between the braces."}),"\n",(0,s.jsx)(n.p,{children:"^code class-body (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"Lox doesn't have field declarations, so anything before the closing brace at the\r\nend of the class body must be a method. We stop compiling methods when we hit\r\nthat final curly or if we reach the end of the file. The latter check ensures\r\nour compiler doesn't get stuck in an infinite loop if the user accidentally\r\nforgets the closing brace."}),"\n",(0,s.jsxs)(n.p,{children:["The tricky part with compiling a class declaration is that a class may declare\r\nany number of methods. Somehow the runtime needs to look up and bind all of\r\nthem. That would be a lot to pack into a single ",(0,s.jsx)(n.code,{children:"OP_CLASS"})," instruction. Instead,\r\nthe bytecode we generate for a class declaration will split the process into a\r\n",(0,s.jsx)(n.span,{name:"series",children:(0,s.jsx)(n.em,{children:"series"})})," of instructions. The compiler already emits\r\nan ",(0,s.jsx)(n.code,{children:"OP_CLASS"})," instruction that creates a new empty ObjClass object. Then it\r\nemits instructions to store the class in a variable with its name."]}),"\n",(0,s.jsxs)(n.aside,{name:"series",children:["\n",(0,s.jsxs)(n.p,{children:["We did something similar for closures. The ",(0,s.jsx)(n.code,{children:"OP_CLOSURE"})," instruction needs to\r\nknow the type and index for each captured upvalue. We encoded that using a\r\nseries of pseudo-instructions following the main ",(0,s.jsx)(n.code,{children:"OP_CLOSURE"})," instruction --\r\nbasically a variable number of operands. The VM processes all of those extra\r\nbytes immediately when interpreting the ",(0,s.jsx)(n.code,{children:"OP_CLOSURE"})," instruction."]}),"\n",(0,s.jsx)(n.p,{children:"Here our approach is a little different because from the VM's perspective, each\r\ninstruction to define a method is a separate stand-alone operation. Either\r\napproach would work. A variable-sized pseudo-instruction is possibly marginally\r\nfaster, but class declarations are rarely in hot loops, so it doesn't matter\r\nmuch."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Now, for each method declaration, we emit a new ",(0,s.jsx)(n.code,{children:"OP_METHOD"})," instruction that\r\nadds a single method to that class. When all of the ",(0,s.jsx)(n.code,{children:"OP_METHOD"})," instructions\r\nhave executed, we're left with a fully formed class. While the user sees a class\r\ndeclaration as a single atomic operation, the VM implements it as a series of\r\nmutations."]}),"\n",(0,s.jsx)(n.p,{children:"To define a new method, the VM needs three things:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The name of the method."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The closure for the method body."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The class to bind the method to."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"We'll incrementally write the compiler code to see how those all get through to\r\nthe runtime, starting here:"}),"\n",(0,s.jsx)(n.p,{children:"^code method"}),"\n",(0,s.jsxs)(n.p,{children:["Like ",(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"})," and other instructions that need names at runtime, the\r\ncompiler adds the method name token's lexeme to the constant table, getting back\r\na table index. Then we emit an ",(0,s.jsx)(n.code,{children:"OP_METHOD"})," instruction with that index as the\r\noperand. That's the name. Next is the method body:"]}),"\n",(0,s.jsx)(n.p,{children:"^code method-body (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["We use the same ",(0,s.jsx)(n.code,{children:"function()"})," helper that we wrote for compiling function\r\ndeclarations. That utility function compiles the subsequent parameter list and\r\nfunction body. Then it emits the code to create an ObjClosure and leave it on\r\ntop of the stack. At runtime, the VM will find the closure there."]}),"\n",(0,s.jsxs)(n.p,{children:["Last is the class to bind the method to. Where can the VM find that?\r\nUnfortunately, by the time we reach the ",(0,s.jsx)(n.code,{children:"OP_METHOD"})," instruction, we don't know\r\nwhere it is. It ",(0,s.jsx)(n.span,{name:"global",children:"could"})," be on the stack, if the user\r\ndeclared the class in a local scope. But a top-level class declaration ends up\r\nwith the ObjClass in the global variable table."]}),"\n",(0,s.jsxs)(n.aside,{name:"global",children:["\n",(0,s.jsx)(n.p,{children:"If Lox supported declaring classes only at the top level, the VM could assume\r\nthat any class could be found by looking it up directly from the global\r\nvariable table. Alas, because we support local classes, we need to handle that\r\ncase too."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Fear not. The compiler does know the ",(0,s.jsx)(n.em,{children:"name"})," of the class. We can capture it\r\nright after we consume its token."]}),"\n",(0,s.jsx)(n.p,{children:"^code class-name (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"And we know that no other declaration with that name could possibly shadow the\r\nclass. So we do the easy fix. Before we start binding methods, we emit whatever\r\ncode is necessary to load the class back on top of the stack."}),"\n",(0,s.jsx)(n.p,{children:"^code load-class (2 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["Right before compiling the class body, we ",(0,s.jsx)(n.span,{name:"load",children:"call"}),"\r\n",(0,s.jsx)(n.code,{children:"namedVariable()"}),". That helper function generates code to load a variable with\r\nthe given name onto the stack. Then we compile the methods."]}),"\n",(0,s.jsxs)(n.aside,{name:"load",children:["\n",(0,s.jsxs)(n.p,{children:["The preceding call to ",(0,s.jsx)(n.code,{children:"defineVariable()"})," pops the class, so it seems silly to\r\ncall ",(0,s.jsx)(n.code,{children:"namedVariable()"})," to load it right back onto the stack. Why not simply\r\nleave it on the stack in the first place? We could, but in the ",(0,s.jsx)(n.a,{href:"superclasses.html",children:"next\r\nchapter"})," we will insert code between these two calls to support\r\ninheritance. At that point, it will be simpler if the class isn't sitting around\r\non the stack."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["This means that when we execute each ",(0,s.jsx)(n.code,{children:"OP_METHOD"})," instruction, the stack has the\r\nmethod's closure on top with the class right under it. Once we've reached the\r\nend of the methods, we no longer need the class and tell the VM to pop it off\r\nthe stack."]}),"\n",(0,s.jsx)(n.p,{children:"^code pop-class (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"Putting all of that together, here is an example class declaration to throw at\r\nthe compiler:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"class Brunch {\r\n  bacon() {}\r\n  eggs() {}\r\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"Given that, here is what the compiler generates and how those instructions\r\naffect the stack at runtime:"}),"\n",(0,s.jsx)(n.img,{src:"image/methods-and-initializers/method-instructions.png",alt:"The series of bytecode instructions for a class declaration with two methods."}),"\n",(0,s.jsxs)(n.p,{children:["All that remains for us is to implement the runtime for that new ",(0,s.jsx)(n.code,{children:"OP_METHOD"}),"\r\ninstruction."]}),"\n",(0,s.jsx)(n.h3,{id:"executing-method-declarations",children:"Executing method declarations"}),"\n",(0,s.jsx)(n.p,{children:"First we define the opcode."}),"\n",(0,s.jsx)(n.p,{children:"^code method-op (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"We disassemble it like other instructions that have string constant operands."}),"\n",(0,s.jsx)(n.p,{children:"^code disassemble-method (2 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"And over in the interpreter, we add a new case too."}),"\n",(0,s.jsx)(n.p,{children:"^code interpret-method (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"There, we read the method name from the constant table and pass it here:"}),"\n",(0,s.jsx)(n.p,{children:"^code define-method"}),"\n",(0,s.jsx)(n.p,{children:"The method closure is on top of the stack, above the class it will be bound to.\r\nWe read those two stack slots and store the closure in the class's method table.\r\nThen we pop the closure since we're done with it."}),"\n",(0,s.jsxs)(n.p,{children:["Note that we don't do any runtime type checking on the closure or class object.\r\nThat ",(0,s.jsx)(n.code,{children:"AS_CLASS()"})," call is safe because the compiler itself generated the code\r\nthat causes the class to be in that stack slot. The VM ",(0,s.jsx)(n.span,{name:"verify",children:"trusts"})," its own compiler."]}),"\n",(0,s.jsxs)(n.aside,{name:"verify",children:["\n",(0,s.jsxs)(n.p,{children:["The VM trusts that the instructions it executes are valid because the ",(0,s.jsx)(n.em,{children:"only"})," way\r\nto get code to the bytecode interpreter is by going through clox's own compiler.\r\nMany bytecode VMs, like the JVM and CPython, support executing bytecode that has\r\nbeen compiled separately. That leads to a different security story. Maliciously\r\ncrafted bytecode could crash the VM or worse."]}),"\n",(0,s.jsx)(n.p,{children:"To prevent that, the JVM does a bytecode verification pass before it executes\r\nany loaded code. CPython says it's up to the user to ensure any bytecode they\r\nrun is safe."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["After the series of ",(0,s.jsx)(n.code,{children:"OP_METHOD"})," instructions is done and the ",(0,s.jsx)(n.code,{children:"OP_POP"})," has popped\r\nthe class, we will have a class with a nicely populated method table, ready to\r\nstart doing things. The next step is pulling those methods back out and using\r\nthem."]}),"\n",(0,s.jsx)(n.h2,{id:"method-references",children:"Method References"}),"\n",(0,s.jsx)(n.p,{children:"Most of the time, methods are accessed and immediately called, leading to this\r\nfamiliar syntax:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"instance.method(argument);\n"})}),"\n",(0,s.jsx)(n.p,{children:"But remember, in Lox and some other languages, those two steps are distinct and\r\ncan be separated."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"var closure = instance.method;\r\nclosure(argument);\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Since users ",(0,s.jsx)(n.em,{children:"can"})," separate the operations, we have to implement them separately.\r\nThe first step is using our existing dotted property syntax to access a method\r\ndefined on the instance's class. That should return some kind of object that the\r\nuser can then call like a function."]}),"\n",(0,s.jsxs)(n.p,{children:["The obvious approach is to look up the method in the class's method table and\r\nreturn the ObjClosure associated with that name. But we also need to remember\r\nthat when you access a method, ",(0,s.jsx)(n.code,{children:"this"})," gets bound to the instance the method was\r\naccessed from. Here's the example from ",(0,s.jsx)(n.a,{href:"classes.html#methods-on-classes",children:"when we added methods to jlox"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:'class Person {\r\n  sayName() {\r\n    print this.name;\r\n  }\r\n}\r\n\r\nvar jane = Person();\r\njane.name = "Jane";\r\n\r\nvar method = jane.sayName;\r\nmethod(); // ?\n'})}),"\n",(0,s.jsxs)(n.p,{children:['This should print "Jane", so the object returned by ',(0,s.jsx)(n.code,{children:".sayName"}),' somehow needs to\r\nremember the instance it was accessed from when it later gets called. In jlox,\r\nwe implemented that "memory" using the interpreter\'s existing heap-allocated\r\nEnvironment class, which handled all variable storage.']}),"\n",(0,s.jsxs)(n.p,{children:["Our bytecode VM has a more complex architecture for storing state. ",(0,s.jsx)(n.a,{href:"local-variables.html#representing-local-variables",children:"Local\r\nvariables and temporaries"})," are on the stack, ",(0,s.jsx)(n.a,{href:"global-variables.html#variable-declarations",children:"globals"})," are in a hash\r\ntable, and variables in closures use ",(0,s.jsx)(n.a,{href:"closures.html#upvalues",children:"upvalues"}),". That necessitates a somewhat\r\nmore complex solution for tracking a method's receiver in clox, and a new\r\nruntime type."]}),"\n",(0,s.jsx)(n.h3,{id:"bound-methods",children:"Bound methods"}),"\n",(0,s.jsxs)(n.p,{children:["When the user executes a method access, we'll find the closure for that method\r\nand wrap it in a new ",(0,s.jsx)(n.span,{name:"bound",children:'"bound method"'})," object that tracks\r\nthe instance that the method was accessed from. This bound object can be called\r\nlater like a function. When invoked, the VM will do some shenanigans to wire up\r\n",(0,s.jsx)(n.code,{children:"this"})," to point to the receiver inside the method's body."]}),"\n",(0,s.jsxs)(n.aside,{name:"bound",children:["\n",(0,s.jsx)(n.p,{children:'I took the name "bound method" from CPython. Python behaves similar to Lox here,\r\nand I used its implementation for inspiration.'}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Here's the new object type:"}),"\n",(0,s.jsx)(n.p,{children:"^code obj-bound-method (2 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"It wraps the receiver and the method closure together. The receiver's type is\r\nValue even though methods can be called only on ObjInstances. Since the VM\r\ndoesn't care what kind of receiver it has anyway, using Value means we don't\r\nhave to keep converting the pointer back to a Value when it gets passed to more\r\ngeneral functions."}),"\n",(0,s.jsx)(n.p,{children:"The new struct implies the usual boilerplate you're used to by now. A new case\r\nin the object type enum:"}),"\n",(0,s.jsx)(n.p,{children:"^code obj-type-bound-method (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"A macro to check a value's type:"}),"\n",(0,s.jsx)(n.p,{children:"^code is-bound-method (2 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"Another macro to cast the value to an ObjBoundMethod pointer:"}),"\n",(0,s.jsx)(n.p,{children:"^code as-bound-method (2 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"A function to create a new ObjBoundMethod:"}),"\n",(0,s.jsx)(n.p,{children:"^code new-bound-method-h (2 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"And an implementation of that function here:"}),"\n",(0,s.jsx)(n.p,{children:"^code new-bound-method"}),"\n",(0,s.jsx)(n.p,{children:"The constructor-like function simply stores the given closure and receiver. When\r\nthe bound method is no longer needed, we free it."}),"\n",(0,s.jsx)(n.p,{children:"^code free-bound-method (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["The bound method has a couple of references, but it doesn't ",(0,s.jsx)(n.em,{children:"own"})," them, so it\r\nfrees nothing but itself. However, those references do get traced by the garbage\r\ncollector."]}),"\n",(0,s.jsx)(n.p,{children:"^code blacken-bound-method (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["This ",(0,s.jsx)(n.span,{name:"trace",children:"ensures"})," that a handle to a method keeps the\r\nreceiver around in memory so that ",(0,s.jsx)(n.code,{children:"this"})," can still find the object when you\r\ninvoke the handle later. We also trace the method closure."]}),"\n",(0,s.jsxs)(n.aside,{name:"trace",children:["\n",(0,s.jsx)(n.p,{children:"Tracing the method closure isn't really necessary. The receiver is an\r\nObjInstance, which has a pointer to its ObjClass, which has a table for all of\r\nthe methods. But it feels dubious to me in some vague way to have ObjBoundMethod\r\nrely on that."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The last operation all objects support is printing."}),"\n",(0,s.jsx)(n.p,{children:"^code print-bound-method (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["A bound method prints exactly the same way as a function. From the user's\r\nperspective, a bound method ",(0,s.jsx)(n.em,{children:"is"})," a function. It's an object they can call. We\r\ndon't expose that the VM implements bound methods using a different object type."]}),"\n",(0,s.jsxs)(n.aside,{name:"party",children:["\n",(0,s.jsx)(n.img,{src:"image/methods-and-initializers/party-hat.png",alt:"A party hat."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Put on your ",(0,s.jsx)(n.span,{name:"party",children:"party"})," hat because we just reached a little\r\nmilestone. ObjBoundMethod is the very last runtime type to add to clox. You've\r\nwritten your last ",(0,s.jsx)(n.code,{children:"IS_"})," and ",(0,s.jsx)(n.code,{children:"AS_"})," macros. We're only a few chapters from the end\r\nof the book, and we're getting close to a complete VM."]}),"\n",(0,s.jsx)(n.h3,{id:"accessing-methods",children:"Accessing methods"}),"\n",(0,s.jsxs)(n.p,{children:['Let\'s get our new object type doing something. Methods are accessed using the\r\nsame "dot" property syntax we implemented in the last chapter. The compiler\r\nalready parses the right expressions and emits ',(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"})," instructions\r\nfor them. The only changes we need to make are in the runtime."]}),"\n",(0,s.jsx)(n.p,{children:"When a property access instruction executes, the instance is on top of the\r\nstack. The instruction's job is to find a field or method with the given name\r\nand replace the top of the stack with the accessed property."}),"\n",(0,s.jsxs)(n.p,{children:["The interpreter already handles fields, so we simply extend the\r\n",(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"})," case with another section."]}),"\n",(0,s.jsx)(n.p,{children:"^code get-method (5 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"We insert this after the code to look up a field on the receiver instance.\r\nFields take priority over and shadow methods, so we look for a field first. If\r\nthe instance does not have a field with the given property name, then the name\r\nmay refer to a method."}),"\n",(0,s.jsxs)(n.p,{children:["We take the instance's class and pass it to a new ",(0,s.jsx)(n.code,{children:"bindMethod()"})," helper. If that\r\nfunction finds a method, it places the method on the stack and returns ",(0,s.jsx)(n.code,{children:"true"}),".\r\nOtherwise it returns ",(0,s.jsx)(n.code,{children:"false"})," to indicate a method with that name couldn't be\r\nfound. Since the name also wasn't a field, that means we have a runtime error,\r\nwhich aborts the interpreter."]}),"\n",(0,s.jsx)(n.p,{children:"Here is the good stuff:"}),"\n",(0,s.jsx)(n.p,{children:"^code bind-method"}),"\n",(0,s.jsx)(n.p,{children:"First we look for a method with the given name in the class's method table. If\r\nwe don't find one, we report a runtime error and bail out. Otherwise, we take\r\nthe method and wrap it in a new ObjBoundMethod. We grab the receiver from its\r\nhome on top of the stack. Finally, we pop the instance and replace the top of\r\nthe stack with the bound method."}),"\n",(0,s.jsx)(n.p,{children:"For example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"class Brunch {\r\n  eggs() {}\r\n}\r\n\r\nvar brunch = Brunch();\r\nvar eggs = brunch.eggs;\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Here is what happens when the VM executes the ",(0,s.jsx)(n.code,{children:"bindMethod()"})," call for the\r\n",(0,s.jsx)(n.code,{children:"brunch.eggs"})," expression:"]}),"\n",(0,s.jsx)(n.img,{src:"image/methods-and-initializers/bind-method.png",alt:"The stack changes caused by bindMethod()."}),"\n",(0,s.jsx)(n.p,{children:"That's a lot of machinery under the hood, but from the user's perspective, they\r\nsimply get a function that they can call."}),"\n",(0,s.jsx)(n.h3,{id:"calling-methods",children:"Calling methods"}),"\n",(0,s.jsxs)(n.p,{children:["Users can declare methods on classes, access them on instances, and get bound\r\nmethods onto the stack. They just can't ",(0,s.jsx)(n.span,{name:"do",children:(0,s.jsx)(n.em,{children:"do"})})," anything\r\nuseful with those bound method objects. The operation we're missing is calling\r\nthem. Calls are implemented in ",(0,s.jsx)(n.code,{children:"callValue()"}),", so we add a case there for the new\r\nobject type."]}),"\n",(0,s.jsxs)(n.aside,{name:"do",children:["\n",(0,s.jsxs)(n.p,{children:["A bound method ",(0,s.jsx)(n.em,{children:"is"}),' a first-class value, so they can store it in variables, pass\r\nit to functions, and otherwise do "value"-y stuff with it.']}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"^code call-bound-method (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["We pull the raw closure back out of the ObjBoundMethod and use the existing\r\n",(0,s.jsx)(n.code,{children:"call()"})," helper to begin an invocation of that closure by pushing a CallFrame\r\nfor it onto the call stack. That's all it takes to be able to run this Lox\r\nprogram:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:'class Scone {\r\n  topping(first, second) {\r\n    print "scone with " + first + " and " + second;\r\n  }\r\n}\r\n\r\nvar scone = Scone();\r\nscone.topping("berries", "cream");\n'})}),"\n",(0,s.jsx)(n.p,{children:"That's three big steps. We can declare, access, and invoke methods. But\r\nsomething is missing. We went to all that trouble to wrap the method closure in\r\nan object that binds the receiver, but when we invoke the method, we don't use\r\nthat receiver at all."}),"\n",(0,s.jsx)(n.h2,{id:"this",children:"This"}),"\n",(0,s.jsxs)(n.p,{children:["The reason bound methods need to keep hold of the receiver is so that it can be\r\naccessed inside the body of the method. Lox exposes a method's receiver through\r\n",(0,s.jsx)(n.code,{children:"this"})," expressions. It's time for some new syntax. The lexer already treats\r\n",(0,s.jsx)(n.code,{children:"this"})," as a special token type, so the first step is wiring that token up in the\r\nparse table."]}),"\n",(0,s.jsx)(n.p,{children:"^code table-this (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.aside,{name:"this",children:["\n",(0,s.jsxs)(n.p,{children:["The underscore at the end of the name of the parser function is because ",(0,s.jsx)(n.code,{children:"this"}),"\r\nis a reserved word in C++ and we support compiling clox as C++."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["When the parser encounters a ",(0,s.jsx)(n.code,{children:"this"})," in prefix position, it dispatches to a new\r\nparser function."]}),"\n",(0,s.jsx)(n.p,{children:"^code this"}),"\n",(0,s.jsxs)(n.p,{children:["We'll apply the same implementation technique for ",(0,s.jsx)(n.code,{children:"this"})," in clox that we used in\r\njlox. We treat ",(0,s.jsx)(n.code,{children:"this"})," as a lexically scoped local variable whose value gets\r\nmagically initialized. Compiling it like a local variable means we get a lot of\r\nbehavior for free. In particular, closures inside a method that reference ",(0,s.jsx)(n.code,{children:"this"}),"\r\nwill do the right thing and capture the receiver in an upvalue."]}),"\n",(0,s.jsxs)(n.p,{children:["When the parser function is called, the ",(0,s.jsx)(n.code,{children:"this"})," token has just been consumed and\r\nis stored as the previous token. We call our existing ",(0,s.jsx)(n.code,{children:"variable()"})," function\r\nwhich compiles identifier expressions as variable accesses. It takes a single\r\nBoolean parameter for whether the compiler should look for a following ",(0,s.jsx)(n.code,{children:"="}),"\r\noperator and parse a setter. You can't assign to ",(0,s.jsx)(n.code,{children:"this"}),", so we pass ",(0,s.jsx)(n.code,{children:"false"})," to\r\ndisallow that."]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"variable()"})," function doesn't care that ",(0,s.jsx)(n.code,{children:"this"}),' has its own token type and\r\nisn\'t an identifier. It is happy to treat the lexeme "this" as if it were a\r\nvariable name and then look it up using the existing scope resolution machinery.\r\nRight now, that lookup will fail because we never declared a variable whose name\r\nis "this". It\'s time to think about where the receiver should live in memory.']}),"\n",(0,s.jsx)(n.p,{children:"At least until they get captured by closures, clox stores every local variable\r\non the VM's stack. The compiler keeps track of which slots in the function's\r\nstack window are owned by which local variables. If you recall, the compiler\r\nsets aside stack slot zero by declaring a local variable whose name is an empty\r\nstring."}),"\n",(0,s.jsxs)(n.p,{children:["For function calls, that slot ends up holding the function being called. Since\r\nthe slot has no name, the function body never accesses it. You can guess where\r\nthis is going. For ",(0,s.jsx)(n.em,{children:"method"})," calls, we can repurpose that slot to store the\r\nreceiver. Slot zero will store the instance that ",(0,s.jsx)(n.code,{children:"this"})," is bound to. In order to\r\ncompile ",(0,s.jsx)(n.code,{children:"this"})," expressions, the compiler simply needs to give the correct name\r\nto that local variable."]}),"\n",(0,s.jsx)(n.p,{children:"^code slot-zero (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["We want to do this only for methods. Function declarations don't have a ",(0,s.jsx)(n.code,{children:"this"}),".\r\nAnd, in fact, they ",(0,s.jsx)(n.em,{children:"must not"}),' declare a variable named "this", so that if you\r\nwrite a ',(0,s.jsx)(n.code,{children:"this"})," expression inside a function declaration which is itself inside a\r\nmethod, the ",(0,s.jsx)(n.code,{children:"this"})," correctly resolves to the outer method's receiver."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"class Nested {\r\n  method() {\r\n    fun function() {\r\n      print this;\r\n    }\r\n\r\n    function();\r\n  }\r\n}\r\n\r\nNested().method();\n"})}),"\n",(0,s.jsx)(n.p,{children:'This program should print "Nested instance". To decide what name to give to\r\nlocal slot zero, the compiler needs to know whether it\'s compiling a function or\r\nmethod declaration, so we add a new case to our FunctionType enum to distinguish\r\nmethods.'}),"\n",(0,s.jsx)(n.p,{children:"^code method-type-enum (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"When we compile a method, we use that type."}),"\n",(0,s.jsx)(n.p,{children:"^code method-type (2 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:['Now we can correctly compile references to the special "this" variable, and the\r\ncompiler will emit the right ',(0,s.jsx)(n.code,{children:"OP_GET_LOCAL"})," instructions to access it. Closures\r\ncan even capture ",(0,s.jsx)(n.code,{children:"this"})," and store the receiver in upvalues. Pretty cool."]}),"\n",(0,s.jsxs)(n.p,{children:["Except that at runtime, the receiver isn't actually ",(0,s.jsx)(n.em,{children:"in"})," slot zero. The\r\ninterpreter isn't holding up its end of the bargain yet. Here is the fix:"]}),"\n",(0,s.jsx)(n.p,{children:"^code store-receiver (2 before, 2 after)"}),"\n",(0,s.jsx)(n.p,{children:"When a method is called, the top of the stack contains all of the arguments, and\r\nthen just under those is the closure of the called method. That's where slot\r\nzero in the new CallFrame will be. This line of code inserts the receiver into\r\nthat slot. For example, given a method call like this:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:'scone.topping("berries", "cream");\n'})}),"\n",(0,s.jsx)(n.p,{children:"We calculate the slot to store the receiver like so:"}),"\n",(0,s.jsx)(n.img,{src:"image/methods-and-initializers/closure-slot.png",alt:"Skipping over the argument stack slots to find the slot containing the closure."}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"-argCount"})," skips past the arguments and the ",(0,s.jsx)(n.code,{children:"- 1"})," adjusts for the fact that\r\n",(0,s.jsx)(n.code,{children:"stackTop"})," points just ",(0,s.jsx)(n.em,{children:"past"})," the last used stack slot."]}),"\n",(0,s.jsx)(n.h3,{id:"misusing-this",children:"Misusing this"}),"\n",(0,s.jsxs)(n.p,{children:["Our VM now supports users ",(0,s.jsx)(n.em,{children:"correctly"})," using ",(0,s.jsx)(n.code,{children:"this"}),", but we also need to make\r\nsure it properly handles users ",(0,s.jsx)(n.em,{children:"mis"}),"using ",(0,s.jsx)(n.code,{children:"this"}),". Lox says it is a compile\r\nerror for a ",(0,s.jsx)(n.code,{children:"this"})," expression to appear outside of the body of a method. These\r\ntwo wrong uses should be caught by the compiler:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"print this; // At top level.\r\n\r\nfun notMethod() {\r\n  print this; // In a function.\r\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"So how does the compiler know if it's inside a method? The obvious answer is to\r\nlook at the FunctionType of the current Compiler. We did just add an enum case\r\nthere to treat methods specially. However, that wouldn't correctly handle code\r\nlike the earlier example where you are inside a function which is, itself,\r\nnested inside a method."}),"\n",(0,s.jsx)(n.p,{children:'We could try to resolve "this" and then report an error if it wasn\'t found in\r\nany of the surrounding lexical scopes. That would work, but would require us to\r\nshuffle around a bunch of code, since right now the code for resolving a\r\nvariable implicitly considers it a global access if no declaration is found.'}),"\n",(0,s.jsx)(n.p,{children:"In the next chapter, we will need information about the nearest enclosing class.\r\nIf we had that, we could use it here to determine if we are inside a method. So\r\nwe may as well make our future selves' lives a little easier and put that\r\nmachinery in place now."}),"\n",(0,s.jsx)(n.p,{children:"^code current-class (1 before, 2 after)"}),"\n",(0,s.jsx)(n.p,{children:"This module variable points to a struct representing the current, innermost\r\nclass being compiled. The new type looks like this:"}),"\n",(0,s.jsx)(n.p,{children:"^code class-compiler-struct (1 before, 2 after)"}),"\n",(0,s.jsx)(n.p,{children:"Right now we store only a pointer to the ClassCompiler for the enclosing class,\r\nif any. Nesting a class declaration inside a method in some other class is an\r\nuncommon thing to do, but Lox supports it. Just like the Compiler struct, this\r\nmeans ClassCompiler forms a linked list from the current innermost class being\r\ncompiled out through all of the enclosing classes."}),"\n",(0,s.jsxs)(n.p,{children:["If we aren't inside any class declaration at all, the module variable\r\n",(0,s.jsx)(n.code,{children:"currentClass"})," is ",(0,s.jsx)(n.code,{children:"NULL"}),". When the compiler begins compiling a class, it pushes\r\na new ClassCompiler onto that implicit linked stack."]}),"\n",(0,s.jsx)(n.p,{children:"^code create-class-compiler (2 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"The memory for the ClassCompiler struct lives right on the C stack, a handy\r\ncapability we get by writing our compiler using recursive descent. At the end of\r\nthe class body, we pop that compiler off the stack and restore the enclosing\r\none."}),"\n",(0,s.jsx)(n.p,{children:"^code pop-enclosing (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["When an outermost class body ends, ",(0,s.jsx)(n.code,{children:"enclosing"})," will be ",(0,s.jsx)(n.code,{children:"NULL"}),", so this resets\r\n",(0,s.jsx)(n.code,{children:"currentClass"})," to ",(0,s.jsx)(n.code,{children:"NULL"}),". Thus, to see if we are inside a class -- and therefore\r\ninside a method -- we simply check that module variable."]}),"\n",(0,s.jsx)(n.p,{children:"^code this-outside-class (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["With that, ",(0,s.jsx)(n.code,{children:"this"})," outside of a class is correctly forbidden. Now our methods\r\nreally feel like ",(0,s.jsx)(n.em,{children:"methods"})," in the object-oriented sense. Accessing the receiver\r\nlets them affect the instance you called the method on. We're getting there!"]}),"\n",(0,s.jsx)(n.h2,{id:"instance-initializers",children:"Instance Initializers"}),"\n",(0,s.jsxs)(n.p,{children:["The reason object-oriented languages tie state and behavior together -- one of\r\nthe core tenets of the paradigm -- is to ensure that objects are always in a\r\nvalid, meaningful state. When the only way to touch an object's state is ",(0,s.jsx)(n.span,{name:"through",children:"through"})," its methods, the methods can make sure nothing\r\ngoes awry. But that presumes the object is ",(0,s.jsx)(n.em,{children:"already"})," in a proper state. What\r\nabout when it's first created?"]}),"\n",(0,s.jsxs)(n.aside,{name:"through",children:["\n",(0,s.jsx)(n.p,{children:"Of course, Lox does let outside code directly access and modify an instance's\r\nfields without going through its methods. This is unlike Ruby and Smalltalk,\r\nwhich completely encapsulate state inside objects. Our toy scripting language,\r\nalas, isn't so principled."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Object-oriented languages ensure that brand new objects are properly set up\r\nthrough constructors, which both produce a new instance and initialize its\r\nstate. In Lox, the runtime allocates new raw instances, and a class may declare\r\nan initializer to set up any fields. Initializers work mostly like normal\r\nmethods, with a few tweaks:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The runtime automatically invokes the initializer method whenever an\r\ninstance of a class is created."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["The caller that constructs an instance always gets the instance ",(0,s.jsx)(n.span,{name:"return",children:"back"})," after the initializer finishes, regardless of what\r\nthe initializer function itself returns. The initializer method doesn't need\r\nto explicitly return ",(0,s.jsx)(n.code,{children:"this"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["In fact, an initializer is ",(0,s.jsx)(n.em,{children:"prohibited"})," from returning any value at all\r\nsince the value would never be seen anyway."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.aside,{name:"return",children:["\n",(0,s.jsx)(n.p,{children:"It's as if the initializer is implicitly wrapped in a bundle of code like this:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:"fun create(klass) {\r\n  var obj = newInstance(klass);\r\n  obj.init();\r\n  return obj;\r\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Note how the value returned by ",(0,s.jsx)(n.code,{children:"init()"})," is discarded."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Now that we support methods, to add initializers, we merely need to implement\r\nthose three special rules. We'll go in order."}),"\n",(0,s.jsx)(n.h3,{id:"invoking-initializers",children:"Invoking initializers"}),"\n",(0,s.jsxs)(n.p,{children:["First, automatically calling ",(0,s.jsx)(n.code,{children:"init()"})," on new instances:"]}),"\n",(0,s.jsx)(n.p,{children:"^code call-init (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["After the runtime allocates the new instance, we look for an ",(0,s.jsx)(n.code,{children:"init()"})," method on\r\nthe class. If we find one, we initiate a call to it. This pushes a new CallFrame\r\nfor the initializer's closure. Say we run this program:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:'class Brunch {\r\n  init(food, drink) {}\r\n}\r\n\r\nBrunch("eggs", "coffee");\n'})}),"\n",(0,s.jsxs)(n.p,{children:["When the VM executes the call to ",(0,s.jsx)(n.code,{children:"Brunch()"}),", it goes like this:"]}),"\n",(0,s.jsx)(n.img,{src:"image/methods-and-initializers/init-call-frame.png",alt:"The aligned stack windows for the Brunch() call and the corresponding init() method it forwards to."}),"\n",(0,s.jsxs)(n.p,{children:["Any arguments passed to the class when we called it are still sitting on the\r\nstack above the instance. The new CallFrame for the ",(0,s.jsx)(n.code,{children:"init()"})," method shares that\r\nstack window, so those arguments implicitly get forwarded to the initializer."]}),"\n",(0,s.jsxs)(n.p,{children:["Lox doesn't require a class to define an initializer. If omitted, the runtime\r\nsimply returns the new uninitialized instance. However, if there is no ",(0,s.jsx)(n.code,{children:"init()"}),"\r\nmethod, then it doesn't make any sense to pass arguments to the class when\r\ncreating the instance. We make that an error."]}),"\n",(0,s.jsx)(n.p,{children:"^code no-init-arity-error (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["When the class ",(0,s.jsx)(n.em,{children:"does"})," provide an initializer, we also need to ensure that the\r\nnumber of arguments passed matches the initializer's arity. Fortunately, the\r\n",(0,s.jsx)(n.code,{children:"call()"})," helper does that for us already."]}),"\n",(0,s.jsxs)(n.p,{children:["To call the initializer, the runtime looks up the ",(0,s.jsx)(n.code,{children:"init()"}),' method by name. We\r\nwant that to be fast since it happens every time an instance is constructed.\r\nThat means it would be good to take advantage of the string interning we\'ve\r\nalready implemented. To do that, the VM creates an ObjString for "init" and\r\nreuses it. The string lives right in the VM struct.']}),"\n",(0,s.jsx)(n.p,{children:"^code vm-init-string (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"We create and intern the string when the VM boots up."}),"\n",(0,s.jsx)(n.p,{children:"^code init-init-string (1 before, 2 after)"}),"\n",(0,s.jsx)(n.p,{children:"We want it to stick around, so the GC considers it a root."}),"\n",(0,s.jsx)(n.p,{children:"^code mark-init-string (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["Look carefully. See any bug waiting to happen? No? It's a subtle one. The\r\ngarbage collector now reads ",(0,s.jsx)(n.code,{children:"vm.initString"}),". That field is initialized from the\r\nresult of calling ",(0,s.jsx)(n.code,{children:"copyString()"}),". But copying a string allocates memory, which\r\ncan trigger a GC. If the collector ran at just the wrong time, it would read\r\n",(0,s.jsx)(n.code,{children:"vm.initString"})," before it had been initialized. So, first we zero the field out."]}),"\n",(0,s.jsx)(n.p,{children:"^code null-init-string (2 before, 2 after)"}),"\n",(0,s.jsx)(n.p,{children:"We clear the pointer when the VM shuts down since the next line will free it."}),"\n",(0,s.jsx)(n.p,{children:"^code clear-init-string (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"OK, that lets us call initializers."}),"\n",(0,s.jsx)(n.h3,{id:"initializer-return-values",children:"Initializer return values"}),"\n",(0,s.jsxs)(n.p,{children:["The next step is ensuring that constructing an instance of a class with an\r\ninitializer always returns the new instance, and not ",(0,s.jsx)(n.code,{children:"nil"})," or whatever the body\r\nof the initializer returns. Right now, if a class defines an initializer, then\r\nwhen an instance is constructed, the VM pushes a call to that initializer onto\r\nthe CallFrame stack. Then it just keeps on trucking."]}),"\n",(0,s.jsxs)(n.p,{children:["The user's invocation on the class to create the instance will complete whenever\r\nthat initializer method returns, and will leave on the stack whatever value the\r\ninitializer puts there. That means that unless the user takes care to put\r\n",(0,s.jsx)(n.code,{children:"return this;"})," at the end of the initializer, no instance will come out. Not\r\nvery helpful."]}),"\n",(0,s.jsxs)(n.p,{children:["To fix this, whenever the front end compiles an initializer method, it will emit\r\ndifferent bytecode at the end of the body to return ",(0,s.jsx)(n.code,{children:"this"})," from the method\r\ninstead of the usual implicit ",(0,s.jsx)(n.code,{children:"nil"})," most functions return. In order to do\r\n",(0,s.jsx)(n.em,{children:"that"}),', the compiler needs to actually know when it is compiling an initializer.\r\nWe detect that by checking to see if the name of the method we\'re compiling is\r\n"init".']}),"\n",(0,s.jsx)(n.p,{children:"^code initializer-name (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"We define a new function type to distinguish initializers from other methods."}),"\n",(0,s.jsx)(n.p,{children:"^code initializer-type-enum (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"Whenever the compiler emits the implicit return at the end of a body, we check\r\nthe type to decide whether to insert the initializer-specific behavior."}),"\n",(0,s.jsx)(n.p,{children:"^code return-this (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["In an initializer, instead of pushing ",(0,s.jsx)(n.code,{children:"nil"})," onto the stack before returning,\r\nwe load slot zero, which contains the instance. This ",(0,s.jsx)(n.code,{children:"emitReturn()"})," function is\r\nalso called when compiling a ",(0,s.jsx)(n.code,{children:"return"})," statement without a value, so this also\r\ncorrectly handles cases where the user does an early return inside the\r\ninitializer."]}),"\n",(0,s.jsx)(n.h3,{id:"incorrect-returns-in-initializers",children:"Incorrect returns in initializers"}),"\n",(0,s.jsxs)(n.p,{children:["The last step, the last item in our list of special features of initializers, is\r\nmaking it an error to try to return anything ",(0,s.jsx)(n.em,{children:"else"})," from an initializer. Now\r\nthat the compiler tracks the method type, this is straightforward."]}),"\n",(0,s.jsx)(n.p,{children:"^code return-from-init (3 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["We report an error if a ",(0,s.jsx)(n.code,{children:"return"})," statement in an initializer has a value. We\r\nstill go ahead and compile the value afterwards so that the compiler doesn't get\r\nconfused by the trailing expression and report a bunch of cascaded errors."]}),"\n",(0,s.jsxs)(n.p,{children:["Aside from inheritance, which we'll get to ",(0,s.jsx)(n.a,{href:"superclasses.html",children:"soon"}),", we now have a\r\nfairly full-featured class system working in clox."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:'class CoffeeMaker {\r\n  init(coffee) {\r\n    this.coffee = coffee;\r\n  }\r\n\r\n  brew() {\r\n    print "Enjoy your cup of " + this.coffee;\r\n\r\n    // No reusing the grounds!\r\n    this.coffee = nil;\r\n  }\r\n}\r\n\r\nvar maker = CoffeeMaker("coffee and chicory");\r\nmaker.brew();\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Pretty fancy for a C program that would fit on an old ",(0,s.jsx)(n.span,{name:"floppy",children:"floppy"})," disk."]}),"\n",(0,s.jsxs)(n.aside,{name:"floppy",children:["\n",(0,s.jsx)(n.p,{children:'I acknowledge that "floppy disk" may no longer be a useful size reference for\r\ncurrent generations of programmers. Maybe I should have said "a few tweets" or\r\nsomething.'}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"optimized-invocations",children:"Optimized Invocations"}),"\n",(0,s.jsx)(n.p,{children:"Our VM correctly implements the language's semantics for method calls and\r\ninitializers. We could stop here. But the main reason we are building an entire\r\nsecond implementation of Lox from scratch is to execute faster than our old Java\r\ninterpreter. Right now, method calls even in clox are slow."}),"\n",(0,s.jsxs)(n.p,{children:["Lox's semantics define a method invocation as two operations -- accessing the\r\nmethod and then calling the result. Our VM must support those as separate\r\noperations because the user ",(0,s.jsx)(n.em,{children:"can"})," separate them. You can access a method without\r\ncalling it and then invoke the bound method later. Nothing we've implemented so\r\nfar is unnecessary."]}),"\n",(0,s.jsxs)(n.p,{children:["But ",(0,s.jsx)(n.em,{children:"always"})," executing those as separate operations has a significant cost.\r\nEvery single time a Lox program accesses and invokes a method, the runtime\r\nheap allocates a new ObjBoundMethod, initializes its fields, then pulls them\r\nright back out. Later, the GC has to spend time freeing all of those ephemeral\r\nbound methods."]}),"\n",(0,s.jsxs)(n.p,{children:["Most of the time, a Lox program accesses a method and then immediately calls it.\r\nThe bound method is created by one bytecode instruction and then consumed by the\r\nvery next one. In fact, it's so immediate that the compiler can even textually\r\n",(0,s.jsx)(n.em,{children:"see"})," that it's happening -- a dotted property access followed by an opening\r\nparenthesis is most likely a method call."]}),"\n",(0,s.jsxs)(n.p,{children:["Since we can recognize this pair of operations at compile time, we have the\r\nopportunity to emit a ",(0,s.jsx)(n.span,{name:"super",children:"new, special"})," instruction that\r\nperforms an optimized method call."]}),"\n",(0,s.jsx)(n.p,{children:"We start in the function that compiles dotted property expressions."}),"\n",(0,s.jsxs)(n.aside,{name:"super",className:"bottom",children:["\n",(0,s.jsxs)(n.p,{children:["If you spend enough time watching your bytecode VM run, you'll notice it often\r\nexecutes the same series of bytecode instructions one after the other. A classic\r\noptimization technique is to define a new single instruction called a\r\n",(0,s.jsx)(n.strong,{children:"superinstruction"})," that fuses those into a single instruction with the same\r\nbehavior as the entire sequence."]}),"\n",(0,s.jsx)(n.p,{children:"One of the largest performance drains in a bytecode interpreter is the overhead\r\nof decoding and dispatching each instruction. Fusing several instructions into\r\none eliminates some of that."}),"\n",(0,s.jsxs)(n.p,{children:["The challenge is determining ",(0,s.jsx)(n.em,{children:"which"})," instruction sequences are common enough to\r\nbenefit from this optimization. Every new superinstruction claims an opcode for\r\nits own use and there are only so many of those to go around. Add too many, and\r\nyou'll need a larger encoding for opcodes, which then increases code size and\r\nmakes decoding ",(0,s.jsx)(n.em,{children:"all"})," instructions slower."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"^code parse-call (3 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["After the compiler has parsed the property name, we look for a left parenthesis.\r\nIf we match one, we switch to a new code path. There, we compile the argument\r\nlist exactly like we do when compiling a call expression. Then we emit a single\r\nnew ",(0,s.jsx)(n.code,{children:"OP_INVOKE"})," instruction. It takes two operands:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The index of the property name in the constant table."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The number of arguments passed to the method."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["In other words, this single instruction combines the operands of the\r\n",(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"})," and ",(0,s.jsx)(n.code,{children:"OP_CALL"})," instructions it replaces, in that order. It\r\nreally is a fusion of those two instructions. Let's define it."]}),"\n",(0,s.jsx)(n.p,{children:"^code invoke-op (1 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"And add it to the disassembler:"}),"\n",(0,s.jsx)(n.p,{children:"^code disassemble-invoke (2 before, 1 after)"}),"\n",(0,s.jsx)(n.p,{children:"This is a new, special instruction format, so it needs a little custom\r\ndisassembly logic."}),"\n",(0,s.jsx)(n.p,{children:"^code invoke-instruction"}),"\n",(0,s.jsx)(n.p,{children:"We read the two operands and then print out both the method name and the\r\nargument count. Over in the interpreter's bytecode dispatch loop is where the\r\nreal action begins."}),"\n",(0,s.jsx)(n.p,{children:"^code interpret-invoke (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["Most of the work happens in ",(0,s.jsx)(n.code,{children:"invoke()"}),", which we'll get to. Here, we look up the\r\nmethod name from the first operand and then read the argument count operand.\r\nThen we hand off to ",(0,s.jsx)(n.code,{children:"invoke()"})," to do the heavy lifting. That function returns\r\n",(0,s.jsx)(n.code,{children:"true"})," if the invocation succeeds. As usual, a ",(0,s.jsx)(n.code,{children:"false"})," return means a runtime\r\nerror occurred. We check for that here and abort the interpreter if disaster has\r\nstruck."]}),"\n",(0,s.jsxs)(n.p,{children:["Finally, assuming the invocation succeeded, then there is a new CallFrame on the\r\nstack, so we refresh our cached copy of the current frame in ",(0,s.jsx)(n.code,{children:"frame"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"The interesting work happens here:"}),"\n",(0,s.jsx)(n.p,{children:"^code invoke"}),"\n",(0,s.jsx)(n.p,{children:"First we grab the receiver off the stack. The arguments passed to the method are\r\nabove it on the stack, so we peek that many slots down. Then it's a simple\r\nmatter to cast the object to an instance and invoke the method on it."}),"\n",(0,s.jsxs)(n.p,{children:["That does assume the object ",(0,s.jsx)(n.em,{children:"is"})," an instance. As with ",(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"}),"\r\ninstructions, we also need to handle the case where a user incorrectly tries to\r\ncall a method on a value of the wrong type."]}),"\n",(0,s.jsx)(n.p,{children:"^code invoke-check-type (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.span,{name:"helper",children:"That's"})," a runtime error, so we report that and bail\r\nout. Otherwise, we get the instance's class and jump over to this other new\r\nutility function:"]}),"\n",(0,s.jsxs)(n.aside,{name:"helper",children:["\n",(0,s.jsxs)(n.p,{children:["As you can guess by now, we split this code into a separate function because\r\nwe're going to reuse it later -- in this case for ",(0,s.jsx)(n.code,{children:"super"})," calls."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"^code invoke-from-class"}),"\n",(0,s.jsxs)(n.p,{children:["This function combines the logic of how the VM implements ",(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"})," and\r\n",(0,s.jsx)(n.code,{children:"OP_CALL"})," instructions, in that order. First we look up the method by name in\r\nthe class's method table. If we don't find one, we report that runtime error and\r\nexit."]}),"\n",(0,s.jsxs)(n.p,{children:["Otherwise, we take the method's closure and push a call to it onto the CallFrame\r\nstack. We don't need to heap allocate and initialize an ObjBoundMethod. In fact,\r\nwe don't even need to ",(0,s.jsx)(n.span,{name:"juggle",children:"juggle"})," anything on the stack.\r\nThe receiver and method arguments are already right where they need to be."]}),"\n",(0,s.jsxs)(n.aside,{name:"juggle",children:["\n",(0,s.jsxs)(n.p,{children:["This is a key reason ",(0,s.jsx)(n.em,{children:"why"})," we use stack slot zero to store the receiver -- it's\r\nhow the caller already organizes the stack for a method call. An efficient\r\ncalling convention is an important part of a bytecode VM's performance story."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["If you fire up the VM and run a little program that calls methods now, you\r\nshould see the exact same behavior as before. But, if we did our job right, the\r\n",(0,s.jsx)(n.em,{children:"performance"})," should be much improved. I wrote a little microbenchmark that\r\ndoes a batch of 10,000 method calls. Then it tests how many of these batches it\r\ncan execute in 10 seconds. On my computer, without the new ",(0,s.jsx)(n.code,{children:"OP_INVOKE"}),"\r\ninstruction, it got through 1,089 batches. With this new optimization, it\r\nfinished 8,324 batches in the same time. That's ",(0,s.jsx)(n.em,{children:"7.6 times faster"}),", which is a\r\nhuge improvement when it comes to programming language optimization."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.span,{name:"pat"})}),"\n",(0,s.jsxs)(n.aside,{name:"pat",children:["\n",(0,s.jsxs)(n.p,{children:["We shouldn't pat ourselves on the back ",(0,s.jsx)(n.em,{children:"too"})," firmly. This performance\r\nimprovement is relative to our own unoptimized method call implementation which\r\nwas quite slow. Doing a heap allocation for every single method call isn't going\r\nto win any races."]}),"\n"]}),"\n",(0,s.jsx)(n.img,{src:"image/methods-and-initializers/benchmark.png",alt:"Bar chart comparing the two benchmark results."}),"\n",(0,s.jsx)(n.h3,{id:"invoking-fields",children:"Invoking fields"}),"\n",(0,s.jsxs)(n.p,{children:['The fundamental creed of optimization is: "Thou shalt not break correctness."\r\n',(0,s.jsx)(n.span,{name:"monte",children:"Users"})," like it when a language implementation gives\r\nthem an answer faster, but only if it's the ",(0,s.jsx)(n.em,{children:"right"})," answer. Alas, our\r\nimplementation of faster method invocations fails to uphold that principle:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-lox",children:'class Oops {\r\n  init() {\r\n    fun f() {\r\n      print "not a method";\r\n    }\r\n\r\n    this.field = f;\r\n  }\r\n}\r\n\r\nvar oops = Oops();\r\noops.field();\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The last line looks like a method call. The compiler thinks that it is and\r\ndutifully emits an ",(0,s.jsx)(n.code,{children:"OP_INVOKE"})," instruction for it. However, it's not. What is\r\nactually happening is a ",(0,s.jsx)(n.em,{children:"field"}),' access that returns a function which then gets\r\ncalled. Right now, instead of executing that correctly, our VM reports a runtime\r\nerror when it can\'t find a method named "field".']}),"\n",(0,s.jsxs)(n.aside,{name:"monte",children:["\n",(0,s.jsxs)(n.p,{children:["There are cases where users may be satisfied when a program sometimes returns\r\nthe wrong answer in return for running significantly faster or with a better\r\nbound on the performance. These are the field of ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Monte_Carlo_algorithm",children:(0,s.jsx)(n.strong,{children:"Monte Carlo\r\nalgorithms"})}),". For some use cases, this is a good trade-off."]}),"\n",(0,s.jsxs)(n.p,{children:["The important part, though, is that the user is ",(0,s.jsx)(n.em,{children:"choosing"})," to apply one of these\r\nalgorithms. We language implementers can't unilaterally decide to sacrifice\r\ntheir program's correctness."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Earlier, when we implemented ",(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"}),", we handled both field and method\r\naccesses. To squash this new bug, we need to do the same thing for ",(0,s.jsx)(n.code,{children:"OP_INVOKE"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"^code invoke-field (1 before, 1 after)"}),"\n",(0,s.jsxs)(n.p,{children:["Pretty simple fix. Before looking up a method on the instance's class, we look\r\nfor a field with the same name. If we find a field, then we store it on the\r\nstack in place of the receiver, ",(0,s.jsx)(n.em,{children:"under"})," the argument list. This is how\r\n",(0,s.jsx)(n.code,{children:"OP_GET_PROPERTY"})," behaves since the latter instruction executes before a\r\nsubsequent parenthesized list of arguments has been evaluated."]}),"\n",(0,s.jsxs)(n.p,{children:["Then we try to call that field's value like the callable that it hopefully is.\r\nThe ",(0,s.jsx)(n.code,{children:"callValue()"})," helper will check the value's type and call it as appropriate\r\nor report a runtime error if the field's value isn't a callable type like a\r\nclosure."]}),"\n",(0,s.jsxs)(n.p,{children:["That's all it takes to make our optimization fully safe. We do sacrifice a\r\nlittle performance, unfortunately. But that's the price you have to pay\r\nsometimes. You occasionally get frustrated by optimizations you ",(0,s.jsx)(n.em,{children:"could"})," do if\r\nonly the language wouldn't allow some annoying corner case. But, as language\r\n",(0,s.jsx)(n.span,{name:"designer",children:"implementers"}),", we have to play the game we're given."]}),"\n",(0,s.jsxs)(n.aside,{name:"designer",children:["\n",(0,s.jsxs)(n.p,{children:["As language ",(0,s.jsx)(n.em,{children:"designers"}),", our role is very different. If we do control the\r\nlanguage itself, we may sometimes choose to restrict or change the language in\r\nways that enable optimizations. Users want expressive languages, but they also\r\nwant fast implementations. Sometimes it is good language design to sacrifice a\r\nlittle power if you can give them perf in return."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The code we wrote here follows a typical pattern in optimization:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Recognize a common operation or sequence of operations that is performance\r\ncritical. In this case, it is a method access followed by a call."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Add an optimized implementation of that pattern. That's our ",(0,s.jsx)(n.code,{children:"OP_INVOKE"}),"\r\ninstruction."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Guard the optimized code with some conditional logic that validates that the\r\npattern actually applies. If it does, stay on the fast path. Otherwise, fall\r\nback to a slower but more robust unoptimized behavior. Here, that means\r\nchecking that we are actually calling a method and not accessing a field."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["As your language work moves from getting the implementation working ",(0,s.jsx)(n.em,{children:"at all"})," to\r\ngetting it to work ",(0,s.jsx)(n.em,{children:"faster"}),", you will find yourself spending more and more\r\ntime looking for patterns like this and adding guarded optimizations for them.\r\nFull-time VM engineers spend much of their careers in this loop."]}),"\n",(0,s.jsx)(n.p,{children:"But we can stop here for now. With this, clox now supports most of the features\r\nof an object-oriented programming language, and with respectable performance."}),"\n",(0,s.jsxs)(n.div,{className:"challenges",children:["\n",(0,s.jsx)(n.h2,{id:"challenges",children:"Challenges"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["The hash table lookup to find a class's ",(0,s.jsx)(n.code,{children:"init()"})," method is constant time,\r\nbut still fairly slow. Implement something faster. Write a benchmark and\r\nmeasure the performance difference."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"In a dynamically typed language like Lox, a single callsite may invoke a\r\nvariety of methods on a number of classes throughout a program's execution.\r\nEven so, in practice, most of the time a callsite ends up calling the exact\r\nsame method on the exact same class for the duration of the run. Most calls\r\nare actually not polymorphic even if the language says they can be."}),"\n",(0,s.jsx)(n.p,{children:"How do advanced language implementations optimize based on that observation?"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["When interpreting an ",(0,s.jsx)(n.code,{children:"OP_INVOKE"})," instruction, the VM has to do two hash\r\ntable lookups. First, it looks for a field that could shadow a method, and\r\nonly if that fails does it look for a method. The former check is rarely\r\nuseful -- most fields do not contain functions. But it is ",(0,s.jsx)(n.em,{children:"necessary"}),"\r\nbecause the language says fields and methods are accessed using the same\r\nsyntax, and fields shadow methods."]}),"\n",(0,s.jsxs)(n.p,{children:["That is a language ",(0,s.jsx)(n.em,{children:"choice"})," that affects the performance of our\r\nimplementation. Was it the right choice? If Lox were your language, what\r\nwould you do?"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.div,{className:"design-note",children:["\n",(0,s.jsx)(n.h2,{id:"design-note-novelty-budget",children:"Design Note: Novelty Budget"}),"\n",(0,s.jsxs)(n.p,{children:["I still remember the first time I wrote a tiny BASIC program on a TRS-80 and\r\nmade a computer do something it hadn't done before. It felt like a superpower.\r\nThe first time I cobbled together just enough of a parser and interpreter to let\r\nme write a tiny program in ",(0,s.jsx)(n.em,{children:"my own language"})," that made a computer do a thing was\r\nlike some sort of higher-order meta-superpower. It was and remains a wonderful\r\nfeeling."]}),"\n",(0,s.jsxs)(n.p,{children:["I realized I could design a language that looked and behaved however I chose. It\r\nwas like I'd been going to a private school that required uniforms my whole life\r\nand then one day transferred to a public school where I could wear whatever I\r\nwanted. I don't need to use curly braces for blocks? I can use something other\r\nthan an equals sign for assignment? I can do objects without classes? Multiple\r\ninheritance ",(0,s.jsx)(n.em,{children:"and"})," multimethods? A dynamic language that overloads statically, by\r\narity?"]}),"\n",(0,s.jsx)(n.p,{children:"Naturally, I took that freedom and ran with it. I made the weirdest, most\r\narbitrary language design decisions. Apostrophes for generics. No commas between\r\narguments. Overload resolution that can fail at runtime. I did things\r\ndifferently just for difference's sake."}),"\n",(0,s.jsx)(n.p,{children:"This is a very fun experience that I highly recommend. We need more weird,\r\navant-garde programming languages. I want to see more art languages. I still\r\nmake oddball toy languages for fun sometimes."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"However"}),', if your goal is success where "success" is defined as a large number\r\nof users, then your priorities must be different. In that case, your primary\r\ngoal is to have your language loaded into the brains of as many people as\r\npossible. That\'s ',(0,s.jsx)(n.em,{children:"really hard"}),". It takes a lot of human effort to move a\r\nlanguage's syntax and semantics from a computer into trillions of neurons."]}),"\n",(0,s.jsx)(n.p,{children:"Programmers are naturally conservative with their time and cautious about what\r\nlanguages are worth uploading into their wetware. They don't want to waste their\r\ntime on a language that ends up not being useful to them. As a language\r\ndesigner, your goal is thus to give them as much language power as you can with\r\nas little required learning as possible."}),"\n",(0,s.jsxs)(n.p,{children:["One natural approach is ",(0,s.jsx)(n.em,{children:"simplicity"}),". The fewer concepts and features your\r\nlanguage has, the less total volume of stuff there is to learn. This is one of\r\nthe reasons minimal ",(0,s.jsx)(n.span,{name:"dynamic",children:"scripting"})," languages often find\r\nsuccess even though they aren't as powerful as the big industrial languages --\r\nthey are easier to get started with, and once they are in someone's brain, the\r\nuser wants to keep using them."]}),"\n",(0,s.jsxs)(n.aside,{name:"dynamic",children:["\n",(0,s.jsxs)(n.p,{children:["In particular, this is a big advantage of dynamically typed languages. A static\r\nlanguage requires you to learn ",(0,s.jsx)(n.em,{children:"two"})," languages -- the runtime semantics and the\r\nstatic type system -- before you can get to the point where you are making the\r\ncomputer do stuff. Dynamic languages require you to learn only the former."]}),"\n",(0,s.jsx)(n.p,{children:"Eventually, programs get big enough that the value of static analysis pays for\r\nthe effort to learn that second static language, but the value proposition isn't\r\nas obvious at the outset."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The problem with simplicity is that simply cutting features often sacrifices\r\npower and expressiveness. There is an art to finding features that punch above\r\ntheir weight, but often minimal languages simply do less."}),"\n",(0,s.jsxs)(n.p,{children:["There is another path that avoids much of that problem. The trick is to realize\r\nthat a user doesn't have to load your entire language into their head, ",(0,s.jsx)(n.em,{children:"just the\r\npart they don't already have in there"}),". As I mentioned in an ",(0,s.jsx)(n.a,{href:"parsing-expressions.html#design-note",children:"earlier design\r\nnote"}),", learning is about transferring the ",(0,s.jsx)(n.em,{children:"delta"})," between what they\r\nalready know and what they need to know."]}),"\n",(0,s.jsx)(n.p,{children:'Many potential users of your language already know some other programming\r\nlanguage. Any features your language shares with that language are essentially\r\n"free" when it comes to learning. It\'s already in their head, they just have to\r\nrecognize that your language does the same thing.'}),"\n",(0,s.jsxs)(n.p,{children:["In other words, ",(0,s.jsx)(n.em,{children:"familiarity"})," is another key tool to lower the adoption cost of\r\nyour language. Of course, if you fully maximize that attribute, the end result\r\nis a language that is completely identical to some existing one. That's not a\r\nrecipe for success, because at that point there's no incentive for users to\r\nswitch to your language at all."]}),"\n",(0,s.jsx)(n.p,{children:"So you do need to provide some compelling differences. Some things your language\r\ncan do that other languages can't, or at least can't do as well. I believe this\r\nis one of the fundamental balancing acts of language design: similarity to other\r\nlanguages lowers learning cost, while divergence raises the compelling\r\nadvantages."}),"\n",(0,s.jsxs)(n.p,{children:["I think of this balancing act in terms of a ",(0,s.jsx)(n.span,{name:"idiosyncracy",children:(0,s.jsx)(n.strong,{children:"novelty\r\nbudget"})}),', or as Steve Klabnik calls it, a "',(0,s.jsx)(n.a,{href:"https://words.steveklabnik.com/the-language-strangeness-budget",children:"strangeness budget"}),"\". Users\r\nhave a low threshold for the total amount of new stuff they are willing to\r\naccept to learn a new language. Exceed that, and they won't show up."]}),"\n",(0,s.jsxs)(n.aside,{name:"idiosyncracy",children:["\n",(0,s.jsxs)(n.p,{children:["A related concept in psychology is ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Idiosyncrasy_credit",children:(0,s.jsx)(n.strong,{children:"idiosyncrasy credit"})}),', the\r\nidea that other people in society grant you a finite amount of deviations from\r\nsocial norms. You earn credit by fitting in and doing in-group things, which you\r\ncan then spend on oddball activities that might otherwise raise eyebrows. In\r\nother words, demonstrating that you are "one of the good ones" gives you license\r\nto raise your freak flag, but only so far.']}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Anytime you add something new to your language that other languages don't have,\r\nor anytime your language does something other languages do in a different way,\r\nyou spend some of that budget. That's OK -- you ",(0,s.jsx)(n.em,{children:"need"})," to spend it to make your\r\nlanguage compelling. But your goal is to spend it ",(0,s.jsx)(n.em,{children:"wisely"}),". For each feature or\r\ndifference, ask yourself how much compelling power it adds to your language and\r\nthen evaluate critically whether it pays its way. Is the change so valuable that\r\nit is worth blowing some of your novelty budget?"]}),"\n",(0,s.jsx)(n.p,{children:"In practice, I find this means that you end up being pretty conservative with\r\nsyntax and more adventurous with semantics. As fun as it is to put on a new\r\nchange of clothes, swapping out curly braces with some other block delimiter is\r\nvery unlikely to add much real power to the language, but it does spend some\r\nnovelty. It's hard for syntax differences to carry their weight."}),"\n",(0,s.jsx)(n.p,{children:"On the other hand, new semantics can significantly increase the power of the\r\nlanguage. Multimethods, mixins, traits, reflection, dependent types, runtime\r\nmetaprogramming, etc. can radically level up what a user can do with the\r\nlanguage."}),"\n",(0,s.jsx)(n.p,{children:"Alas, being conservative like this is not as fun as just changing everything.\r\nBut it's up to you to decide whether you want to chase mainstream success or not\r\nin the first place. We don't all need to be radio-friendly pop bands. If you\r\nwant your language to be like free jazz or drone metal and are happy with the\r\nproportionally smaller (but likely more devoted) audience size, go for it."}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var s=t(6540);const r={},i=s.createContext(r);function a(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);